{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão Linear\n",
    "\n",
    "*fonte: Wikipedia*\n",
    "\n",
    "<img src=\"img/linear_regression.png\" width=\"350\" />\n",
    "\n",
    "Em estatística ou econometria, regressão linear é uma equação para se estimar a condicional (valor esperado) de uma variável y, dados os valores de algumas outras variáveis x.\n",
    "Exemplo de regressão linear.\n",
    "\n",
    "A regressão, em geral, tem como objectivo tratar de um valor que não se consegue estimar inicialmente.\n",
    "\n",
    "A regressão linear é chamada \"linear\" porque se considera que a relação da resposta às variáveis é uma função linear de alguns parâmetros. Os modelos de regressão que não são uma função linear dos parâmetros se chamam modelos de regressão não-linear. Sendo uma das primeiras formas de análise regressiva a ser estudada rigorosamente, e usada extensamente em aplicações práticas. Isso acontece porque modelos que dependem de forma linear dos seus parâmetros desconhecidos, são mais fáceis de ajustar que os modelos não-lineares aos seus parâmetros, e porque as propriedades estatísticas dos estimadores resultantes são fáceis de determinar.\n",
    "\n",
    "Modelos de regressão linear são frequentemente ajustados usando a abordagem dos mínimos quadrados, mas que também pode ser montada de outras maneiras, tal como minimizando a \"falta de ajuste\" em alguma outra norma (com menos desvios absolutos de regressão), ou através da minimização de uma penalização da versão dos mínimos quadrados. Por outro lado, a abordagem de mínimos quadrados pode ser utilizado para ajustar a modelos que não são modelos lineares. Assim, embora os termos \"mínimos quadrados\" e \"modelo linear\" estejam intimamente ligados, eles não são sinônimos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise de dados e introdução a Regressão\n",
    "\n",
    "\n",
    "## Forma do modelo linear\n",
    "\n",
    "$y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + ... + \\beta_nx_n$\n",
    "- $y$ é a variável dependente (a resposta)\n",
    "- $\\beta_0$ é o termo de intercepção\n",
    "- $\\beta_1$ é o coeficiente para $x_1$ \n",
    "- $\\beta_n$ é o coeficiente para $x_n$\n",
    "\n",
    "Os **$\\beta$** são os chamados **_Coeficientes do modelo_**\n",
    "\n",
    "- Esses valores são estimados (ou \"aprendidos\") no processo de adaptação do modelo utilizando o critério ** mínimos quadrados **.\n",
    "- Especificamente, encontramos a linha (matematicamente) que minimiza a adição ** de quadrados de resíduos ** (ou “total de erros quadráticos”).\n",
    "- E quando já tivermos aprendido esses coeficientes, podemos usar o modelo para prever a resposta.\n",
    "\n",
    "## Operação vetorial (multidimensioanal)\n",
    "\n",
    "Ao usar a base de dados com $k$ variáveis explicativas e $n$ observações, o modelo pode ser escrito na forma matricial:\n",
    "\n",
    "<img src=\"img/regressao_matriz.png\" width=\"450\" />\n",
    "\n",
    "\n",
    "## Pré-requisitos do modelo de regressão Linear\n",
    "\n",
    "A maioria dos testes estatísticos depende de suposições sobre as variáveis. Para tirar conclusões sobre as estimativas para um modelo de regressão linear, quatro suposições são feitas sobre o comportamento dos dados:\n",
    "\n",
    "- A relação entre as variáveis de resposta e de previsão é **linear** na natureza.\n",
    "- Os erros são **independentes**. \n",
    "- Os erros possuem distribuições **normal**. \n",
    "- Os erros têm a **mesma** variância.\n",
    "\n",
    "\n",
    "**LINEAR**\n",
    "- Se a relação entre as variáveis ​​de resposta e preditor não for linear, os resultados da análise de regressão irão subestimar a verdadeira relação. Isso é melhor verificado com um gráfico de dispersão dos valores previstos versus os valores observados.\n",
    "\n",
    "\n",
    "**INDEPENDENTES**\n",
    "- Séries autocorrelacionadas o que não é o nosso caso. Plotar um histograma dos resíduos pode ajudar a verificar se eles são aleatórios. Se aleatório, os dados não devem exibir nenhuma estrutura identificável. Além disso, é comum testarmos a correlação dos residuos com as variaveis independentes.\n",
    "\n",
    "\n",
    "**NORMAL**\n",
    "- Se a distribuição de erro for significativamente não normal, os intervalos de previsão não serão confiáveis. O melhor teste para erros normalmente distribuídos é um gráfico de probabilidade normal dos resíduos . Se a distribuição for normal, os pontos em tal plotagem devem se aproximar da linha de referência diagonal.\n",
    "\n",
    "\n",
    "- As violações da normalidade freqüentemente surgem porque as distribuições das variáveis ​​são significativamente não-normais e / ou a suposição de linearidade é violada. Em tais casos, uma transformação não linear de variáveis pode resolver ambos os problemas. Se as distribuições de algumas das variáveis ​​forem extremamente assimétricas ou de cauda longa, elas podem não se encaixar em um modelo linear com erros normalmente distribuídos.\n",
    "\n",
    "\n",
    "- Como os dados reais raramente apresentam erros que normalmente são distribuídos normalmente e, como uma violação significativa da suposição de distribuição normal pode indicar outro problema com as premissas do modelo e / ou a presença de pontos de dados influentes, geralmente é útil se concentrar mais em quaisquer violações de dados. as outras suposições e / ou a influência de alguns outliers (que podem ser os principais responsáveis ​​por violações da normalidade de qualquer maneira).\n",
    "\n",
    "\n",
    "**VARIÂNCIA**\n",
    "- Se a variação dos erros for marcadamente diferente em vários valores, isso pode levar à distorção dos resultados e enfraquecer a análise. Essa suposição pode ser verificada examinando-se um gráfico residual dos valores previstos versus os resíduos padronizados . Idealmente, os resíduos são aleatoriamente espalhados em torno de 0, fornecendo uma distribuição relativamente uniforme. A largura vertical da dispersão não deve aparecer para aumentar ou diminuir os valores ajustados.\n",
    "\n",
    "\n",
    "**Regressões Simples**\n",
    "\n",
    "- O objetivo é ajustar a inclinação (w1 nesse exemplo) e o intercepto (b) de modo que a regressão linear (a \"linha\" laranja) minimize a soma dos resíduos (as distâncias entre as observações, \"bolas azuis\" e os valores esperados pela regressão, os resíduos são as distâncias verticais.)\n",
    "\n",
    "<img src=\"img/linear_regression_scheme.png\" width=\"450\" />\n",
    "\n",
    "\n",
    "#### Gerando dados para treinarmos.\n",
    "\n",
    "- RNG é o método de números aleatórios que estamos criando com um seed fixo (123) para tornar-se reprodutivel, para que os mesmos números aleatórios sejam gerados - para documentação [clique aqui](https://www.mathworks.com/help/matlab/ref/rng.html);\n",
    "- Como vamos gerar duas variáveis, vamos definir duas médias, 100 e 1000;\n",
    "- Na variável cov está o \"truque\" para gerar dados fakes para uma regressão linear, estamos definindo uma matriz 2x2 (2 linhas e 2 colunas) e dizendo que a covariância entre as duas séries de números aleatórios que estamos criando **não** são independentes e essa não independencia é o que vamos tentar capturar com a regressão linear.\n",
    "- Na variável sample estamos criando duas distribuições normal que seguem certa regra de covariância que passamos, por isso a ideia de elas são \"multivariadas\" (ou seja, os valores de uma série dependem da outra).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_formats=['svg']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Começaremos com a regressão linear mais familiar, um ajuste linear aos dados. Um ajuste em linha reta é um modelo da forma de:\n",
    "$$y = a * x + b $$\n",
    "\n",
    "Onde $b$ é chamado de intercepto e $a$ de inclinação.\n",
    "\n",
    "Considere os seguintes dados, que estão espalhados sobre uma linha com uma inclinação de 4 e um intercepto de -5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(42)\n",
    "\n",
    "x = 10 * rng.rand(200)\n",
    "y = 3 * x  -5 + 4*rng.randn(200)\n",
    "\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solução analitica\n",
    " $w = (X^T X)^{-1} X^T y$\n",
    " \n",
    "Para solução da derivação [clique aqui](https://stats.stackexchange.com/questions/46151/how-to-derive-the-least-square-estimator-for-multiple-linear-regression) \n",
    "<br>\n",
    "\n",
    "\n",
    "Onde:\n",
    "- w é o **vetor** de pesos (nossos parâmetros estimados)\n",
    "- X é a matriz de valores, onde cada linha é uma observação e cada coluna é uma variável\n",
    "- o Sobrescrito T indica \"Transposto\", ou seja, a matriz com um T é a matriz transposta.\n",
    "- y é simplesmente o vetor da variável y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculando o intercepto $b$ e a inclinação $a$ pela Solução Analítica (método raiz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = x[:, np.newaxis]\n",
    "\n",
    "# Um ponto importante aqui é adicionar uma coluna de \"1s\" que será nosso intercepto.\n",
    "Xb = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "w = np.zeros(X.shape[1])\n",
    "\n",
    "z = np.linalg.inv(np.dot(Xb.T, Xb))\n",
    "w = np.dot(z, np.dot(Xb.T, y))\n",
    "b, w1 = w[0], w[1]\n",
    "\n",
    "print('Intercepto: %.2f' % b)\n",
    "print('Inclinação: %.2f' % w1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agora utilizando o Sklearn.Linar_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression(fit_intercept=True)\n",
    "\n",
    "model.fit(x[:, np.newaxis], y)\n",
    "\n",
    "xfit = np.linspace(0, 10, 100)\n",
    "yhat = model.predict(xfit[:, np.newaxis])\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.plot(xfit, yhat)\n",
    "\n",
    "print(\"Intercepto beta_0: \", model.intercept_)\n",
    "print(\"Inclinação beta_1: \", model.coef_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE\n",
    "\n",
    "Na estatística, o erro quadrático médio (MSE) ou o desvio médio quadrático (MSD) de um estimador (de um procedimento para estimar uma quantidade não observada) mede a média dos quadrados dos erros - isto é, a diferença quadrática média entre os estimados valores e o que é estimado. MSE é uma função de risco, correspondente ao valor esperado da perda de erro quadrada. O fato de que o MSE é quase sempre estritamente positivo (e não zero) é por causa da aleatoriedade ou porque o estimador não leva em conta informações que poderiam produzir uma estimativa mais precisa.\n",
    "\n",
    "O MSE é uma medida da qualidade de um estimador - é sempre não negativo, e valores próximos de zero são melhores.\n",
    "\n",
    "O MSE é o segundo momento (sobre a origem) do erro e, portanto, incorpora tanto a variância do estimador (quão amplamente difundidas as estimativas são de uma amostra de dados para outra) quanto seu viés (a que distância o valor médio estimado é da verdade). Para um estimador não-viesado, o MSE é a variância do estimador. Como a variância, o MSE tem as mesmas unidades de medida do quadrado da quantidade estimada. Em uma analogia ao desvio padrão, obter a raiz quadrada do MSE produz o erro quadrático médio ou o desvio quadrático médio (RMSE ou RMSD), que tem as mesmas unidades que a quantidade estimada; para um estimador não-viesado, o RMSE é a raiz quadrada da variância, conhecida como o erro padrão.\n",
    "\n",
    "\n",
    "#### Qualidade do Ajuste\n",
    "\n",
    "#### Erros Quadraticos Médios \n",
    "(MSE, Mean Squared Error)\n",
    "\n",
    "$$MSE = \\frac{1}{n} \\sum_{i=1}^{n} \\big(y_i - \\hat{y_i}\\big)^2$$\n",
    "\n",
    "- Note que o MSE é dependente da escala, e retorna $unidade^2$\n",
    "\n",
    "### RMSE\n",
    "\n",
    "O RMSE (Root Mean Squared Error) representa simplesmente o MSE extraindo-se a raiz quadrada, para que o resultado fique na mesma unidade da variável estudada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando os valores preditos pelo método raiz e calculando os Erros Quadráticos Médios\n",
    "\n",
    "y_predicted = x*w1 + b\n",
    "mse = np.mean((y - y_predicted)**2)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraindo a raiz quadrada para obter a resposta na mesma unidade de medida\n",
    "\n",
    "# R = Root, Raiz\n",
    "rmse = np.sqrt(mse)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotando a distribuição dos dados pelo respectivo erro em um gráfico de dispersão\n",
    "\n",
    "plt.scatter(np.arange(x.shape[0]), y - y_predicted)\n",
    "plt.ylabel('vertical offset')\n",
    "plt.xlabel('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotando a distribuição dos erros em um histograma\n",
    "\n",
    "plt.hist(y - y_predicted, bins=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coeficiente de Determinação \n",
    "ou $R^2$\n",
    "\n",
    "- Soma total dos quadrados (variabilidade da variável resposta ou alvo, proporcional à variância do y):\n",
    "\n",
    "$$SS_{total} = \\sum_{i=1}^{n} \\big( y_i - \\bar{y_i} \\big)^2$$\n",
    "\n",
    "- Soma dos Residuos ao Quadrado:\n",
    "\n",
    "$$SS_{residual} = \\sum_{i=1}^{n} \\big( \\hat{y_i} - \\bar{y_i} \\big)^2$$\n",
    "\n",
    "- Coeficiente de Determinação $R^2$:\n",
    "\n",
    "$$R^2 = 1-\\frac{SS_{residual}}{SS_{total}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mais informações sobre o R Quadrado\n",
    "\n",
    "R2 representa a porcentagem de variação na resposta que é explicada pelo modelo. Ele é calculado como 1 menos a razão da soma dos quadrados dos erros (que é a variação que não é explicada pelo modelo) para a soma total dos quadrados (que é a variação total no modelo).\n",
    "\n",
    "#### Interpretação\n",
    "\n",
    "Use R2 para determinar se o modelo ajusta bem os dados. Quanto mais alto o valor de R2 melhor o modelo ajusta seus dados. O valor de R2 está sempre entre 0 e 100%.\n",
    "\n",
    "Você pode usar um gráfico de linha ajustada para ilustrar graficamente valores de R2 diferentes. O primeiro gráfico ilustra um modelo de regressão simples que explica 85,5% da variação na resposta. O segundo gráfico ilustra um modelo que explica 22,6% da variação na resposta. Quanto mais variação é explicada pelo modelo, mais perto os pontos de dados caem da linha de regressão ajustada. Teoricamente, se um modelo pudesse explicar 100% da variação, os valores ajustados sempre se igualariam aos valores observados e todos os pontos de dados cairiam sobre a linha ajustada. No entanto, mesmo se R2 representar 100%, o modelo não necessariamente prediz bem as novas observações. \n",
    "\n",
    "<br>\n",
    "<img src=\"img/r2_exemplo.png\" width=\"550\" />\n",
    "<br>\n",
    "\n",
    "Considere as seguintes questões ao interpretar o valor de R2:\n",
    "\n",
    "- O R2 sempre aumenta quando você adiciona mais preditores a um modelo. Por exemplo, o melhor modelo de cinco preditores terá sempre um R2 que é pelo menos tão elevado quanto o melhor modelo de quatro preditores. Portanto, R2 é mais útil quando for comparado a modelos do mesmo tamanho.\n",
    "\n",
    "- Amostras pequenas não fornecem uma estimativa precisa da força da relação entre a resposta e os preditores. Se você precisar que R2 seja mais exato, deve usar uma amostra maior (geralmente, 40 ou mais).\n",
    "\n",
    "- R2 é apenas uma medida de o quão bem o modelo ajusta os dados. Mesmo quando um modelo tem um R2 elevado, você deve verificar os gráficos de resíduos para conferir se o modelo satisfaz os pressupostos do modelo.\n",
    "\n",
    "# R Quadrado Ajustado\n",
    "\n",
    "O R2 ajustado é a porcentagem de variação na resposta que é explicada pelo modelo, ajustada para o número de preditores do modelo em relação ao número de observações. O R2 ajustado é calculado como 1 menos a razão entre o quadrado médio do erro (QME) em relação ao quadrado médio total (QM total).\n",
    "Interpretação\n",
    "\n",
    "Use o R2 ajustado quando desejar comparar modelos que têm diferentes números de preditores. R2 sempre aumenta quando você adiciona um preditor ao modelo, mesmo quando não existe uma verdadeira melhoria ao modelo. O valor de R2 ajustado incorpora o número de preditores no modelo para ajudá-lo a escolher o modelo correto.\n",
    "Por exemplo, você trabalha para um fabricante de batatas fritas que examina os fatores que afetam a porcentagem de batatas quebradas por embalagem. Você recebe os seguintes resultados ao adicionar os preditores em uma abordagem stepwise. \n",
    "\n",
    "<br>\n",
    "<img src=\"img/r2_ajustado.png\" width=\"650\" />\n",
    "<br>\n",
    "\n",
    "O primeiro modelo produz um R2 de mais de 50%. O segundo modelo adiciona a taxa de resfriamento ao modelo. O R2 ajustado aumenta, o que indica que a taxa de resfriamento melhora o modelo. O terceiro modelo, o que aumenta a temperatura de cozimento, aumenta o R2, mas não o R2 ajustado. Esses resultados indicam que a temperatura de cozimento não aprimoram o modelo. Com base nesses resultados, você considera remover a temperatura de cozimento do modelo. \n",
    "\n",
    "### Calculando o R Quadrado na prática"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Método raiz\n",
    "mean_y = np.mean(y)\n",
    "SS_total = np.sum((y - mean_y)**2)\n",
    "SS_residual = np.sum((y_predicted - mean_y)**2)\n",
    "r_squared = SS_residual / SS_total\n",
    "r_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# método nutella\n",
    "slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(x, y)\n",
    "r_value**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisando a relação entre Salário e Educação\n",
    "\n",
    "<br>\n",
    "<img src=\"img/ibge_sidra.png\" width=\"350\" />\n",
    "<br>\n",
    "\n",
    "Vamos testar uma hipótese. Será que estudar aumenta nossos salarios?\n",
    "\n",
    "Vamos usar uma regressão de Salario ~ Estudo para nos ajudar a responder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r'../../99 Datasets/demografia.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primeiro vamos ver o Scatter plot e tentar inferir alguma relação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df.dropna().sample(1000, random_state=7)\n",
    "plt.scatter(sample['anos_estudo'], sample['salario'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dificil inferir algo desse grafico, mas já vemos que tem alguns outliners que não fazem muito sentido, vamos filtra-los."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mascara_salario = df.salario<500000\n",
    "sample = df[mascara_salario].dropna().sample(1000, random_state=7)\n",
    "\n",
    "plt.scatter(sample['anos_estudo'], sample['salario'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisando a correlação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[['anos_estudo','salario']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Legal! Correlação de 0.3 responde nossa pergunta. Quanto mais estudo mais salario, além disso a taxa é de 30% de \"transferência\" entre estudo e salario. Está certo isso? Quais os problemas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos rodar uma regressão para ver as diferenças .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression(fit_intercept=True)\n",
    "\n",
    "model.fit(sample['anos_estudo'][:, np.newaxis], sample['salario'])\n",
    "\n",
    "xfit = np.linspace(0, 14, 100)\n",
    "yhat = model.predict(xfit[:, np.newaxis])\n",
    "\n",
    "print(\"Intercepto beta_0: \", model.intercept_)\n",
    "print(\"Inclinação beta_1: \", model.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression(fit_intercept=True)\n",
    "\n",
    "model.fit(sample['anos_estudo'][:, np.newaxis], sample['salario'])\n",
    "\n",
    "xfit = np.linspace(0, 14, 1000)\n",
    "yhat = model.predict(xfit[:, np.newaxis])\n",
    "\n",
    "print(\"Intercepto beta_0: \", model.intercept_)\n",
    "print(\"Inclinação beta_1: \", model.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R^2: \", model.score(sample['anos_estudo'][:, np.newaxis], sample['salario']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando o método Scipy.Stats.Linregress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# método nutella\n",
    "slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(sample['anos_estudo'], sample['salario'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Inclinação:', slope)\n",
    "print ('Intercepto:', intercept)\n",
    "print ('R-quadrado:', r_value**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plotar o gráfico de distribuição dos erros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = sample['salario']\n",
    "plt.hist(y - yhat,bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plotar o gráfico de dispersão dos erros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(xfit, y-yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estudar a relação entre idade e salário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
