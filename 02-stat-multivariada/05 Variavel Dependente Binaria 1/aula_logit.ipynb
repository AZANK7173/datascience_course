{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão Logística\n",
    "\n",
    "<br>\n",
    "<img src=\"img/regressao_logistica.png\">\n",
    "<br>\n",
    "\n",
    "\n",
    "A regressão logística é uma técnica estatística que tem como objetivo produzir, a partir de um conjunto de observações, um modelo que permita a predição de valores tomados por uma variável categórica, frequentemente binária, a partir de uma série de variáveis explicativas contínuas e/ou binárias[1][2]\n",
    "\n",
    "A regressão logística é amplamente usada em ciências médicas e sociais, e tem outras denominações, como modelo logístico, modelo logit, e classificador de máxima entropia. A regressão logística é utilizada em áreas como as seguintes:\n",
    "\n",
    "- Em medicina, permite por exemplo determinar os factores que caracterizam um grupo de indivíduos doentes em relação a indivíduos sãos.\n",
    "- No domínio dos seguros, permite encontrar fracções da clientela que sejam sensíveis a determinada política securitária em relação a um dado risco particular.\n",
    "- Em instituições financeiras, pode detectar os grupos de risco para a subscrição de um crédito.\n",
    "- Em econometria, permite explicar uma variável discreta, como por exemplo as intenções de voto em atos eleitorais.\n",
    "\n",
    "O êxito da regressão logística assenta sobretudo nas numerosas ferramentas que permitem interpretar de modo aprofundado os resultados obtidos.\n",
    "\n",
    "Em comparação com as técnicas conhecidas em regressão, em especial a regressão linear, a regressão logística distingue-se essencialmente pelo facto de a variável resposta ser categórica.\n",
    "\n",
    "Enquanto método de predição para variáveis categóricas, a regressão logística é comparável às técnicas supervisionadas propostas em aprendizagem automática (árvores de decisão, redes neurais, etc.), ou ainda a análise discriminante preditiva em estatística exploratória. É possível de as colocar em concorrência para escolha do modelo mais adaptado para um certo problema preditivo a resolver.\n",
    "\n",
    "Trata-se de um modelo de regressão para variáveis dependentes ou de resposta binomialmente distribuídas. É útil para modelar a probabilidade de um evento ocorrer como função de outros factores. É um modelo linear generalizado que usa como função de ligação a função logit. \n",
    "\n",
    "Calculando a probabilidade de um certo evento booleano ser verdadeiro:\n",
    "\n",
    "<br>\n",
    "\\begin{equation*}\n",
    "P(y=1|X)= \\dfrac{1}{e^{-z}} = P_i\n",
    "\\end{equation*}\n",
    "<br>\n",
    "\n",
    "Da mesma forma, o mesmo evento tem a seguinte probabilidade de ser falso:\n",
    "\n",
    "<br>\n",
    "\\begin{equation*}\n",
    "P(y=0|X)= \\dfrac{1}{e^{z}} = 1 - P_i\n",
    "\\end{equation*}\n",
    "<br>\n",
    "\n",
    "Dividindo-se uma equação pela outra:\n",
    "\n",
    "<br>\n",
    "\\begin{equation*}\n",
    "\\dfrac{P_i}{1-P_i} = \\dfrac{1}{e^{-z}} * \\dfrac{e^{z}}{1}\n",
    "\\end{equation*}\n",
    "<br>\n",
    "\n",
    "Aplicando o Logatítmo Neperiano (Log de base _e_) dos dois lados da equação:\n",
    "\n",
    "<br>\n",
    "\\begin{equation*}\n",
    "z = ln(\\dfrac{P_i}{1-P_i})\n",
    "\\end{equation*}\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemplo de Regressão Logistica\n",
    "\n",
    "Vamos estudar como analisar as correlações parciais e os impactos causais em variaveis dependentes binárias.\n",
    "\n",
    "<br>\n",
    "<img src=\"img/diabetes.png\" / width = 200>\n",
    "<br>\n",
    "\n",
    "\n",
    "Cerca de um em cada sete adultos dos EUA tem diabetes agora, de acordo com os Centros para Controle e Prevenção de Doenças. Mas até 2050, essa taxa pode disparar para até um em três. Com isto em mente, isso é o que vamos fazer hoje: Aprender a usar o Aprendizado de Máquina para nos ajudar a prever o Diabetes. Vamos começar!\n",
    "\n",
    "Dataset1: Diabetes\n",
    "    1. Number of times pregnant\n",
    "    2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "    3. Diastolic blood pressure (mm Hg)\n",
    "    4. Triceps skin fold thickness (mm)\n",
    "    5. 2-Hour serum insulin (mu U/ml)\n",
    "    6. Body mass index (weight in kg/(height in m)^2)\n",
    "    7. Diabetes pedigree function\n",
    "    8. Age (years)\n",
    "    9. Class variable (0 or 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando as bibliotecas e os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd  \n",
    "import statsmodels.api as sm  \n",
    "import numpy as np  \n",
    "from bokeh.plotting import figure, show, output_file\n",
    "from bokeh.io import output_notebook, push_notebook, show\n",
    "from ipywidgets import interact\n",
    "import scipy.special\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "#read the data in  \n",
    "df = pd.read_csv('../../99 Datasets/diabetes.csv.zip')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lendo e analisando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colormap = {'tested_positive': 'red', 'tested_negative': 'blue'}\n",
    "colors = [colormap[x] for x in df['class']]\n",
    "\n",
    "colors[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DICA DO PROFESSOR\n",
    "\n",
    "Uma opção de biblioteca de vizualização me Python, com a geração de gráficos interativos é o BOKEH.\n",
    "\n",
    "# BOKEH: Biblioteca para plotagem de gráficos em Python\n",
    "\n",
    "\n",
    "<br>\n",
    "<img src=\"img/bokeh_logo.png\" / width = 200>\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "O Bokeh é uma biblioteca de visualização interativa voltada para os navegadores da Web modernos para apresentação. Seu objetivo é fornecer uma construção elegante e concisa de gráficos versáteis e estender esse recurso com interatividade de alto desempenho em conjuntos de dados muito grandes ou de fluxo contínuo. O Bokeh pode ajudar qualquer pessoa que queira criar de forma rápida e fácil plotagens interativas, painéis e aplicativos de dados.\n",
    "\n",
    "O Bokeh é um projeto patrocinado fiscalmente do NumFOCUS, uma organização sem fins lucrativos dedicada a apoiar a comunidade de computação científica de código aberto. Se você gosta do Bokeh e quer apoiar nossa missão, por favor, considere fazer uma doação para apoiar nossos esforços.\n",
    "\n",
    "<br>\n",
    "<img src=\"img/bokeh.png\" / width = 600>\n",
    "<br>\n",
    "\n",
    "Para documentação oficial [clique aqui](https://bokeh.pydata.org/en/latest/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemplos do quanto o bokeh é flexivel e poderoso\n",
    "\n",
    "- http://bokeh.pydata.org/en/0.10.0/docs/gallery/periodic.html\n",
    "- https://bokeh.pydata.org/en/latest/docs/gallery.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import bokeh\n",
    "bokeh.sampledata.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0,2*np.pi, 2000)\n",
    "y = np.sin(x)\n",
    "\n",
    "\n",
    "p = figure(title='teste seno', plot_height=300, plot_width=600, y_range=(-5,5))\n",
    "r = p.line(x, y, color='#2222aa', line_width=3)\n",
    "\n",
    "\n",
    "def update(f, w=1, A=1, phi=0):\n",
    "    if f == 'sin': func = np.sin\n",
    "    elif f == 'cos': func = np.cos\n",
    "    elif f == 'tan': func = np.tan\n",
    "    r.data_source.data['y'] = A * func(w * x + phi)\n",
    "    push_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(p, notebook_handle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(update, f=['sin', 'cos', 'tan'], w=(0,100), A=(1,5), phi=(0,20, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from bokeh.palettes import Spectral4\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.sampledata.stocks import AAPL, IBM, MSFT, GOOG\n",
    "\n",
    "p = figure(plot_width=800, plot_height=250, x_axis_type=\"datetime\")\n",
    "p.title.text = 'Click on legend entries to mute the corresponding lines'\n",
    "\n",
    "for data, name, color in zip([AAPL, IBM, MSFT, GOOG], [\"AAPL\", \"IBM\", \"MSFT\", \"GOOG\"], Spectral4):\n",
    "    temp = pd.DataFrame(data)\n",
    "    temp['date'] = pd.to_datetime(temp['date'])\n",
    "    p.line(temp['date'], temp['close'], line_width=2, color=color, alpha=0.8,\n",
    "           muted_color=color, muted_alpha=0.2, legend=name)\n",
    "\n",
    "p.legend.location = \"top_left\"\n",
    "p.legend.click_policy=\"mute\"\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.special\n",
    "\n",
    "from bokeh.layouts import gridplot\n",
    "from bokeh.plotting import figure, show, output_file\n",
    "\n",
    "def make_plot(title, hist, edges, x, pdf, cdf):\n",
    "    p = figure(title=title, tools='', background_fill_color=\"#fafafa\")\n",
    "    p.quad(top=hist, bottom=0, left=edges[:-1], right=edges[1:],\n",
    "           fill_color=\"navy\", line_color=\"white\", alpha=0.5)\n",
    "    p.line(x, pdf, line_color=\"#ff8888\", line_width=4, alpha=0.7, legend=\"PDF\")\n",
    "    p.line(x, cdf, line_color=\"orange\", line_width=2, alpha=0.7, legend=\"CDF\")\n",
    "\n",
    "    p.y_range.start = 0\n",
    "    p.legend.location = \"center_right\"\n",
    "    p.legend.background_fill_color = \"#fefefe\"\n",
    "    p.xaxis.axis_label = 'x'\n",
    "    p.yaxis.axis_label = 'Pr(x)'\n",
    "    p.grid.grid_line_color=\"white\"\n",
    "    return p\n",
    "\n",
    "# Normal Distribution\n",
    "\n",
    "mu, sigma = 0, 0.5\n",
    "\n",
    "measured = np.random.normal(mu, sigma, 1000)\n",
    "hist, edges = np.histogram(measured, density=True, bins=50)\n",
    "\n",
    "x = np.linspace(-2, 2, 1000)\n",
    "pdf = 1/(sigma * np.sqrt(2*np.pi)) * np.exp(-(x-mu)**2 / (2*sigma**2))\n",
    "cdf = (1+scipy.special.erf((x-mu)/np.sqrt(2*sigma**2)))/2\n",
    "\n",
    "p1 = make_plot(\"Normal Distribution (μ=0, σ=0.5)\", hist, edges, x, pdf, cdf)\n",
    "\n",
    "# Log-Normal Distribution\n",
    "\n",
    "mu, sigma = 0, 0.5\n",
    "\n",
    "measured = np.random.lognormal(mu, sigma, 1000)\n",
    "hist, edges = np.histogram(measured, density=True, bins=50)\n",
    "\n",
    "x = np.linspace(0.0001, 8.0, 1000)\n",
    "pdf = 1/(x* sigma * np.sqrt(2*np.pi)) * np.exp(-(np.log(x)-mu)**2 / (2*sigma**2))\n",
    "cdf = (1+scipy.special.erf((np.log(x)-mu)/(np.sqrt(2)*sigma)))/2\n",
    "\n",
    "p2 = make_plot(\"Log Normal Distribution (μ=0, σ=0.5)\", hist, edges, x, pdf, cdf)\n",
    "\n",
    "# Gamma Distribution\n",
    "\n",
    "k, theta = 7.5, 1.0\n",
    "\n",
    "measured = np.random.gamma(k, theta, 1000)\n",
    "hist, edges = np.histogram(measured, density=True, bins=50)\n",
    "\n",
    "x = np.linspace(0.0001, 20.0, 1000)\n",
    "pdf = x**(k-1) * np.exp(-x/theta) / (theta**k * scipy.special.gamma(k))\n",
    "cdf = scipy.special.gammainc(k, x/theta)\n",
    "\n",
    "p3 = make_plot(\"Gamma Distribution (k=7.5, θ=1)\", hist, edges, x, pdf, cdf)\n",
    "\n",
    "# Weibull Distribution\n",
    "\n",
    "lam, k = 1, 1.25\n",
    "measured = lam*(-np.log(np.random.uniform(0, 1, 1000)))**(1/k)\n",
    "hist, edges = np.histogram(measured, density=True, bins=50)\n",
    "\n",
    "x = np.linspace(0.0001, 8, 1000)\n",
    "pdf = (k/lam)*(x/lam)**(k-1) * np.exp(-(x/lam)**k)\n",
    "cdf = 1 - np.exp(-(x/lam)**k)\n",
    "\n",
    "p4 = make_plot(\"Weibull Distribution (λ=1, k=1.25)\", hist, edges, x, pdf, cdf)\n",
    "\n",
    "# output_file('histogram.html', title=\"histogram.py example\")\n",
    "\n",
    "show(gridplot([p1,p2,p3,p4], ncols=2, plot_width=400, plot_height=400, toolbar_location=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import linspace\n",
    "from scipy.stats.kde import gaussian_kde\n",
    "\n",
    "from bokeh.io import output_file, show\n",
    "from bokeh.models import ColumnDataSource, FixedTicker, PrintfTickFormatter\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.sampledata.perceptions import probly\n",
    "\n",
    "import colorcet as cc\n",
    "\n",
    "# output_file(\"ridgeplot.html\")\n",
    "\n",
    "def ridge(category, data, scale=20):\n",
    "    return list(zip([category]*len(data), scale*data))\n",
    "\n",
    "cats = list(reversed(probly.keys()))\n",
    "\n",
    "palette = [cc.rainbow[i*15] for i in range(17)]\n",
    "\n",
    "x = linspace(-20,110, 500)\n",
    "\n",
    "source = ColumnDataSource(data=dict(x=x))\n",
    "\n",
    "p = figure(y_range=cats, plot_width=900, x_range=(-5, 105), toolbar_location=None)\n",
    "\n",
    "for i, cat in enumerate(reversed(cats)):\n",
    "    pdf = gaussian_kde(probly[cat])\n",
    "    y = ridge(cat, pdf(x))\n",
    "    source.add(y, cat)\n",
    "    p.patch('x', cat, color=palette[i], alpha=0.6, line_color=\"black\", source=source)\n",
    "\n",
    "p.outline_line_color = None\n",
    "p.background_fill_color = \"#efefef\"\n",
    "\n",
    "p.xaxis.ticker = FixedTicker(ticks=list(range(0, 101, 10)))\n",
    "p.xaxis.formatter = PrintfTickFormatter(format=\"%d%%\")\n",
    "\n",
    "p.ygrid.grid_line_color = None\n",
    "p.xgrid.grid_line_color = \"#dddddd\"\n",
    "p.xgrid.ticker = p.xaxis[0].ticker\n",
    "\n",
    "p.axis.minor_tick_line_color = None\n",
    "p.axis.major_tick_line_color = None\n",
    "p.axis.axis_line_color = None\n",
    "\n",
    "p.y_range.range_padding = 0.12\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voltando para os dados\n",
    "\n",
    "Estabelecendo cores para os resultados dos testes de diabetes (Positivo=Vermelho, Negativo=Azul), podemos plotar uma despersão do índice de massa corpórea por idade, para tentar identificar alguma tendência nos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colormap = {'tested_positive': 'red', 'tested_negative': 'blue'}\n",
    "colors = [colormap[x] for x in df['class']]\n",
    "\n",
    "colors[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plotando a de\n",
    "\n",
    "p = figure(title = \"Diabeyes\")\n",
    "p.xaxis.axis_label = 'Age'\n",
    "p.yaxis.axis_label = 'IMC'\n",
    "\n",
    "p.circle(df[\"age\"], df[\"mass\"],\n",
    "         color=colors, fill_alpha=0.3, size=7)\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotando uma dispersão com reta de tendência (best fit line) do nível de gordura da pele pela insulina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.io import show\n",
    "\n",
    "#the data\n",
    "x=df['skin']\n",
    "y=df['insu']\n",
    "\n",
    "# determine best fit line\n",
    "par = np.polyfit(x, y, 1, full=True)\n",
    "slope=par[0][0]\n",
    "intercept=par[0][1]\n",
    "y_predicted = [slope*i + intercept  for i in x]\n",
    "\n",
    "# plot it\n",
    "fig=figure()\n",
    "fig.circle(x,y)\n",
    "fig.line(x,y_predicted,color='red',legend='y='+str(round(slope,2))+'x+'+str(round(intercept,2)))\n",
    "show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identificando o nível de correlação das pessoas com diabetes (tested_positive) com todas as variáveis do DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y'] = df['class'] == 'tested_positive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.corr().round(2)['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotando a dispersão da concentração de glicose\n",
    "\n",
    "Quando plotamos a dispersão da concentração de glicose pelos casosde teste positivo em diabetes, não parece algo que possa ser representado por uma reta de tendência para representação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df['plas']\n",
    "y=df['y']\n",
    "\n",
    "fig=figure()\n",
    "fig.circle(x,y)\n",
    "show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quando usamos OLS para estimar esse efeito, temos um modelo linear de probabilidade\n",
    "\n",
    "\n",
    "- pode ser usado porque a categórica tem distribuição de Bernouli e sua média é a própria probabilidade\n",
    "- Pode ser maior que 1 e menor que zero (que não faz muito sentido)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine best fit line\n",
    "par = np.polyfit(x, y, 1, full=True)\n",
    "slope=par[0][0]\n",
    "intercept=par[0][1]\n",
    "y_predicted = [slope*i + intercept  for i in x]\n",
    "\n",
    "fig=figure()\n",
    "fig.circle(x,y)\n",
    "fig.line(x,y_predicted,color='red',legend='y='+str(round(slope,2))+'x+'+str(round(intercept,2)))\n",
    "show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rodando uma Regressão Linear dos testes positivos de diabetes pela concentração de glicose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y'] = df['y'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function1 = 'y ~ plas'\n",
    "\n",
    "model1 = smf.ols(function1, df).fit()\n",
    "print(model1.summary2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rodando a Regressão Linear com todas as variáveis do DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function1 = 'y ~ preg + plas + pres + skin + insu + mass + pedi + age'\n",
    "\n",
    "model1 = smf.ols(function1, df).fit()\n",
    "print(model1.summary2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rodando a Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = smf.logit(function1, df).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(logit.summary2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cálculo do valor predito para que o indivíduo tenha diabetes de acordo com a Regressão Logistica\n",
    "\n",
    "Este cálculo deve trazer o valor da __PROBABILIDADE__ do indivíduo ter diabetes, de acordo com a fórmula da regressão (que segue o mesmo princípio da regrassão linear), trazendo a composição dos efeitos de cada variável de aacordo com seus __Betas.__\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\\begin{equation}\n",
    "  (\\text{Diabete} = 1 \\mid \\text{Id, Imc, Ins}) = \\frac{\\text{exp}(\\beta_0 + \\beta_1 \\text{Idade} + \\beta_2 \\text{IMC} + \\beta_{3} \\text{Insulina)} }{1 + \\text{exp}(\\beta_0 + \\beta_1 \\text{Idade} + \\beta_2 \\text{IMC} +  \\beta_{3} \\text{Insulina})} \\label{eq:glm1}\n",
    "  \\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificando os valores para a primeira observação\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definindo o valor do intercepto \n",
    "\n",
    "logit.conf_int().mean(axis=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificando o código para cada posição dos valores da primeira observação\n",
    "\n",
    "df.iloc[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculando a soma dos valores para a primeira observação\n",
    "\n",
    "soma = 0\n",
    "\n",
    "for index, beta in enumerate(list(logit.conf_int().mean(axis=1))):\n",
    "    if index == 0:\n",
    "        soma = soma + beta\n",
    "    else:\n",
    "        betax = beta * df.iloc[0, index-1]\n",
    "        print(df.iloc[0, index-1], beta, betax)\n",
    "        soma += betax\n",
    "\n",
    "print(soma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1/(1+np.exp(-soma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparando com o valor nominal temos o mesmo resultado\n",
    "\n",
    "logit.predict()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotando a dsitribuição dos valores preditos pelo modelo de Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['yhat'] = logit.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['yhat'].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['yhat'].plot.kde()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisando probabilidade condicional com pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['yresult'] = 0\n",
    "\n",
    "threshold = 0.5\n",
    "\n",
    "for (i, p) in enumerate(df['yhat']):\n",
    "    if p > threshold:\n",
    "        df['yresult'][i] = 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['yresult'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz de Confusão\n",
    "\n",
    "<br>\n",
    "<img src=\"img/confusion_matrix.png\" / width = 600>\n",
    "<br>\n",
    "\n",
    "\n",
    "No campo de Machine Learning e especificamente o problema da classificação estatística, uma matriz de confusão, também conhecida como matriz de erro, é um layout de tabela específico que permite a visualização do desempenho de um algoritmo, tipicamente um aprendizado supervisionado (em aprendizagem não supervisionada é geralmente chamado de matriz de correspondência). Cada linha da matriz representa as instâncias em uma classe prevista, enquanto cada coluna representa as instâncias em uma classe real (ou vice-versa). O nome deriva do fato de que fica mais fácil ver se o sistema está confundindo duas classes (ou seja, comumente errando um nome como outro).\n",
    "\n",
    "É um tipo especial de tabela de contingência, com duas dimensões (\"atual\" e \"previsto\") e conjuntos idênticos de \"classes\" em ambas as dimensões (cada combinação de dimensão e classe é uma variável na tabela de contingência)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "result_matrix = confusion_matrix(df.y, df.yresult)\n",
    "result_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(df.y, df.yresult).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo da Precisão\n",
    "\n",
    "precision = tp / (tp+fp)\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo da Sensiblidade\n",
    "\n",
    "recall = tp / (tp+fn)\n",
    "recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alterando o limite da condição "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['yresult'] = 0\n",
    "\n",
    "threshold = 0.7\n",
    "\n",
    "for (i, p) in enumerate(df['yhat']):\n",
    "    if p > threshold:\n",
    "        df['yresult'][i] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['yresult'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_matrix = confusion_matrix(df.y, df.yresult)\n",
    "result_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(df.y, df.yresult).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo da Precisão\n",
    "\n",
    "precision = tp / (tp+fp)\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo da Sensiblidade\n",
    "\n",
    "recall = tp / (tp+fn)\n",
    "recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Com o aumento do limite de corte da probabilidade, ganhamos em precisão mas perdemos em sensibilidade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logit x Probit (Poisson x OLS)\n",
    "\n",
    "## Modelo Probit\n",
    "\n",
    "_fonte: Wikipedia_\n",
    "\n",
    "Na estatística, um modelo de __probit__ é um tipo de regressão onde a variável dependente pode levar apenas dois valores, por exemplo, casado ou não. A palavra é uma mala, vinda da probabilidade + unidade. O objetivo do modelo é estimar a probabilidade de que uma observação com características particulares caia em uma das categorias específicas. Além disso, classificar as observações com base em suas probabilidades previstas é um tipo de modelo de classificação binária.\n",
    "\n",
    "Um modelo de probit é uma especificação popular para um modelo de resposta ordinal ou binária. Como tal, trata o mesmo conjunto de problemas que a regressão logística usando técnicas semelhantes. O modelo __probit__, que emprega uma função probit link, é mais frequentemente estimado usando o procedimento padrão de máxima verossimilhança, sendo essa estimativa chamada de regressão probit.\n",
    "\n",
    "Os modelos probit foram introduzidos por Chester Bliss em 1934 como um método rápido para calcular as estimativas de máxima verossimilhança; para eles foi proposto por Ronald Fisher como um apêndice ao trabalho de Bliss em 1935."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "ax = fig.add_subplot(111)\n",
    "support = np.linspace(-6, 6, 1000)\n",
    "ax.plot(support, stats.logistic.cdf(support), 'r-', label='Logistic')\n",
    "ax.plot(support, stats.norm.cdf(support), label='Probit')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "ax = fig.add_subplot(111)\n",
    "support = np.linspace(-6, 6, 1000)\n",
    "ax.plot(support, stats.logistic.pdf(support), 'r-', label='Logistic')\n",
    "ax.plot(support, stats.norm.pdf(support), label='Probit')\n",
    "ax.legend();\n",
    "\n",
    "# Multiplicando-se a Legistica pelo desvio padrão da logistica, obtém-se a probit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
