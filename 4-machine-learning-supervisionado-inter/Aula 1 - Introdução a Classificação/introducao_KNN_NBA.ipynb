{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução ao KNN\n",
    "A idéia por trás do kNN é que pontos de dados semelhantes devem ter a mesma classe, pelo menos na maioria das vezes. Esse método é muito intuitivo e já provou em muitos domínios, incluindo sistemas de recomendação, detecção de anomalias e classificação de imagens / textos.\n",
    "\n",
    "Por exemplo, considere um caso em que você deseja classificar uma imagem como um dos 2000 tipos possíveis, como \"pessoa\", \"animal\", \"ao ar livre\", \"oceano\", \"pôr do sol\" e assim por diante. Dada uma função de distância adequada entre as imagens, a classificação de uma imagem não rotulada pode ser determinada pelas etiquetas atribuídas aos seus vizinhos mais próximos, ou seja, as imagens rotuladas que estão mais próximas a ela, de acordo com a função de distância.\n",
    "\n",
    "\n",
    "### Prós\n",
    "\n",
    "**Qualidade de previsão** : Um classificador kNN é capaz de recuperar partições não estruturadas do espaço, ao contrário de, digamos, um classificador linear que requer uma separação linear entre as classes. Ele também pode se adaptar a diferentes densidades no espaço, tornando-o mais robusto do que métodos lineares. Os dois exemplos de dados 2D a seguir ilustram diferentes partições do espaço impostas por dados rotulados e a previsão de um modelo kNN nesse espaço.\n",
    "\n",
    "<img src=\"img/sagemaker-knn-1.gif\">\n",
    "\n",
    "\n",
    "**Ciclos curtos** : Outra vantagem do kNN é que há pouco ou nenhum treinamento envolvido. Isso significa que iterar sobre diferentes métricas / modificações possíveis do conjunto de dados de entrada é potencialmente mais rápido quando comparado a um classificador que requer um procedimento de treinamento pesado, como redes neurais profundas, ou mesmo funções SVM.\n",
    "\n",
    "**Muitas classes de saída** : o kNN pode manipular facilmente um grande número de classes. Para comparação, um modelo linear ou uma rede neural profunda com  deve calcular explicitamente uma pontuação para cada classe possível e escolher a melhor. Imagine, por exemplo, uma tarefa de reconhecer tipos de flores por sua imagem ou por um conjunto de suas características, para as quais temos 100 mil exemplos de características e 5 mil exemplos de tipos de flores. Qualquer modelo que aprenda explicitamente 5mil conjuntos de parâmetros para identificar cada tipo de flor pode ser facilmente propenso a overfiting, o que significa que pode produzir respostas erradas.\n",
    "\n",
    "**Interpretabilidade** : A previsão de um modelo kNN é baseada na similaridade aos objetos existentes. Como resultado, a pergunta “por que meu exemplo recebeu a classe X?” É respondida assim: “porque itens semelhantes são rotulados com X.” Por exemplo, considere um modelo que avalie o risco envolvido com um empréstimo. No exemplo, um cliente foi considerado de alto risco porque 8 de 10 clientes que foram avaliados anteriormente e eram mais semelhantes a eles em termos de X, Y e Z, foram considerados de alto risco. Ao observar os vizinhos mais próximos, você pode ver objetos semelhantes ao exemplo que são rotulados como X, e você pode decidir se a previsão faz sentido.\n",
    "\n",
    "### Contras\n",
    "\n",
    "**Predição custosa**: A principal desvantagem do kNN é sua inferência cara. Para inferir o rótulo de uma consulta de entrada, precisamos encontrar os pontos de dados mais próximos a ela. Uma solução ingênua manteria todos os pontos de dados na memória e, dada uma consulta, calcularia a distância entre ela e todos os pontos de dados. Para quantidades concretas, se o conjunto de treinamento continha n pontos de dados de d dimensões, este processo requer operações aritméticas nd."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HandsOn\n",
    "\n",
    "Vamos usar o dataset sobre os jogadores da NBA em 2013 para prever seus pontos em 2014 utilizando KNN.\n",
    "\n",
    "Antes de começarmos algumas informações das colunas.\n",
    "\n",
    "    player - nome do jogador\n",
    "    pos - a posição do jogador\n",
    "    g - número de jogos em que o jogador estava\n",
    "    gs - número de jogos que o jogador iniciou\n",
    "    pts - total de pontos que o jogador marcou\n",
    "    \n",
    "Há muito mais colunas nos dados, a maioria contendo informações sobre o desempenho médio dos jogadores durante a temporada. \n",
    "\n",
    "Veja este site para uma explicação sobre o resto deles: https://www.rotowire.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(481, 31)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player</th>\n",
       "      <th>pos</th>\n",
       "      <th>age</th>\n",
       "      <th>bref_team_id</th>\n",
       "      <th>g</th>\n",
       "      <th>gs</th>\n",
       "      <th>mp</th>\n",
       "      <th>fg</th>\n",
       "      <th>fga</th>\n",
       "      <th>fg.</th>\n",
       "      <th>...</th>\n",
       "      <th>drb</th>\n",
       "      <th>trb</th>\n",
       "      <th>ast</th>\n",
       "      <th>stl</th>\n",
       "      <th>blk</th>\n",
       "      <th>tov</th>\n",
       "      <th>pf</th>\n",
       "      <th>pts</th>\n",
       "      <th>season</th>\n",
       "      <th>season_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quincy Acy</td>\n",
       "      <td>SF</td>\n",
       "      <td>23</td>\n",
       "      <td>TOT</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>847</td>\n",
       "      <td>66</td>\n",
       "      <td>141</td>\n",
       "      <td>0.468</td>\n",
       "      <td>...</td>\n",
       "      <td>144</td>\n",
       "      <td>216</td>\n",
       "      <td>28</td>\n",
       "      <td>23</td>\n",
       "      <td>26</td>\n",
       "      <td>30</td>\n",
       "      <td>122</td>\n",
       "      <td>171</td>\n",
       "      <td>2013-2014</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Steven Adams</td>\n",
       "      <td>C</td>\n",
       "      <td>20</td>\n",
       "      <td>OKC</td>\n",
       "      <td>81</td>\n",
       "      <td>20</td>\n",
       "      <td>1197</td>\n",
       "      <td>93</td>\n",
       "      <td>185</td>\n",
       "      <td>0.503</td>\n",
       "      <td>...</td>\n",
       "      <td>190</td>\n",
       "      <td>332</td>\n",
       "      <td>43</td>\n",
       "      <td>40</td>\n",
       "      <td>57</td>\n",
       "      <td>71</td>\n",
       "      <td>203</td>\n",
       "      <td>265</td>\n",
       "      <td>2013-2014</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jeff Adrien</td>\n",
       "      <td>PF</td>\n",
       "      <td>27</td>\n",
       "      <td>TOT</td>\n",
       "      <td>53</td>\n",
       "      <td>12</td>\n",
       "      <td>961</td>\n",
       "      <td>143</td>\n",
       "      <td>275</td>\n",
       "      <td>0.520</td>\n",
       "      <td>...</td>\n",
       "      <td>204</td>\n",
       "      <td>306</td>\n",
       "      <td>38</td>\n",
       "      <td>24</td>\n",
       "      <td>36</td>\n",
       "      <td>39</td>\n",
       "      <td>108</td>\n",
       "      <td>362</td>\n",
       "      <td>2013-2014</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arron Afflalo</td>\n",
       "      <td>SG</td>\n",
       "      <td>28</td>\n",
       "      <td>ORL</td>\n",
       "      <td>73</td>\n",
       "      <td>73</td>\n",
       "      <td>2552</td>\n",
       "      <td>464</td>\n",
       "      <td>1011</td>\n",
       "      <td>0.459</td>\n",
       "      <td>...</td>\n",
       "      <td>230</td>\n",
       "      <td>262</td>\n",
       "      <td>248</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>146</td>\n",
       "      <td>136</td>\n",
       "      <td>1330</td>\n",
       "      <td>2013-2014</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alexis Ajinca</td>\n",
       "      <td>C</td>\n",
       "      <td>25</td>\n",
       "      <td>NOP</td>\n",
       "      <td>56</td>\n",
       "      <td>30</td>\n",
       "      <td>951</td>\n",
       "      <td>136</td>\n",
       "      <td>249</td>\n",
       "      <td>0.546</td>\n",
       "      <td>...</td>\n",
       "      <td>183</td>\n",
       "      <td>277</td>\n",
       "      <td>40</td>\n",
       "      <td>23</td>\n",
       "      <td>46</td>\n",
       "      <td>63</td>\n",
       "      <td>187</td>\n",
       "      <td>328</td>\n",
       "      <td>2013-2014</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          player pos  age bref_team_id   g  gs    mp   fg   fga    fg.  \\\n",
       "0     Quincy Acy  SF   23          TOT  63   0   847   66   141  0.468   \n",
       "1   Steven Adams   C   20          OKC  81  20  1197   93   185  0.503   \n",
       "2    Jeff Adrien  PF   27          TOT  53  12   961  143   275  0.520   \n",
       "3  Arron Afflalo  SG   28          ORL  73  73  2552  464  1011  0.459   \n",
       "4  Alexis Ajinca   C   25          NOP  56  30   951  136   249  0.546   \n",
       "\n",
       "      ...      drb  trb  ast  stl  blk  tov   pf   pts     season  season_end  \n",
       "0     ...      144  216   28   23   26   30  122   171  2013-2014        2013  \n",
       "1     ...      190  332   43   40   57   71  203   265  2013-2014        2013  \n",
       "2     ...      204  306   38   24   36   39  108   362  2013-2014        2013  \n",
       "3     ...      230  262  248   35    3  146  136  1330  2013-2014        2013  \n",
       "4     ...      183  277   40   23   46   63  187   328  2013-2014        2013  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "nba = pd.read_csv('nba_2013.csv')\n",
    "print(nba.shape)\n",
    "nba.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visão geral da KNN**\n",
    "\n",
    "O algoritmo de k vizinhos mais próximos baseia-se na ideia simples de prever valores desconhecidos, combinando-os com os valores conhecidos mais semelhantes.\n",
    "\n",
    "Vamos dizer que temos 3 tipos diferentes de carros. Sabemos o nome do carro, sua potência, se tem listras ou não, e se é ou não rápido:\n",
    "\n",
    "    car,horsepower,racing_stripes,is_fast\n",
    "    Honda Accord,180,False,False\n",
    "    Yugo,500,True,True\n",
    "    Delorean DMC-12,200,True,True\n",
    "    \n",
    "Digamos que agora temos outro carro, mas não sabemos o quão rápido é:\n",
    "\n",
    "    car,horsepower,racing_stripes,is_fast\n",
    "    Chevrolet Camaro,400,True,Unknown\n",
    "    \n",
    "Queremos descobrir se o carro é rápido ou não. Para prever se é com k vizinhos mais próximos, primeiro encontramos o carro conhecido mais similar. Nesse caso, comparamos os valores horsepowere racing_stripespara encontrar o carro mais parecido, que é o Yugo. Como o Yugo é rápido, nós preveríamos que o Camaro também é rápido. Este é um exemplo de 1 vizinho mais próximo - nós olhamos apenas para o carro mais similar, dando-nos um k de 1.\n",
    "\n",
    "Se nós executássemos os 2 vizinhos mais próximos, acabaríamos com 2 Truevalores (para o Delorean e o Yugo), o que significaria média para True. O Delorean e Yugo são os dois carros mais parecidos, nos dando um k de 2.\n",
    "\n",
    "Se fizéssemos 3 vizinhos mais próximos, acabaríamos com 2 Truevalores e um Falsevalor, o que significaria média para True.\n",
    "\n",
    "O número de vizinhos que usamos para os k vizinhos mais próximos (k) pode ser qualquer valor menor que o número de linhas em nosso conjunto de dados. Na prática, observar apenas alguns vizinhos faz com que o algoritmo tenha um melhor desempenho, porque quanto menos semelhantes os vizinhos forem aos nossos dados, pior será a previsão."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Distância euclidiana**\n",
    "\n",
    "Antes de podermos prever usando o KNN, precisamos encontrar alguma maneira de descobrir quais linhas de dados estão \"mais próximas\" da linha que estamos tentando prever.\n",
    "\n",
    "<img src='img/347a4b535ffd805ffdf332e51905bcdf4764f663.svg'>\n",
    "\n",
    "Digamos que temos essas duas linhas e queremos encontrar a distância entre elas:\n",
    "\n",
    "    car,horsepower,is_fast\n",
    "    Honda Accord,180,0\n",
    "    Chevrolet Camaro,400,1\n",
    "    \n",
    "Primeiro, selecionamos apenas as colunas numéricas. Então a distância se torna:\n",
    "\n",
    "$\\sqrt {(400-180)^ 2 + (1-0)^2 } = 220$\n",
    "\n",
    "\n",
    "Podemos usar o princípio da distância euclidiana para encontrar os jogadores mais similares da NBA para **Lebron James**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleciona o mito\n",
    "selected_player = nba[nba[\"player\"] == \"LeBron James\"].iloc[0]\n",
    "\n",
    "# Escolhe as variáveis numéricas para calcularmos a distância.\n",
    "distance_columns = ['age', 'g', 'gs', 'mp', 'fg', 'fga', 'fg.', 'x3p', 'x3pa', 'x3p.', 'x2p', 'x2pa', 'x2p.', 'efg.', 'ft', 'fta', 'ft.', 'orb', 'drb', 'trb', 'ast', 'stl', 'blk', 'tov', 'pf', 'pts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def euclidean_distance(row):\n",
    "    inner_value=0\n",
    "    for k in distance_columns:\n",
    "        inner_value += (row[k] - selected_player[k]) ** 2\n",
    "    return math.sqrt(inner_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3475.792868\n",
       "1            NaN\n",
       "2            NaN\n",
       "3    1189.554979\n",
       "4    3216.773098\n",
       "5            NaN\n",
       "6     960.443178\n",
       "7    3131.071083\n",
       "8    2326.129199\n",
       "9    2806.955657\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculamos a distância de cada jogador em relação ao lebron\n",
    "lebron_distance = nba.apply(euclidean_distance, axis=1)\n",
    "lebron_distance[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Colunas de normalização**\n",
    "\n",
    "Você deve ter notado que horsepower no exemplo dos carros teve um impacto muito maior na distância final do que racing_stripes. Isso ocorre porque os valores para horsepower são muito maiores em termos absolutos e, portanto, diminuem o impacto dos racing_stripes nos cálculos de distâncias (no caso euclidiano).\n",
    "\n",
    "Isso pode ser ruim, porque uma variável com valores maiores não necessariamente melhora a previsão de quais linhas são semelhantes.\n",
    "\n",
    "Uma maneira simples de lidar com isso é normalizar todas as colunas para ter uma média de 0 e um desvio padrão de 1. Isso garantirá que nenhuma coluna individual tenha um impacto dominante nos cálculos de distância euclideana.\n",
    "\n",
    "Para definir a média como 0, temos que encontrar a média de uma coluna e, em seguida, subtrair a média de todos os valores da coluna. Para definir o desvio padrão para 1, dividimos todos os valores na coluna pelo desvio padrão. A fórmula é \n",
    "\n",
    "$$x_n = \\frac {x- \\mu} {\\sigma}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleciona variáveis numéricas\n",
    "nba_numeric = nba[distance_columns]\n",
    "\n",
    "# Normaliza\n",
    "nba_normalized = (nba_numeric - nba_numeric.mean()) / nba_numeric.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>g</th>\n",
       "      <th>gs</th>\n",
       "      <th>mp</th>\n",
       "      <th>fg</th>\n",
       "      <th>fga</th>\n",
       "      <th>fg.</th>\n",
       "      <th>x3p</th>\n",
       "      <th>x3pa</th>\n",
       "      <th>x3p.</th>\n",
       "      <th>...</th>\n",
       "      <th>ft.</th>\n",
       "      <th>orb</th>\n",
       "      <th>drb</th>\n",
       "      <th>trb</th>\n",
       "      <th>ast</th>\n",
       "      <th>stl</th>\n",
       "      <th>blk</th>\n",
       "      <th>tov</th>\n",
       "      <th>pf</th>\n",
       "      <th>pts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.012074</td>\n",
       "      <td>0.025163</td>\n",
       "      <td>0.007961</td>\n",
       "      <td>-0.009749</td>\n",
       "      <td>-0.018304</td>\n",
       "      <td>0.017929</td>\n",
       "      <td>0.050611</td>\n",
       "      <td>0.028850</td>\n",
       "      <td>0.012090</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005692</td>\n",
       "      <td>-0.068726</td>\n",
       "      <td>0.010822</td>\n",
       "      <td>-0.013451</td>\n",
       "      <td>0.019216</td>\n",
       "      <td>-0.028315</td>\n",
       "      <td>-0.017398</td>\n",
       "      <td>-0.030789</td>\n",
       "      <td>-0.028221</td>\n",
       "      <td>-0.011910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g</th>\n",
       "      <td>-0.012074</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.610951</td>\n",
       "      <td>0.864487</td>\n",
       "      <td>0.739993</td>\n",
       "      <td>0.746963</td>\n",
       "      <td>0.342499</td>\n",
       "      <td>0.518074</td>\n",
       "      <td>0.537011</td>\n",
       "      <td>0.243597</td>\n",
       "      <td>...</td>\n",
       "      <td>0.440999</td>\n",
       "      <td>0.546902</td>\n",
       "      <td>0.707389</td>\n",
       "      <td>0.682688</td>\n",
       "      <td>0.551128</td>\n",
       "      <td>0.709650</td>\n",
       "      <td>0.475581</td>\n",
       "      <td>0.713508</td>\n",
       "      <td>0.865797</td>\n",
       "      <td>0.728462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gs</th>\n",
       "      <td>0.025163</td>\n",
       "      <td>0.610951</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.860036</td>\n",
       "      <td>0.821619</td>\n",
       "      <td>0.811531</td>\n",
       "      <td>0.240620</td>\n",
       "      <td>0.501808</td>\n",
       "      <td>0.515718</td>\n",
       "      <td>0.162971</td>\n",
       "      <td>...</td>\n",
       "      <td>0.249641</td>\n",
       "      <td>0.560067</td>\n",
       "      <td>0.774892</td>\n",
       "      <td>0.735738</td>\n",
       "      <td>0.636059</td>\n",
       "      <td>0.743178</td>\n",
       "      <td>0.505589</td>\n",
       "      <td>0.767107</td>\n",
       "      <td>0.725573</td>\n",
       "      <td>0.810294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mp</th>\n",
       "      <td>0.007961</td>\n",
       "      <td>0.864487</td>\n",
       "      <td>0.860036</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.931120</td>\n",
       "      <td>0.936883</td>\n",
       "      <td>0.286372</td>\n",
       "      <td>0.645056</td>\n",
       "      <td>0.666126</td>\n",
       "      <td>0.276297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.386839</td>\n",
       "      <td>0.576844</td>\n",
       "      <td>0.821145</td>\n",
       "      <td>0.774492</td>\n",
       "      <td>0.733041</td>\n",
       "      <td>0.852331</td>\n",
       "      <td>0.506254</td>\n",
       "      <td>0.885406</td>\n",
       "      <td>0.884484</td>\n",
       "      <td>0.927464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fg</th>\n",
       "      <td>-0.009749</td>\n",
       "      <td>0.739993</td>\n",
       "      <td>0.821619</td>\n",
       "      <td>0.931120</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988262</td>\n",
       "      <td>0.286553</td>\n",
       "      <td>0.597239</td>\n",
       "      <td>0.613988</td>\n",
       "      <td>0.239951</td>\n",
       "      <td>...</td>\n",
       "      <td>0.355072</td>\n",
       "      <td>0.562293</td>\n",
       "      <td>0.820259</td>\n",
       "      <td>0.769339</td>\n",
       "      <td>0.708228</td>\n",
       "      <td>0.786597</td>\n",
       "      <td>0.484208</td>\n",
       "      <td>0.903383</td>\n",
       "      <td>0.798769</td>\n",
       "      <td>0.992041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fga</th>\n",
       "      <td>-0.018304</td>\n",
       "      <td>0.746963</td>\n",
       "      <td>0.811531</td>\n",
       "      <td>0.936883</td>\n",
       "      <td>0.988262</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.222932</td>\n",
       "      <td>0.662004</td>\n",
       "      <td>0.685535</td>\n",
       "      <td>0.289914</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382954</td>\n",
       "      <td>0.487154</td>\n",
       "      <td>0.771821</td>\n",
       "      <td>0.710910</td>\n",
       "      <td>0.748141</td>\n",
       "      <td>0.803290</td>\n",
       "      <td>0.412738</td>\n",
       "      <td>0.910689</td>\n",
       "      <td>0.786560</td>\n",
       "      <td>0.989211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fg.</th>\n",
       "      <td>0.017929</td>\n",
       "      <td>0.342499</td>\n",
       "      <td>0.240620</td>\n",
       "      <td>0.286372</td>\n",
       "      <td>0.286553</td>\n",
       "      <td>0.222932</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.010666</td>\n",
       "      <td>-0.025327</td>\n",
       "      <td>-0.082476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.184496</td>\n",
       "      <td>0.422362</td>\n",
       "      <td>0.381352</td>\n",
       "      <td>0.407564</td>\n",
       "      <td>0.080506</td>\n",
       "      <td>0.197596</td>\n",
       "      <td>0.399377</td>\n",
       "      <td>0.232955</td>\n",
       "      <td>0.370017</td>\n",
       "      <td>0.257634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x3p</th>\n",
       "      <td>0.050611</td>\n",
       "      <td>0.518074</td>\n",
       "      <td>0.501808</td>\n",
       "      <td>0.645056</td>\n",
       "      <td>0.597239</td>\n",
       "      <td>0.662004</td>\n",
       "      <td>-0.010666</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991700</td>\n",
       "      <td>0.539664</td>\n",
       "      <td>...</td>\n",
       "      <td>0.374845</td>\n",
       "      <td>-0.065822</td>\n",
       "      <td>0.280171</td>\n",
       "      <td>0.182848</td>\n",
       "      <td>0.617553</td>\n",
       "      <td>0.592092</td>\n",
       "      <td>-0.043707</td>\n",
       "      <td>0.560520</td>\n",
       "      <td>0.446711</td>\n",
       "      <td>0.655342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x3pa</th>\n",
       "      <td>0.028850</td>\n",
       "      <td>0.537011</td>\n",
       "      <td>0.515718</td>\n",
       "      <td>0.666126</td>\n",
       "      <td>0.613988</td>\n",
       "      <td>0.685535</td>\n",
       "      <td>-0.025327</td>\n",
       "      <td>0.991700</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.538397</td>\n",
       "      <td>...</td>\n",
       "      <td>0.381336</td>\n",
       "      <td>-0.058075</td>\n",
       "      <td>0.291838</td>\n",
       "      <td>0.193712</td>\n",
       "      <td>0.643211</td>\n",
       "      <td>0.622973</td>\n",
       "      <td>-0.040987</td>\n",
       "      <td>0.589799</td>\n",
       "      <td>0.463455</td>\n",
       "      <td>0.672076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x3p.</th>\n",
       "      <td>0.012090</td>\n",
       "      <td>0.243597</td>\n",
       "      <td>0.162971</td>\n",
       "      <td>0.276297</td>\n",
       "      <td>0.239951</td>\n",
       "      <td>0.289914</td>\n",
       "      <td>-0.082476</td>\n",
       "      <td>0.539664</td>\n",
       "      <td>0.538397</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.346851</td>\n",
       "      <td>-0.235295</td>\n",
       "      <td>0.012785</td>\n",
       "      <td>-0.063656</td>\n",
       "      <td>0.330362</td>\n",
       "      <td>0.288919</td>\n",
       "      <td>-0.147881</td>\n",
       "      <td>0.230831</td>\n",
       "      <td>0.105314</td>\n",
       "      <td>0.272773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2p</th>\n",
       "      <td>-0.028862</td>\n",
       "      <td>0.684729</td>\n",
       "      <td>0.785619</td>\n",
       "      <td>0.863941</td>\n",
       "      <td>0.960853</td>\n",
       "      <td>0.924781</td>\n",
       "      <td>0.338137</td>\n",
       "      <td>0.351640</td>\n",
       "      <td>0.374057</td>\n",
       "      <td>0.093644</td>\n",
       "      <td>...</td>\n",
       "      <td>0.284942</td>\n",
       "      <td>0.679022</td>\n",
       "      <td>0.860592</td>\n",
       "      <td>0.834779</td>\n",
       "      <td>0.613292</td>\n",
       "      <td>0.713556</td>\n",
       "      <td>0.580246</td>\n",
       "      <td>0.860769</td>\n",
       "      <td>0.777982</td>\n",
       "      <td>0.931493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2pa</th>\n",
       "      <td>-0.035970</td>\n",
       "      <td>0.694243</td>\n",
       "      <td>0.784812</td>\n",
       "      <td>0.874109</td>\n",
       "      <td>0.962059</td>\n",
       "      <td>0.944490</td>\n",
       "      <td>0.290952</td>\n",
       "      <td>0.382531</td>\n",
       "      <td>0.408290</td>\n",
       "      <td>0.120546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.308082</td>\n",
       "      <td>0.637025</td>\n",
       "      <td>0.836051</td>\n",
       "      <td>0.803959</td>\n",
       "      <td>0.647796</td>\n",
       "      <td>0.726077</td>\n",
       "      <td>0.536007</td>\n",
       "      <td>0.875709</td>\n",
       "      <td>0.777085</td>\n",
       "      <td>0.937036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2p.</th>\n",
       "      <td>-0.009250</td>\n",
       "      <td>0.315076</td>\n",
       "      <td>0.215888</td>\n",
       "      <td>0.264127</td>\n",
       "      <td>0.253483</td>\n",
       "      <td>0.204324</td>\n",
       "      <td>0.866809</td>\n",
       "      <td>0.059374</td>\n",
       "      <td>0.061420</td>\n",
       "      <td>-0.077821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156399</td>\n",
       "      <td>0.318834</td>\n",
       "      <td>0.313951</td>\n",
       "      <td>0.326578</td>\n",
       "      <td>0.087729</td>\n",
       "      <td>0.203885</td>\n",
       "      <td>0.305917</td>\n",
       "      <td>0.207074</td>\n",
       "      <td>0.317260</td>\n",
       "      <td>0.234833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>efg.</th>\n",
       "      <td>0.062808</td>\n",
       "      <td>0.371362</td>\n",
       "      <td>0.236999</td>\n",
       "      <td>0.316093</td>\n",
       "      <td>0.286020</td>\n",
       "      <td>0.247632</td>\n",
       "      <td>0.916108</td>\n",
       "      <td>0.224392</td>\n",
       "      <td>0.203220</td>\n",
       "      <td>0.214500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.290915</td>\n",
       "      <td>0.266327</td>\n",
       "      <td>0.306291</td>\n",
       "      <td>0.304747</td>\n",
       "      <td>0.141244</td>\n",
       "      <td>0.239572</td>\n",
       "      <td>0.270028</td>\n",
       "      <td>0.227944</td>\n",
       "      <td>0.341637</td>\n",
       "      <td>0.277257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ft</th>\n",
       "      <td>-0.046554</td>\n",
       "      <td>0.598333</td>\n",
       "      <td>0.707049</td>\n",
       "      <td>0.805468</td>\n",
       "      <td>0.893619</td>\n",
       "      <td>0.887922</td>\n",
       "      <td>0.224380</td>\n",
       "      <td>0.503353</td>\n",
       "      <td>0.527835</td>\n",
       "      <td>0.177594</td>\n",
       "      <td>...</td>\n",
       "      <td>0.320348</td>\n",
       "      <td>0.462211</td>\n",
       "      <td>0.704035</td>\n",
       "      <td>0.654005</td>\n",
       "      <td>0.699452</td>\n",
       "      <td>0.720571</td>\n",
       "      <td>0.383611</td>\n",
       "      <td>0.872003</td>\n",
       "      <td>0.663557</td>\n",
       "      <td>0.927618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fta</th>\n",
       "      <td>-0.061751</td>\n",
       "      <td>0.615001</td>\n",
       "      <td>0.720527</td>\n",
       "      <td>0.814450</td>\n",
       "      <td>0.895138</td>\n",
       "      <td>0.877945</td>\n",
       "      <td>0.264500</td>\n",
       "      <td>0.441246</td>\n",
       "      <td>0.467615</td>\n",
       "      <td>0.132361</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274953</td>\n",
       "      <td>0.544659</td>\n",
       "      <td>0.757296</td>\n",
       "      <td>0.718198</td>\n",
       "      <td>0.670307</td>\n",
       "      <td>0.727189</td>\n",
       "      <td>0.456063</td>\n",
       "      <td>0.877715</td>\n",
       "      <td>0.698489</td>\n",
       "      <td>0.918979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ft.</th>\n",
       "      <td>0.005692</td>\n",
       "      <td>0.440999</td>\n",
       "      <td>0.249641</td>\n",
       "      <td>0.386839</td>\n",
       "      <td>0.355072</td>\n",
       "      <td>0.382954</td>\n",
       "      <td>0.184496</td>\n",
       "      <td>0.374845</td>\n",
       "      <td>0.381336</td>\n",
       "      <td>0.346851</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.089972</td>\n",
       "      <td>0.222364</td>\n",
       "      <td>0.189201</td>\n",
       "      <td>0.320851</td>\n",
       "      <td>0.314448</td>\n",
       "      <td>0.059168</td>\n",
       "      <td>0.336330</td>\n",
       "      <td>0.332948</td>\n",
       "      <td>0.370515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>orb</th>\n",
       "      <td>-0.068726</td>\n",
       "      <td>0.546902</td>\n",
       "      <td>0.560067</td>\n",
       "      <td>0.576844</td>\n",
       "      <td>0.562293</td>\n",
       "      <td>0.487154</td>\n",
       "      <td>0.422362</td>\n",
       "      <td>-0.065822</td>\n",
       "      <td>-0.058075</td>\n",
       "      <td>-0.235295</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089972</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.839774</td>\n",
       "      <td>0.919166</td>\n",
       "      <td>0.142708</td>\n",
       "      <td>0.386100</td>\n",
       "      <td>0.782384</td>\n",
       "      <td>0.468581</td>\n",
       "      <td>0.713271</td>\n",
       "      <td>0.505524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drb</th>\n",
       "      <td>0.010822</td>\n",
       "      <td>0.707389</td>\n",
       "      <td>0.774892</td>\n",
       "      <td>0.821145</td>\n",
       "      <td>0.820259</td>\n",
       "      <td>0.771821</td>\n",
       "      <td>0.381352</td>\n",
       "      <td>0.280171</td>\n",
       "      <td>0.291838</td>\n",
       "      <td>0.012785</td>\n",
       "      <td>...</td>\n",
       "      <td>0.222364</td>\n",
       "      <td>0.839774</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985738</td>\n",
       "      <td>0.448866</td>\n",
       "      <td>0.631805</td>\n",
       "      <td>0.740026</td>\n",
       "      <td>0.736415</td>\n",
       "      <td>0.821327</td>\n",
       "      <td>0.784675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trb</th>\n",
       "      <td>-0.013451</td>\n",
       "      <td>0.682688</td>\n",
       "      <td>0.735738</td>\n",
       "      <td>0.774492</td>\n",
       "      <td>0.769339</td>\n",
       "      <td>0.710910</td>\n",
       "      <td>0.407564</td>\n",
       "      <td>0.182848</td>\n",
       "      <td>0.193712</td>\n",
       "      <td>-0.063656</td>\n",
       "      <td>...</td>\n",
       "      <td>0.189201</td>\n",
       "      <td>0.919166</td>\n",
       "      <td>0.985738</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.369862</td>\n",
       "      <td>0.578014</td>\n",
       "      <td>0.779353</td>\n",
       "      <td>0.679468</td>\n",
       "      <td>0.816910</td>\n",
       "      <td>0.725930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ast</th>\n",
       "      <td>0.019216</td>\n",
       "      <td>0.551128</td>\n",
       "      <td>0.636059</td>\n",
       "      <td>0.733041</td>\n",
       "      <td>0.708228</td>\n",
       "      <td>0.748141</td>\n",
       "      <td>0.080506</td>\n",
       "      <td>0.617553</td>\n",
       "      <td>0.643211</td>\n",
       "      <td>0.330362</td>\n",
       "      <td>...</td>\n",
       "      <td>0.320851</td>\n",
       "      <td>0.142708</td>\n",
       "      <td>0.448866</td>\n",
       "      <td>0.369862</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.770428</td>\n",
       "      <td>0.104589</td>\n",
       "      <td>0.855144</td>\n",
       "      <td>0.538109</td>\n",
       "      <td>0.738295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stl</th>\n",
       "      <td>-0.028315</td>\n",
       "      <td>0.709650</td>\n",
       "      <td>0.743178</td>\n",
       "      <td>0.852331</td>\n",
       "      <td>0.786597</td>\n",
       "      <td>0.803290</td>\n",
       "      <td>0.197596</td>\n",
       "      <td>0.592092</td>\n",
       "      <td>0.622973</td>\n",
       "      <td>0.288919</td>\n",
       "      <td>...</td>\n",
       "      <td>0.314448</td>\n",
       "      <td>0.386100</td>\n",
       "      <td>0.631805</td>\n",
       "      <td>0.578014</td>\n",
       "      <td>0.770428</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.317737</td>\n",
       "      <td>0.826865</td>\n",
       "      <td>0.737628</td>\n",
       "      <td>0.797449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blk</th>\n",
       "      <td>-0.017398</td>\n",
       "      <td>0.475581</td>\n",
       "      <td>0.505589</td>\n",
       "      <td>0.506254</td>\n",
       "      <td>0.484208</td>\n",
       "      <td>0.412738</td>\n",
       "      <td>0.399377</td>\n",
       "      <td>-0.043707</td>\n",
       "      <td>-0.040987</td>\n",
       "      <td>-0.147881</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059168</td>\n",
       "      <td>0.782384</td>\n",
       "      <td>0.740026</td>\n",
       "      <td>0.779353</td>\n",
       "      <td>0.104589</td>\n",
       "      <td>0.317737</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.396247</td>\n",
       "      <td>0.633609</td>\n",
       "      <td>0.433549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tov</th>\n",
       "      <td>-0.030789</td>\n",
       "      <td>0.713508</td>\n",
       "      <td>0.767107</td>\n",
       "      <td>0.885406</td>\n",
       "      <td>0.903383</td>\n",
       "      <td>0.910689</td>\n",
       "      <td>0.232955</td>\n",
       "      <td>0.560520</td>\n",
       "      <td>0.589799</td>\n",
       "      <td>0.230831</td>\n",
       "      <td>...</td>\n",
       "      <td>0.336330</td>\n",
       "      <td>0.468581</td>\n",
       "      <td>0.736415</td>\n",
       "      <td>0.679468</td>\n",
       "      <td>0.855144</td>\n",
       "      <td>0.826865</td>\n",
       "      <td>0.396247</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.775430</td>\n",
       "      <td>0.912724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pf</th>\n",
       "      <td>-0.028221</td>\n",
       "      <td>0.865797</td>\n",
       "      <td>0.725573</td>\n",
       "      <td>0.884484</td>\n",
       "      <td>0.798769</td>\n",
       "      <td>0.786560</td>\n",
       "      <td>0.370017</td>\n",
       "      <td>0.446711</td>\n",
       "      <td>0.463455</td>\n",
       "      <td>0.105314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.332948</td>\n",
       "      <td>0.713271</td>\n",
       "      <td>0.821327</td>\n",
       "      <td>0.816910</td>\n",
       "      <td>0.538109</td>\n",
       "      <td>0.737628</td>\n",
       "      <td>0.633609</td>\n",
       "      <td>0.775430</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.778060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pts</th>\n",
       "      <td>-0.011910</td>\n",
       "      <td>0.728462</td>\n",
       "      <td>0.810294</td>\n",
       "      <td>0.927464</td>\n",
       "      <td>0.992041</td>\n",
       "      <td>0.989211</td>\n",
       "      <td>0.257634</td>\n",
       "      <td>0.655342</td>\n",
       "      <td>0.672076</td>\n",
       "      <td>0.272773</td>\n",
       "      <td>...</td>\n",
       "      <td>0.370515</td>\n",
       "      <td>0.505524</td>\n",
       "      <td>0.784675</td>\n",
       "      <td>0.725930</td>\n",
       "      <td>0.738295</td>\n",
       "      <td>0.797449</td>\n",
       "      <td>0.433549</td>\n",
       "      <td>0.912724</td>\n",
       "      <td>0.778060</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           age         g        gs        mp        fg       fga       fg.  \\\n",
       "age   1.000000 -0.012074  0.025163  0.007961 -0.009749 -0.018304  0.017929   \n",
       "g    -0.012074  1.000000  0.610951  0.864487  0.739993  0.746963  0.342499   \n",
       "gs    0.025163  0.610951  1.000000  0.860036  0.821619  0.811531  0.240620   \n",
       "mp    0.007961  0.864487  0.860036  1.000000  0.931120  0.936883  0.286372   \n",
       "fg   -0.009749  0.739993  0.821619  0.931120  1.000000  0.988262  0.286553   \n",
       "fga  -0.018304  0.746963  0.811531  0.936883  0.988262  1.000000  0.222932   \n",
       "fg.   0.017929  0.342499  0.240620  0.286372  0.286553  0.222932  1.000000   \n",
       "x3p   0.050611  0.518074  0.501808  0.645056  0.597239  0.662004 -0.010666   \n",
       "x3pa  0.028850  0.537011  0.515718  0.666126  0.613988  0.685535 -0.025327   \n",
       "x3p.  0.012090  0.243597  0.162971  0.276297  0.239951  0.289914 -0.082476   \n",
       "x2p  -0.028862  0.684729  0.785619  0.863941  0.960853  0.924781  0.338137   \n",
       "x2pa -0.035970  0.694243  0.784812  0.874109  0.962059  0.944490  0.290952   \n",
       "x2p. -0.009250  0.315076  0.215888  0.264127  0.253483  0.204324  0.866809   \n",
       "efg.  0.062808  0.371362  0.236999  0.316093  0.286020  0.247632  0.916108   \n",
       "ft   -0.046554  0.598333  0.707049  0.805468  0.893619  0.887922  0.224380   \n",
       "fta  -0.061751  0.615001  0.720527  0.814450  0.895138  0.877945  0.264500   \n",
       "ft.   0.005692  0.440999  0.249641  0.386839  0.355072  0.382954  0.184496   \n",
       "orb  -0.068726  0.546902  0.560067  0.576844  0.562293  0.487154  0.422362   \n",
       "drb   0.010822  0.707389  0.774892  0.821145  0.820259  0.771821  0.381352   \n",
       "trb  -0.013451  0.682688  0.735738  0.774492  0.769339  0.710910  0.407564   \n",
       "ast   0.019216  0.551128  0.636059  0.733041  0.708228  0.748141  0.080506   \n",
       "stl  -0.028315  0.709650  0.743178  0.852331  0.786597  0.803290  0.197596   \n",
       "blk  -0.017398  0.475581  0.505589  0.506254  0.484208  0.412738  0.399377   \n",
       "tov  -0.030789  0.713508  0.767107  0.885406  0.903383  0.910689  0.232955   \n",
       "pf   -0.028221  0.865797  0.725573  0.884484  0.798769  0.786560  0.370017   \n",
       "pts  -0.011910  0.728462  0.810294  0.927464  0.992041  0.989211  0.257634   \n",
       "\n",
       "           x3p      x3pa      x3p.    ...          ft.       orb       drb  \\\n",
       "age   0.050611  0.028850  0.012090    ...     0.005692 -0.068726  0.010822   \n",
       "g     0.518074  0.537011  0.243597    ...     0.440999  0.546902  0.707389   \n",
       "gs    0.501808  0.515718  0.162971    ...     0.249641  0.560067  0.774892   \n",
       "mp    0.645056  0.666126  0.276297    ...     0.386839  0.576844  0.821145   \n",
       "fg    0.597239  0.613988  0.239951    ...     0.355072  0.562293  0.820259   \n",
       "fga   0.662004  0.685535  0.289914    ...     0.382954  0.487154  0.771821   \n",
       "fg.  -0.010666 -0.025327 -0.082476    ...     0.184496  0.422362  0.381352   \n",
       "x3p   1.000000  0.991700  0.539664    ...     0.374845 -0.065822  0.280171   \n",
       "x3pa  0.991700  1.000000  0.538397    ...     0.381336 -0.058075  0.291838   \n",
       "x3p.  0.539664  0.538397  1.000000    ...     0.346851 -0.235295  0.012785   \n",
       "x2p   0.351640  0.374057  0.093644    ...     0.284942  0.679022  0.860592   \n",
       "x2pa  0.382531  0.408290  0.120546    ...     0.308082  0.637025  0.836051   \n",
       "x2p.  0.059374  0.061420 -0.077821    ...     0.156399  0.318834  0.313951   \n",
       "efg.  0.224392  0.203220  0.214500    ...     0.290915  0.266327  0.306291   \n",
       "ft    0.503353  0.527835  0.177594    ...     0.320348  0.462211  0.704035   \n",
       "fta   0.441246  0.467615  0.132361    ...     0.274953  0.544659  0.757296   \n",
       "ft.   0.374845  0.381336  0.346851    ...     1.000000  0.089972  0.222364   \n",
       "orb  -0.065822 -0.058075 -0.235295    ...     0.089972  1.000000  0.839774   \n",
       "drb   0.280171  0.291838  0.012785    ...     0.222364  0.839774  1.000000   \n",
       "trb   0.182848  0.193712 -0.063656    ...     0.189201  0.919166  0.985738   \n",
       "ast   0.617553  0.643211  0.330362    ...     0.320851  0.142708  0.448866   \n",
       "stl   0.592092  0.622973  0.288919    ...     0.314448  0.386100  0.631805   \n",
       "blk  -0.043707 -0.040987 -0.147881    ...     0.059168  0.782384  0.740026   \n",
       "tov   0.560520  0.589799  0.230831    ...     0.336330  0.468581  0.736415   \n",
       "pf    0.446711  0.463455  0.105314    ...     0.332948  0.713271  0.821327   \n",
       "pts   0.655342  0.672076  0.272773    ...     0.370515  0.505524  0.784675   \n",
       "\n",
       "           trb       ast       stl       blk       tov        pf       pts  \n",
       "age  -0.013451  0.019216 -0.028315 -0.017398 -0.030789 -0.028221 -0.011910  \n",
       "g     0.682688  0.551128  0.709650  0.475581  0.713508  0.865797  0.728462  \n",
       "gs    0.735738  0.636059  0.743178  0.505589  0.767107  0.725573  0.810294  \n",
       "mp    0.774492  0.733041  0.852331  0.506254  0.885406  0.884484  0.927464  \n",
       "fg    0.769339  0.708228  0.786597  0.484208  0.903383  0.798769  0.992041  \n",
       "fga   0.710910  0.748141  0.803290  0.412738  0.910689  0.786560  0.989211  \n",
       "fg.   0.407564  0.080506  0.197596  0.399377  0.232955  0.370017  0.257634  \n",
       "x3p   0.182848  0.617553  0.592092 -0.043707  0.560520  0.446711  0.655342  \n",
       "x3pa  0.193712  0.643211  0.622973 -0.040987  0.589799  0.463455  0.672076  \n",
       "x3p. -0.063656  0.330362  0.288919 -0.147881  0.230831  0.105314  0.272773  \n",
       "x2p   0.834779  0.613292  0.713556  0.580246  0.860769  0.777982  0.931493  \n",
       "x2pa  0.803959  0.647796  0.726077  0.536007  0.875709  0.777085  0.937036  \n",
       "x2p.  0.326578  0.087729  0.203885  0.305917  0.207074  0.317260  0.234833  \n",
       "efg.  0.304747  0.141244  0.239572  0.270028  0.227944  0.341637  0.277257  \n",
       "ft    0.654005  0.699452  0.720571  0.383611  0.872003  0.663557  0.927618  \n",
       "fta   0.718198  0.670307  0.727189  0.456063  0.877715  0.698489  0.918979  \n",
       "ft.   0.189201  0.320851  0.314448  0.059168  0.336330  0.332948  0.370515  \n",
       "orb   0.919166  0.142708  0.386100  0.782384  0.468581  0.713271  0.505524  \n",
       "drb   0.985738  0.448866  0.631805  0.740026  0.736415  0.821327  0.784675  \n",
       "trb   1.000000  0.369862  0.578014  0.779353  0.679468  0.816910  0.725930  \n",
       "ast   0.369862  1.000000  0.770428  0.104589  0.855144  0.538109  0.738295  \n",
       "stl   0.578014  0.770428  1.000000  0.317737  0.826865  0.737628  0.797449  \n",
       "blk   0.779353  0.104589  0.317737  1.000000  0.396247  0.633609  0.433549  \n",
       "tov   0.679468  0.855144  0.826865  0.396247  1.000000  0.775430  0.912724  \n",
       "pf    0.816910  0.538109  0.737628  0.633609  0.775430  1.000000  0.778060  \n",
       "pts   0.725930  0.738295  0.797449  0.433549  0.912724  0.778060  1.000000  \n",
       "\n",
       "[26 rows x 26 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nba_numeric.fillna(0).corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Encontrando o vizinho mais próximo**\n",
    "\n",
    "Agora sabemos o suficiente para encontrar o vizinho mais próximo de uma determinada linha no conjunto de dados da NBA. Podemos usar a distance euclidean (função dentro da classe spatial do módulo scipy), uma maneira muito mais rápida de calcular a distância euclidiana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "# Primeiro vamos substituir todos os nulos por zero.\n",
    "nba_normalized.fillna(0, inplace=True)\n",
    "\n",
    "# Agora vamos selecionar a linha com os dados do lebron\n",
    "lebron_normalized = nba_normalized[nba[\"player\"] == \"LeBron James\"]\n",
    "\n",
    "# Agora calculamos a distância entre lembrom e os outros jogadores\n",
    "# Obs: Aqui usamos uma função implicita lambda:\n",
    "# https://medium.com/@otaviobn/entendendo-as-fun%C3%A7%C3%B5es-lambda-no-python-cbe3c5abb179\n",
    "euclidean_distances = nba_normalized.apply(lambda row: distance.euclidean(row, lebron_normalized), axis=1)\n",
    "\n",
    "# Passamos as distâncias calculadas para um dataframe.\n",
    "distance_frame = pd.DataFrame(data={\"dist\": euclidean_distances,\n",
    "                                    \"idx\": euclidean_distances.index})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora vamos ordenar os dados dos mais parecidos (menor distância) para os menos parecidos.\n",
    "distance_frame.sort_values(\"dist\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dist</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.171854</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>4.206786</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>4.382582</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>4.489928</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         dist  idx\n",
       "225  0.000000  225\n",
       "17   4.171854   17\n",
       "136  4.206786  136\n",
       "128  4.382582  128\n",
       "185  4.489928  185"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Carmelo Anthony'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_smallest = distance_frame.iloc[1][\"idx\"]\n",
    "most_similar_to_lebron = nba.loc[int(second_smallest)][\"player\"]\n",
    "most_similar_to_lebron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gerando conjuntos de treinamento e testes**\n",
    "\n",
    "Agora que sabemos como encontrar os vizinhos mais próximos, podemos fazer previsões em um conjunto de testes. Vamos tentar prever quantos pontos um jogador marcou usando os 5vizinhos mais próximos. Encontraremos os vizinhos usando todas as colunas numéricas no conjunto de dados para gerar pontuações de similaridade.\n",
    "\n",
    "Primeiro, temos que gerar conjuntos de teste e treinamento. Para fazer isso, usaremos amostragem aleatória. Iremos aleatoriamente o índice do nbadataframe e, em seguida, escolheremos as linhas usando os valores aleatoriamente aleatórios.\n",
    "\n",
    "Se não fizéssemos isso, acabaríamos prevendo e treinando no mesmo conjunto de dados, o que seria ótimo. Poderíamos fazer a validação cruzada também, o que seria um pouco melhor, mas um pouco mais complexo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colunas com nossas features (nossos Xs)\n",
    "x_columns = ['age', 'g', 'gs', 'mp', 'fg', 'fga', 'fg.', 'x3p', 'x3pa', 'x3p.', 'x2p', 'x2pa', 'x2p.', 'efg.', 'ft', 'fta', 'ft.', 'orb', 'drb', 'trb', 'ast', 'stl', 'blk', 'tov', 'pf']\n",
    "\n",
    "# Coluna com nosso target (nosso y)\n",
    "y_column = [\"pts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba = nba.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train / test -> método raiz:\n",
    "import random\n",
    "from numpy.random import permutation\n",
    "\n",
    "# Randomly shuffle the index of nba.\n",
    "random_indices = permutation(nba.index)\n",
    "\n",
    "# Set a cutoff for how many items we want in the test set (in this case 1/3 of the items)\n",
    "test_cutoff = math.floor(len(nba)/3)\n",
    "\n",
    "# Generate the test set by taking the first 1/3 of the randomly shuffled indices.\n",
    "test = nba.loc[random_indices[1:test_cutoff]]\n",
    "\n",
    "# Generate the train set with the rest of the data.\n",
    "train = nba.loc[random_indices[test_cutoff:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train / test -> método nutella:\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(nba[x_columns],\n",
    "                                                    nba['pts'],\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Usando sklearn para k vizinhos mais próximos**\n",
    "\n",
    "Em vez de ter que fazer tudo sozinhos, podemos usar a implementação de k-vizinhos mais próximos em scikit-learn. Aqui está a documentação (http://scikit-learn.org/stable/modules/neighbors.html). O KNN é um algoritmo bastante simples e genérico, ele é capaz de ser utilizado para problemas de classificação e regressão utilizando os mesmos métodos.\n",
    "\n",
    "O Sklearn realiza a descoberta de normalização e distância automaticamente e nos permite especificar quantos vizinhos queremos ver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Os mesmos passos de sempre ...\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Instânciamos o modelo em uma variável e passamos o parâmetro \n",
    "# de quantos vizinhos queremos\n",
    "# que o knn utilize para calcular as médias.\n",
    "knn = KNeighborsRegressor(n_neighbors=5)\n",
    "\n",
    "# \"Ajusta\" nosso modelo aos dados.\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Realizamos predições chamando a função predict do modelo treinado.\n",
    "yhat = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Métricas da regressão: https://medium.com/human-in-a-machine-world/mae-and-rmse-which-metric-is-better-e60ac3bde13d\n",
    "\n",
    "\n",
    "Mean squared error (**MSE**) = $\\displaystyle\\frac{1}{n}\\sum_{t=1}^{n}e_t^2$ \n",
    "\n",
    "\n",
    "Root mean squared error (**RMSE**) = $\\displaystyle\\sqrt{\\frac{1}{n}\\sum_{t=1}^{n}e_t^2}$\n",
    "\n",
    "\n",
    "Mean absolute error, (**MAE**) $\\displaystyle\\frac{1}{n}\\sum_{t=1}^{n}|e_t|$ \n",
    "\n",
    "\n",
    "Mean absolute percentage error (**MAPE**) = $\\displaystyle\\frac{100\\%}{n}\\sum_{t=1}^{n}\\left |\\frac{e_t}{y_t}\\right|$\\\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4080.6457931034474\n",
      "63.87993263227074\n"
     ]
    }
   ],
   "source": [
    "# Agora calculamos alguma métrica para ver o quanto estamos errando/acertando:\n",
    "mse = (((yhat - y_test) ** 2).sum()) / len(yhat)\n",
    "print(mse)\n",
    "\n",
    "rmse = math.sqrt((((yhat - y_test) ** 2).sum()) / len(yhat))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desafio para os Alunos:\n",
    "\n",
    "Treinar um algoritmo de classificação com KNN para prever a posição do jogador (coluna 'pos') através das caracteristicas em campo e responder, o que acontece com as métricas do algoritmo quando alteramos o hyperparametro n_neighbors. \n",
    "\n",
    "Plote F1 score para esses diferentes n_neighbors [1,2,5,10] e interprete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SG    109\n",
       "SF     99\n",
       "PF     96\n",
       "C      90\n",
       "PG     85\n",
       "G       1\n",
       "F       1\n",
       "Name: pos, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nba.pos.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nba' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-7496b79eff3a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnew_nba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnba\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mnba\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'G'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'F'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'nba' is not defined"
     ]
    }
   ],
   "source": [
    "new_nba = nba[~nba.pos.isin(['G','F'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SG    109\n",
       "SF     99\n",
       "PF     96\n",
       "C      90\n",
       "PG     85\n",
       "Name: pos, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_nba.pos.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_nba.drop(['pos', 'player','season', 'bref_team_id', 'player'], axis=1)\n",
    "y = new_nba['pos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "for k in range(1, 300, 1):\n",
    "    cls = KNeighborsClassifier(n_neighbors=k)\n",
    "    metrics.append(cross_val_score(cls, X, y, cv = 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.rename(columns={'index':'k'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['k'] = result['k'] +1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4399696651710331"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.drop(['k'], axis =1).mean(axis=1).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.404440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.413908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.419160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.439970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.429682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.416340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.403653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.417619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.427954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.413807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.413765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.427707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.423861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.429754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.421313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.436006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.425991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.427792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.425587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.429927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0.402463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>0.406994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>0.412993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>0.406116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0.402033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>0.395877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0.385542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0.368999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>0.368999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>0.375347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>270</td>\n",
       "      <td>0.220789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>271</td>\n",
       "      <td>0.214537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>272</td>\n",
       "      <td>0.210326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>273</td>\n",
       "      <td>0.210326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>274</td>\n",
       "      <td>0.218932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>275</td>\n",
       "      <td>0.216846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>276</td>\n",
       "      <td>0.221015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>277</td>\n",
       "      <td>0.212591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>278</td>\n",
       "      <td>0.210463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>279</td>\n",
       "      <td>0.208596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>280</td>\n",
       "      <td>0.206332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>281</td>\n",
       "      <td>0.206470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>282</td>\n",
       "      <td>0.206384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>283</td>\n",
       "      <td>0.210421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>284</td>\n",
       "      <td>0.216630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>285</td>\n",
       "      <td>0.214495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>286</td>\n",
       "      <td>0.212498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>287</td>\n",
       "      <td>0.214626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>288</td>\n",
       "      <td>0.216667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>289</td>\n",
       "      <td>0.216580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>290</td>\n",
       "      <td>0.212325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>291</td>\n",
       "      <td>0.212412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>292</td>\n",
       "      <td>0.210371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>293</td>\n",
       "      <td>0.214626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>294</td>\n",
       "      <td>0.216848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>295</td>\n",
       "      <td>0.212635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>296</td>\n",
       "      <td>0.214850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>297</td>\n",
       "      <td>0.212809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>298</td>\n",
       "      <td>0.210595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>299</td>\n",
       "      <td>0.208380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>299 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       k      mean\n",
       "0      1  0.404440\n",
       "1      2  0.413908\n",
       "2      3  0.419160\n",
       "3      4  0.439970\n",
       "4      5  0.429682\n",
       "5      6  0.416340\n",
       "6      7  0.403653\n",
       "7      8  0.417619\n",
       "8      9  0.427954\n",
       "9     10  0.413807\n",
       "10    11  0.413765\n",
       "11    12  0.427707\n",
       "12    13  0.423861\n",
       "13    14  0.429754\n",
       "14    15  0.421313\n",
       "15    16  0.436006\n",
       "16    17  0.425991\n",
       "17    18  0.427792\n",
       "18    19  0.425587\n",
       "19    20  0.429927\n",
       "20    21  0.402463\n",
       "21    22  0.406994\n",
       "22    23  0.412993\n",
       "23    24  0.406116\n",
       "24    25  0.402033\n",
       "25    26  0.395877\n",
       "26    27  0.385542\n",
       "27    28  0.368999\n",
       "28    29  0.368999\n",
       "29    30  0.375347\n",
       "..   ...       ...\n",
       "269  270  0.220789\n",
       "270  271  0.214537\n",
       "271  272  0.210326\n",
       "272  273  0.210326\n",
       "273  274  0.218932\n",
       "274  275  0.216846\n",
       "275  276  0.221015\n",
       "276  277  0.212591\n",
       "277  278  0.210463\n",
       "278  279  0.208596\n",
       "279  280  0.206332\n",
       "280  281  0.206470\n",
       "281  282  0.206384\n",
       "282  283  0.210421\n",
       "283  284  0.216630\n",
       "284  285  0.214495\n",
       "285  286  0.212498\n",
       "286  287  0.214626\n",
       "287  288  0.216667\n",
       "288  289  0.216580\n",
       "289  290  0.212325\n",
       "290  291  0.212412\n",
       "291  292  0.210371\n",
       "292  293  0.214626\n",
       "293  294  0.216848\n",
       "294  295  0.212635\n",
       "295  296  0.214850\n",
       "296  297  0.212809\n",
       "297  298  0.210595\n",
       "298  299  0.208380\n",
       "\n",
       "[299 rows x 2 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['mean'] = result.drop(['k'], axis =1).mean(axis=1)\n",
    "result[['k','mean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_k = result['mean'] == result.drop(['k'], axis =1).mean(axis=1).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[best_k]['k'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1aea4c01828>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(metrics).mean(axis=1).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
