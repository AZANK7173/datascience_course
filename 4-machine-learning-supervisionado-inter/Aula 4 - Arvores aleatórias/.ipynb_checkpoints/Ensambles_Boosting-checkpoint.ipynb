{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRÁTICA GUIADA 2: Classificadores Ada Boost e Gradient Boosting\n",
    "\n",
    "\n",
    "## 1. Introdução\n",
    "\n",
    "O objetivo desta prática é começar a nos aproximar do uso e da avaliação dos métodos do algoritmo de Boosting.\n",
    "\n",
    "Lembrem: \n",
    "\n",
    "* A ideia fundamental dos algoritmos baseados na noção de boosting é tentar combinar muitos classificadores fracos em um classificador forte. \n",
    "\n",
    "* A principal diferença em relação aos métodos de Bagging é a forma com que o ensemble é construído: Boosting tenta melhorar o desempenho concentrando-se de alguma forma nos casos com o maior erro de treinamento.\n",
    "\n",
    "### `AdaBoostClassifier()`\n",
    "\n",
    "A ideia central de AdaBoost é construir um ensemble de week learners e, em cada iteração, aumentar o peso dos casos classificados incorretamente. A implementação do Scikit-Learn usa os seguintes parâmetros:\n",
    "\n",
    "* `base_estimator`: análogo ao caso de `BaggingClassifier()`, o estimador sobre o qual o ensemble será construído. Por padrão, são árvores de decisão.\n",
    "* `n_estimators`: o máximo de iterações\n",
    "* `learning_rate`: o peso que a previsão de cada árvore terá no ensemble final\n",
    "\n",
    "\n",
    "### `GradientBoostingClassifier()`\n",
    "\n",
    "É uma generalização do algoritmo geral de Boosting para qualquer tipo de função de perda diferenciavel. Em cada estágio, uma árvore de decisão é ajustada, mas isso é realizado sobre os resíduos da árvore anterior. Ou seja, procuramos corrigir as estimativas treinando novos classificadores sobre os \"resíduos\" (a diferença entre o valor observado e o valor previsto ($y - \\hat{y}$)\n",
    "\n",
    "Os argumentos usados como entrada já são conhecidos:\n",
    "\n",
    "* `learning_rate`: o peso que a previsão de cada árvore terá no ensemble final\n",
    "\n",
    "* `n_estimators`: o máximo de iterações\n",
    "* `criterion`: define o critério de impureza para avaliar a qualidade das partições\n",
    "* `max_features`: a quantidade de recursos extraídos para treinar cada `base_estimator`. Por padrão, é igual a `sqrt(X.shape[1])`\n",
    "* `bootstrap` e `bootstrap_features`: controla se tanto os n_samples como os recursos são extraídos com reposição.\n",
    "* `max_depth`: a profundidade máxima da árvore\n",
    "* `min_samples_leaf`: o número mínimo de n_samples para constituir uma folha da árvore (nó terminal)\n",
    "* `min_samples_split`: o número mínimo de n_samples para realizar um split.\n",
    "\n",
    "Como ponto de partida, usaremos o mesmo código utilizado anteriormente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('cars.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "y = LabelEncoder().fit_transform(df['acceptability'])\n",
    "X = pd.get_dummies(df.drop('acceptability', axis=1), drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score,StratifiedKFold\n",
    "cv = StratifiedKFold(n_splits=3, random_state=41, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos inicializar o classificador da árvore de decisão e avaliar seu desempenho:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desempenho de Árvore de decisão:\t0.899 ± 0.01\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def avaliar_desempenho(modelo, nome):\n",
    "    s = cross_val_score(modelo, X, y, cv=cv, n_jobs=-1)\n",
    "    print(\"Desempenho de {}:\\t{:0.3} ± {:0.3}\".format( \\\n",
    "        nome, s.mean().round(3), s.std().round(3)))\n",
    "    \n",
    "    \n",
    "dt = DecisionTreeClassifier(class_weight='balanced')\n",
    "\n",
    "avaliar_desempenho(dt,\"Árvore de decisão\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, avaliar os seguintes classificadores:\n",
    " * AdaBoostClassifier\n",
    " * GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desempenho de AdaBoostClassifier:\t0.845 ± 0.01\n",
      "Desempenho de GradientBoostingClassifier:\t0.955 ± 0.011\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "ab = AdaBoostClassifier()\n",
    "gb = GradientBoostingClassifier()\n",
    "avaliar_desempenho(ab, \"AdaBoostClassifier\")\n",
    "avaliar_desempenho(gb, \"GradientBoostingClassifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Portanto, é possível ver que AdaBoost tem um desempenho muito pior (pelo menos usando os parâmetros padrão). Desse modo, poderíamos tentar otimizar os hiperparâmetros para fazer com que funcionem melhor."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
