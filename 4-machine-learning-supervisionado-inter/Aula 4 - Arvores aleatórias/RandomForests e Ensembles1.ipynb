{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRÁTICA GUIADA: Random Forest e ExtraTrees no Scikit Learn\n",
    "\n",
    "## 1. Introdução\n",
    "Nesta prática, vamos comparar o desempenho dos seguintes algoritmos:\n",
    "\n",
    "-Árvores de decisão\n",
    "-Bagging sobre Árvores de decisão\n",
    "-Random Forest\n",
    "-Extra Trees\n",
    "\n",
    "\n",
    "Introdução aos métodos de combinação de modelos simples:\n",
    "\n",
    "Todos os três são os chamados \"meta-algoritmos\": abordagens para combinar várias técnicas de aprendizado de máquina em um modelo preditivo, a fim de diminuir a variância (Bagging), o viés (boosting) ou melhorar a força preditiva (stacking).\n",
    "\n",
    "Todo algoritmo consiste em duas etapas:\n",
    "\n",
    "Produzir uma distribuição de modelos ML simples em subconjuntos dos dados originais.\n",
    "\n",
    "Combinando a distribuição em um modelo \"agregado\".\n",
    "\n",
    "Aqui está uma breve descrição de todos os três métodos:\n",
    "\n",
    "**Bagging** (que significa **B**ootstrap **Agg**regat **ing** ) é uma maneira de diminuir a variância de sua previsão, gerando dados adicionais para formação do conjunto de dados original usando combinações com repetições para produzir multisets da mesma cardinalidade / tamanho de seus dados originais. Ao aumentar o tamanho do seu conjunto de treinamento, você não pode melhorar a força preditiva do modelo, mas apenas diminuir a variação, ajustando a previsão ao resultado esperado.\n",
    "\n",
    "https://www.youtube.com/watch?v=sVriC_Ys2cw\n",
    "\n",
    "\n",
    "**Boosting** é uma abordagem em duas etapas, em que primeiro usamos subconjuntos dos dados originais para produzir uma série de modelos de desempenho médio e, em seguida, \"impulsionamos\" seu desempenho combinando-os usando uma função de custo específica (por exemplo voto majoritário). Diferentemente do bagging, no boosting clássico, a criação do subconjunto não é aleatória e depende do desempenho dos modelos anteriores: cada novo subconjunto contém os elementos que (provavelmente seriam) incorretamente classificados pelos modelos anteriores.\n",
    "\n",
    "O **stacking** é semelhante ao boosting: você também aplica vários modelos aos dados originais. A diferença aqui é, no entanto, que você não tem apenas uma fórmula para a sua função de custo, mas introduz um meta-nível e usa outro modelo/abordagem para estimar a entrada junto com as saídas de cada modelo para estimar os pesos ou, em outras palavras, para determinar quais modelos têm um bom desempenho e o que mal recebem esses dados de entrada. O pacote em python, MLENS, ajuda a implementar esse tipo de método que pode se tornar bastante complexo.\n",
    "\n",
    "Aqui está uma tabela de comparação:\n",
    "\n",
    "<img src='img/RFfqb.png'>\n",
    "\n",
    "Como você vê, todas essas abordagens são diferentes para combinar vários modelos em um melhor, e não há um único vencedor aqui: tudo depende do seu domínio e do que você vai fazer. Você ainda pode tratar o stacking como uma espécie de boosting com um passo a mais, no entanto, a dificuldade de encontrar uma boa abordagem para o seu meta-nível dificulta a aplicação dessa abordagem na prática.\n",
    "\n",
    "\n",
    "Na aula de hoje estamos interessados apenas em Bagging.\n",
    "\n",
    "Vamos lá."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "buying           object\n",
       "maint            object\n",
       "doors            object\n",
       "persons          object\n",
       "lug_boot         object\n",
       "safety           object\n",
       "acceptability    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('cars.csv')\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desta vez, vamos codificar as características usando um esquema de codificação One Hot, isto é, vamos considerá-las como variáveis categóricas. Também vamos codificar o target usando o `LabelEncoder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>acceptability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  buying  maint doors persons lug_boot safety acceptability\n",
       "0  vhigh  vhigh     2       2    small    low         unacc\n",
       "1  vhigh  vhigh     2       2    small    med         unacc\n",
       "2  vhigh  vhigh     2       2    small   high         unacc\n",
       "3  vhigh  vhigh     2       2      med    low         unacc\n",
       "4  vhigh  vhigh     2       2      med    med         unacc"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
    "\n",
    "lab_enc = LabelEncoder()\n",
    "lab_enc.fit(df['acceptability'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying_high</th>\n",
       "      <th>buying_low</th>\n",
       "      <th>buying_med</th>\n",
       "      <th>buying_vhigh</th>\n",
       "      <th>maint_high</th>\n",
       "      <th>maint_low</th>\n",
       "      <th>maint_med</th>\n",
       "      <th>maint_vhigh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   buying_high  buying_low  buying_med  buying_vhigh  maint_high  maint_low  \\\n",
       "0            0           0           0             1           0          0   \n",
       "1            0           0           0             1           0          0   \n",
       "2            0           0           0             1           0          0   \n",
       "3            0           0           0             1           0          0   \n",
       "4            0           0           0             1           0          0   \n",
       "\n",
       "   maint_med  maint_vhigh  \n",
       "0          0            1  \n",
       "1          0            1  \n",
       "2          0            1  \n",
       "3          0            1  \n",
       "4          0            1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = lab_enc.transform(df['acceptability'])\n",
    "X = pd.get_dummies(df.drop('acceptability', axis=1))\n",
    "\n",
    "X.iloc[:,0:8].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para que os resultados sejam consistentes, é necessário expor os modelos exatamente ao mesmo esquema de validação cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score,StratifiedKFold\n",
    "cv = StratifiedKFold(n_splits=3, random_state=41, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Comparando o desempenho das árvores de decisão e montagens de modelos\n",
    " \n",
    "Agora vamos inicializar o classificador da árvore de decisão, avaliar seu rendimento e compará-lo com o desempenho das montagens que vimos até agora. Para isso, usaremos os seguintes métodos:\n",
    "\n",
    "### RandomForestClassifier()\n",
    "\n",
    "Este método implementa e executa uma RandomForest para resolver um problema de classificação. Alguns dos parâmetros mais importantes são os seguintes:\n",
    "\n",
    "* `n_estimators`: o número de iterações (ou seja, de `base_estimators`) para treinar\n",
    "* `criterion`: define o critério de impureza para avaliar a qualidade das partições (por padrão, é `gini`) \n",
    "* `max_features`: a quantidade de features que extrairá para treinar cada `base_estimator`. Por padrão, é igual a `sqrt(X.shape[1])`\n",
    "* `bootstrap` e `bootstrap_features`: controla se tanto os n_samples como os features são extraídos com reposição.\n",
    "* `max_depth`: a profundidade máxima da árvore\n",
    "* `min_samples_leaf`: o número mínimo de n_samples para constituir uma folha da árvore (nó terminal)\n",
    "* `min_samples_split`: o número mínimo de n_samples para realizar um split.\n",
    "\n",
    "e vários outros que podem ser importantes no momento de realizar o tunning. Em geral, os mais importantes costumam ser: `n_estimators`, `max_features`, `max_depth` e `min_samples_leaf`.\n",
    "\n",
    "\n",
    "### ExtraTreesClassifier()\n",
    "\n",
    "Com este método é possível estimar um conjunto de árvores de decisão randomizadas. Usa os mesmos parâmetros que `RandomForestClassifier()`.\n",
    "\n",
    "\n",
    "### BaggingClassifier()\n",
    "\n",
    "Este método é muito interessante porque, ao contrário dos anteriores, é um \"metaestimador\", está situado em um nível maior de abstração. Ou seja, permite implementar o algoritmo de bagging (para classificação) com quase qualquer estimador Scikit-Learn. Usa como parâmetros análogos aos dois métodos anteriores (com diferentes valores por padrão em alguns casos). Os únicos \"novos\" são: \n",
    "\n",
    "* `base_estimator`: o estimador sobre o qual queremos executar o bagging (regressões, árvores, etc...)\n",
    "* `max_samples`: a quantidade de n_samples de amostra em cada iteração. Por padrão, é igual a `sqrt(X.shape[0])`\n",
    "\n",
    "\n",
    "Para comparar os diferentes algoritmos montamos a seguinte função. Usem como input um estimador e um string com o nome que queiram pôr e executem um `cross_val_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendimento de Árvore de decisão:\t0.964 ± 0.008\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier\n",
    "\n",
    "def avaliar_desempenho(modelo, nome):\n",
    "    s = cross_val_score(modelo, X, y, cv=cv, n_jobs=-1)\n",
    "    print(\"Rendimento de {}:\\t{:0.3} ± {:0.3}\".format( \\\n",
    "        nome, s.mean().round(3), s.std().round(3)))\n",
    "    \n",
    "    \n",
    "dt = DecisionTreeClassifier(class_weight='balanced')\n",
    "\n",
    "avaliar_desempenho(dt,\"Árvore de decisão\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tentem agora com os modelos restantes e avaliem o desempenho.  \n",
    " Bagging de Árvores de decisão\n",
    " * RandomForest\n",
    " *ExtraTrees\n",
    "\n",
    "Recomendamos consultar a documentação para ver quais parâmetros são aceitos.   \n",
    "http://scikit-learn.org/stable/modules/ensemble.html#forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendimento de Árvore de decisão:\t0.964 ± 0.006\n",
      "Rendimento de Bagging AD:\t0.969 ± 0.006\n",
      "Rendimento de Random Forest:\t0.951 ± 0.006\n",
      "Rendimento de Extra Trees:\t0.958 ± 0.005\n"
     ]
    }
   ],
   "source": [
    "bdt = BaggingClassifier(DecisionTreeClassifier())\n",
    "rf = RandomForestClassifier(class_weight='balanced')\n",
    "et = ExtraTreesClassifier(class_weight='balanced')\n",
    "\n",
    "avaliar_desempenho(dt,\"Árvore de decisão\")\n",
    "avaliar_desempenho(bdt, \"Bagging AD\")\n",
    "avaliar_desempenho(rf, \"Random Forest\")\n",
    "avaliar_desempenho(et, \"Extra Trees\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse caso, o bagging de árvores de decisão funciona melhor do que o resto.   \n",
    "Com outros conjuntos de dados, os modelos Random Forest e Extra Trees podem ter resultados melhores e merecem ser testados. Poderíamos implementar um gridsearh para tentar realizar um tunning dos hiperparâmetros..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tunando os hiperparâmetros de RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "param_trees = {'n_estimators': [50, 100, 200],\n",
    "               'max_features': [1, 5, 8, 10, 21],\n",
    "               'max_depth': [5, 20, 50, 70, 100],\n",
    "               'min_samples_leaf':[1, 5, 8, 10, 50]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(class_weight='balanced')\n",
    "kf = StratifiedKFold(n_splits=3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_rf = GridSearchCV(rf, param_grid=param_trees, cv=kf, verbose=1, n_jobs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 375 candidates, totalling 1125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:   11.2s\n",
      "[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:   25.6s\n",
      "[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:   46.4s\n",
      "[Parallel(n_jobs=3)]: Done 1125 out of 1125 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=None, shuffle=True),\n",
       "       error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=3,\n",
       "       param_grid={'n_estimators': [50, 100, 200], 'max_features': [1, 5, 8, 10, 21], 'max_depth': [5, 20, 50, 70, 100], 'min_samples_leaf': [1, 5, 8, 10, 50]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_rf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=70, max_features=10,\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=50, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_rf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9762731481481481"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_rf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível ver que, realizando um processo de tunnig, o RandomForest agora é o algoritmo que melhora o desempenho dos classificadores comparados."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
