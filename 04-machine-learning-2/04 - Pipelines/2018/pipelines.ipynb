{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRÁTICA GUIADA: Pipelines StumbleUpon Evergreen\n",
    "\n",
    "## 1. Introdução\n",
    "\n",
    "Usaremos o dataset do StambleUpon para montar o nosso primeiro Pipeline. StambleUpon é um site que recomenda páginas e conteúdo a seus usuários baseados nos interesses destes. Entre as páginas recomendadas estão algumas que têm curtos períodos de relevância (notícias, receitas de culinária, etc.) e outras que mantêm o interesse ao longo do tempo e podem ser recomendadas aos usuários muito depois de terem sido publicadas. As páginas podem ser classificadas em \"ephemeral\" (efêmeras) ou \"evergreen\" (persistentes).\n",
    "\n",
    "O objetivo é, então, poder construir um classificador que classifique as páginas nessas duas categorias a fim de melhorar o sistema de recomendação do site.\n",
    "\n",
    "Para isso, tentaremos mostrar a utilidade dos pipelines.\n",
    "\n",
    "**Nota:** esta prática está baseada em um [desafio de Kaggle](https://www.kaggle.com/c/stumbleupon)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pipelines \"simples\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Primeiro importaremos os dados, pacotes, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    {\"title\":\"IBM Sees Holographic Calls Air Breat...\n",
       "1    {\"title\":\"The Fully Electronic Futuristic Star...\n",
       "2    {\"title\":\"Fruits that Fight the Flu fruits tha...\n",
       "3    {\"title\":\"10 Foolproof Tips for Better Sleep \"...\n",
       "4    {\"title\":\"The 50 Coolest Jerseys You Didn t Kn...\n",
       "Name: boilerplate, dtype: object"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "data = pd.read_csv(\"train.tsv\", sep='\\t')\n",
    "data.boilerplate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"title\":\"The Fully Electronic Futuristic Starting Gun That Eliminates Advantages in Races the fully electronic, futuristic starting gun that eliminates advantages in races the fully electronic, futuristic starting gun that eliminates advantages in races\",\"body\":\"And that can be carried on a plane without the hassle too The Omega E Gun Starting Pistol Omega It s easy to take for granted just how insanely close some Olympic races are and how much the minutiae of it all can matter The perfect example is the traditional starting gun Seems easy You pull a trigger and the race starts Boom What people don t consider When a conventional gun goes off the sound travels to the ears of the closest runner a fraction of a second sooner than the others That s just enough to matter and why the latest starting pistol has traded in the mechanical boom for orchestrated electronic noise Omega has been the watch company tasked as the official timekeeper of the Olympic Games since 1932 At the 2010 Vancouver games they debuted their new starting gun which is a far cry from the iconic revolvers associated with early games it s clearly electronic but still more than a button that s pressed to get the show rolling About as far away as you can get probably while still clearly being a starting gun Pull the trigger once and off the Olympians go If it s pressed twice consecutively it signals a false start Working through a speaker system is what eliminates any kind of advantage for athletes It s not a big advantage being close to a gun but the sound of the bullet traveling one meter every three milliseconds could contribute to a win Powder pistols have been connected to a speaker system before but even then runners could react to the sound of the real pistol firing rather than wait for the speaker sounds to reach them This year s setup will have speakers placed equidistant from runners forcing the sound to reach each competitor at exactly the same time It wouldn t be an enormous difference Omega Timing board member Peter H\\\\u00fcrzeler said in an email but when you think about reaction times being measured in tiny fractions of a second placing a speaker behind each lane has eliminated any sort of advantage for any athlete They all hear the start commands and signal at exactly the same moment There s also an ulterior reason for its look In a post September 11th world a gun on its way to a major event is going to raise more than a few TSA eyebrows even if it s a realistic looking fake Rather than deal with that the e gun can be transported while still maintaining the general look of a starting gun But there s still nothing like hearing a starting gun go off at the start of a race more than signaling the runners there s probably some Pavlovian response after more than a century of Olympic games that make people want to hear the real thing not a whiny electronic noise Everyone in the stands at home thankfully will still be getting that The sound is programmable and can be synthesized to sound like almost anything H\\\\u00fcrzeler says but we program it to sound like a pistol it s a way to use the best possible starting technology but to keep a rich tradition alive and that can be carried on a plane without the hassle, too technology,gadgets,london 2012,london olympics,olympics,omega,starting guns,summer olympics,timing,popular science,popsci\",\"url\":\"popsci technology article 2012 07 electronic futuristic starting gun eliminates advantages races\"}'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.boilerplate[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Do campo “boilerplate” pegamos os subcampos “title” e “body” e os adicionamos a data\n",
    "* Preenchemos os espaços vazios com ''\n",
    "\n",
    "* Verificamos os valores obtidos no vetor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>urlid</th>\n",
       "      <th>boilerplate</th>\n",
       "      <th>alchemy_category</th>\n",
       "      <th>alchemy_category_score</th>\n",
       "      <th>avglinksize</th>\n",
       "      <th>commonlinkratio_1</th>\n",
       "      <th>commonlinkratio_2</th>\n",
       "      <th>commonlinkratio_3</th>\n",
       "      <th>commonlinkratio_4</th>\n",
       "      <th>...</th>\n",
       "      <th>linkwordscore</th>\n",
       "      <th>news_front_page</th>\n",
       "      <th>non_markup_alphanum_characters</th>\n",
       "      <th>numberOfLinks</th>\n",
       "      <th>numwords_in_url</th>\n",
       "      <th>parametrizedLinkRatio</th>\n",
       "      <th>spelling_errors_ratio</th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.bloomberg.com/news/2010-12-23/ibm-p...</td>\n",
       "      <td>4042</td>\n",
       "      <td>{\"title\":\"IBM Sees Holographic Calls Air Breat...</td>\n",
       "      <td>business</td>\n",
       "      <td>0.789131</td>\n",
       "      <td>2.055556</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>5424</td>\n",
       "      <td>170</td>\n",
       "      <td>8</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.079130</td>\n",
       "      <td>0</td>\n",
       "      <td>IBM Sees Holographic Calls Air Breathing Batte...</td>\n",
       "      <td>A sign stands outside the International Busine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.popsci.com/technology/article/2012-...</td>\n",
       "      <td>8471</td>\n",
       "      <td>{\"title\":\"The Fully Electronic Futuristic Star...</td>\n",
       "      <td>recreation</td>\n",
       "      <td>0.574147</td>\n",
       "      <td>3.677966</td>\n",
       "      <td>0.508021</td>\n",
       "      <td>0.288770</td>\n",
       "      <td>0.213904</td>\n",
       "      <td>0.144385</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>4973</td>\n",
       "      <td>187</td>\n",
       "      <td>9</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.125448</td>\n",
       "      <td>1</td>\n",
       "      <td>The Fully Electronic Futuristic Starting Gun T...</td>\n",
       "      <td>And that can be carried on a plane without the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.menshealth.com/health/flu-fighting-...</td>\n",
       "      <td>1164</td>\n",
       "      <td>{\"title\":\"Fruits that Fight the Flu fruits tha...</td>\n",
       "      <td>health</td>\n",
       "      <td>0.996526</td>\n",
       "      <td>2.382883</td>\n",
       "      <td>0.562016</td>\n",
       "      <td>0.321705</td>\n",
       "      <td>0.120155</td>\n",
       "      <td>0.042636</td>\n",
       "      <td>...</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>2240</td>\n",
       "      <td>258</td>\n",
       "      <td>11</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.057613</td>\n",
       "      <td>1</td>\n",
       "      <td>Fruits that Fight the Flu fruits that fight th...</td>\n",
       "      <td>Apples The most popular source of antioxidants...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.dumblittleman.com/2007/12/10-foolpr...</td>\n",
       "      <td>6684</td>\n",
       "      <td>{\"title\":\"10 Foolproof Tips for Better Sleep \"...</td>\n",
       "      <td>health</td>\n",
       "      <td>0.801248</td>\n",
       "      <td>1.543103</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>2737</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.100858</td>\n",
       "      <td>1</td>\n",
       "      <td>10 Foolproof Tips for Better Sleep</td>\n",
       "      <td>There was a period in my life when I had a lot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://bleacherreport.com/articles/1205138-the...</td>\n",
       "      <td>9006</td>\n",
       "      <td>{\"title\":\"The 50 Coolest Jerseys You Didn t Kn...</td>\n",
       "      <td>sports</td>\n",
       "      <td>0.719157</td>\n",
       "      <td>2.676471</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>0.043210</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>12032</td>\n",
       "      <td>162</td>\n",
       "      <td>10</td>\n",
       "      <td>0.098765</td>\n",
       "      <td>0.082569</td>\n",
       "      <td>0</td>\n",
       "      <td>The 50 Coolest Jerseys You Didn t Know Existed...</td>\n",
       "      <td>Jersey sales is a curious business Whether you...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  urlid  \\\n",
       "0  http://www.bloomberg.com/news/2010-12-23/ibm-p...   4042   \n",
       "1  http://www.popsci.com/technology/article/2012-...   8471   \n",
       "2  http://www.menshealth.com/health/flu-fighting-...   1164   \n",
       "3  http://www.dumblittleman.com/2007/12/10-foolpr...   6684   \n",
       "4  http://bleacherreport.com/articles/1205138-the...   9006   \n",
       "\n",
       "                                         boilerplate alchemy_category  \\\n",
       "0  {\"title\":\"IBM Sees Holographic Calls Air Breat...         business   \n",
       "1  {\"title\":\"The Fully Electronic Futuristic Star...       recreation   \n",
       "2  {\"title\":\"Fruits that Fight the Flu fruits tha...           health   \n",
       "3  {\"title\":\"10 Foolproof Tips for Better Sleep \"...           health   \n",
       "4  {\"title\":\"The 50 Coolest Jerseys You Didn t Kn...           sports   \n",
       "\n",
       "  alchemy_category_score  avglinksize  commonlinkratio_1  commonlinkratio_2  \\\n",
       "0               0.789131     2.055556           0.676471           0.205882   \n",
       "1               0.574147     3.677966           0.508021           0.288770   \n",
       "2               0.996526     2.382883           0.562016           0.321705   \n",
       "3               0.801248     1.543103           0.400000           0.100000   \n",
       "4               0.719157     2.676471           0.500000           0.222222   \n",
       "\n",
       "   commonlinkratio_3  commonlinkratio_4  \\\n",
       "0           0.047059           0.023529   \n",
       "1           0.213904           0.144385   \n",
       "2           0.120155           0.042636   \n",
       "3           0.016667           0.000000   \n",
       "4           0.123457           0.043210   \n",
       "\n",
       "                         ...                          linkwordscore  \\\n",
       "0                        ...                                     24   \n",
       "1                        ...                                     40   \n",
       "2                        ...                                     55   \n",
       "3                        ...                                     24   \n",
       "4                        ...                                     14   \n",
       "\n",
       "   news_front_page  non_markup_alphanum_characters  numberOfLinks  \\\n",
       "0                0                            5424            170   \n",
       "1                0                            4973            187   \n",
       "2                0                            2240            258   \n",
       "3                0                            2737            120   \n",
       "4                0                           12032            162   \n",
       "\n",
       "   numwords_in_url  parametrizedLinkRatio  spelling_errors_ratio label  \\\n",
       "0                8               0.152941               0.079130     0   \n",
       "1                9               0.181818               0.125448     1   \n",
       "2               11               0.166667               0.057613     1   \n",
       "3                5               0.041667               0.100858     1   \n",
       "4               10               0.098765               0.082569     0   \n",
       "\n",
       "                                               title  \\\n",
       "0  IBM Sees Holographic Calls Air Breathing Batte...   \n",
       "1  The Fully Electronic Futuristic Starting Gun T...   \n",
       "2  Fruits that Fight the Flu fruits that fight th...   \n",
       "3                10 Foolproof Tips for Better Sleep    \n",
       "4  The 50 Coolest Jerseys You Didn t Know Existed...   \n",
       "\n",
       "                                                body  \n",
       "0  A sign stands outside the International Busine...  \n",
       "1  And that can be carried on a plane without the...  \n",
       "2  Apples The most popular source of antioxidants...  \n",
       "3  There was a period in my life when I had a lot...  \n",
       "4  Jersey sales is a curious business Whether you...  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['title'] = data.boilerplate.apply(lambda x: json.loads(x).get('title', ''))\n",
    "data['body'] = data.boilerplate.apply(lambda x: json.loads(x).get('body', ''))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    IBM Sees Holographic Calls Air Breathing Batte...\n",
       "1    The Fully Electronic Futuristic Starting Gun T...\n",
       "2    Fruits that Fight the Flu fruits that fight th...\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = data['title'].fillna('')\n",
    "body = data['body'].fillna('')\n",
    "y = data['label']\n",
    "titles[0:3]\n",
    "\n",
    "#y[0:3]\n",
    "#y.value_counts() / len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Vamos usar a classe `CountVectorizer` para extrair um vetor de palavras a partir dos títulos.\n",
    "\n",
    "    **Parâmetros:**\n",
    "\n",
    "    1. `max_features`: Considera apenas as primeiras X características, ordenadas por frequência.\n",
    "    2. `ngram_range` : tuple (min_n, max_n): Analisa as palavras sozinhas ou em pares.\n",
    "    3. `stop_words`: Descarta artigos e palavras sem poder preditivo do idioma inglês. É possível usar listas personalizadas.\n",
    "    4. `binary`: As possibilidades são 0 ou 1 (não se acumulam)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['air', 'breathing', 'calls', 'holographic', 'ibm', 'sees']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(max_features = 1000,\n",
    "                             stop_words='english',\n",
    "                             binary=True)\n",
    "vectorizer.fit(['IBM Sees Holographic Calls Air Breathing'])\n",
    "\n",
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Testamos o vetorizador usando uma frase.\n",
    "\n",
    "* O argumento `todense` permite que vejamos a matriz obtida (em formato \"denso\" não \"sparse\").\n",
    "\n",
    "* A partir do vetor original, é possível observar quais foram os elementos da matriz obtidos\n",
    "\n",
    "* Exemplos: \n",
    "      \n",
    "  * ‘air’ é o primeiro elemento. Como está presente, obtemos um 1.\n",
    "  * ‘air breathing’ é o segundo. Como não está presente, obtemos um 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 0, 0, 1, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.transform(['IBM Sees Holographic Air']).todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Voltamos a inicializar e executar o vetorizador, desta vez, com todos os títulos.\n",
    "* Usando a matriz `X`, que contém todos os termos comuns do nosso dataset (1 e 2 palavras), vamos alimentar o nosso classificador.\n",
    "* Instanciamos um modelo de regressão logística a partir do `sklearn` e o treinamos usando cross-validation para avaliação. \n",
    "* Em seguida, imprimimos os scores obtidos. São 3, porque é a estratégia padrão de crossval (é possível controlar por parâmetro)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.fit(titles)\n",
    "\n",
    "X = vectorizer.transform(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV scores: [ 0.75709651  0.75659229  0.75121753]\n",
      "Average CVScore: 0.755 +/- 0.003\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "model = LogisticRegression()\n",
    "scores = cross_val_score(model, X, y)\n",
    "\n",
    "print('CV scores: {}'.format(scores))\n",
    "\n",
    "print('Average CVScore: {:0.3f} +/- {:0.3f}'.format(scores.mean(),\n",
    "                                                    scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Agora vamos criar um pipeline com os passos executados anteriormente:\n",
    "    1. O vetorizador de texto\n",
    "    2. O modelo de regressão\n",
    "\n",
    "\n",
    "* Primeiro fazemos um split a partir dos dados para ficar com um set de treinamento e outro de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000    Nomskulls Skull Cupcake Mold nomskulls - skull...\n",
       "6001                    Medicine Ball Exercises Workouts \n",
       "6002    Spanakopita Greek Spinach Pie Recipe spanakopi...\n",
       "6003    Dishes Made With The Drink PHOTOS 28 amazing w...\n",
       "6004    The best sports clips of 2012 Classic YouTube ...\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = data[:6000]\n",
    "X_train = training_data['title'].fillna('')\n",
    "y_train = training_data['label']\n",
    "\n",
    "X_new = data[6000:]['title'].fillna('')\n",
    "y_new = data[6000:]['label']\n",
    "\n",
    "X_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos e criamos o pipeline\n",
    "Vamos treiná-lo com o set de treinamento e executá-lo no testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "        ('vec', vectorizer),\n",
    "        ('model', LogisticRegression())])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "pred = pipeline.predict(X_new)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Vamos comparar a previsão com o label\n",
    "* Para isso, passamos o array de previsões a um boolean para comparar com os labels e executamos o relatório de classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.85      0.78       675\n",
      "          1       0.83      0.68      0.75       720\n",
      "\n",
      "avg / total       0.77      0.76      0.76      1395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#pred_bool=pred[:,0]&lt;0.5\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_new, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Combinando pipelines e GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vejamos agora como usar os pipelines junto com o tunning de hiperparâmetros com o `GridSearchCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geramos um pipeline que tem três etapas:\n",
    "\n",
    "1. Um vetorizador de texto: `CountVectorizer`\n",
    "2. Um transformador da matriz original `TfidfTransformer`\n",
    "3. Um classificador baseado em Support Vector Machines\n",
    "\n",
    "Note que neste caso não os instanciamos previamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "   ('vect', CountVectorizer()), \n",
    "   ('tfidf', TfidfTransformer()), \n",
    "   ('svc', svm.SVC()), \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Definimos os parâmetros a buscar.\n",
    "  - É importante notar a forma em que os parâmetros são passados: geralmente são escritos `[nome da etapa]__[parâmetro]`.\n",
    "* Então, os parâmetros que usamos no `GridSeachCV` são \n",
    "  - para `CountVectorizer` (chamado `vect` no pipeline): `max_df` y `n_gram_range`\n",
    "  - para `SVC` (chamado `svc` no pipeline): `kernel` e `C`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'vect__max_df': np.linspace(0.01,0.7,5),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),\n",
    "    'svc__kernel': ['linear'],\n",
    "    'svc__C': np.linspace(0.01,0.7,10)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs = 3 , verbose = 2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done  35 tasks      | elapsed:   41.1s\n",
      "[Parallel(n_jobs=3)]: Done 156 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=3)]: Done 300 out of 300 | elapsed:  5.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...,\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=3,\n",
       "       param_grid={'vect__max_df': array([ 0.01  ,  0.1825,  0.355 ,  0.5275,  0.7   ]), 'vect__ngram_range': ((1, 1), (1, 2)), 'svc__kernel': ['linear'], 'svc__C': array([ 0.01   ,  0.08667,  0.16333,  0.24   ,  0.31667,  0.39333,\n",
       "        0.47   ,  0.54667,  0.62333,  0.7    ])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Performing grid search...\")\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* E imprimimos os melhores parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.766\n",
      "Best parameters set:\n",
      "\t svc__C: 0.54666666666666663\n",
      "\t svc__kernel: 'linear'\n",
      "\t vect__max_df: 0.1825\n",
      "\t vect__ngram_range: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score: %0.3f\" % grid_search . best_score_) \n",
    "print(\"Best parameters set:\" )\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted (parameters . keys()):\n",
    "    print(\"\\t %s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** BÔNUS:** O tempo de computação é muito melhor com `RandomizedSearchCV`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "rand_search = RandomizedSearchCV(pipeline, parameters, n_jobs = 3 , verbose = 2, n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing randomized search...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done  35 tasks      | elapsed:   42.9s\n",
      "[Parallel(n_jobs=3)]: Done 150 out of 150 | elapsed:  2.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=None, error_score='raise',\n",
       "          estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...,\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))]),\n",
       "          fit_params=None, iid=True, n_iter=50, n_jobs=3,\n",
       "          param_distributions={'vect__max_df': array([ 0.01  ,  0.1825,  0.355 ,  0.5275,  0.7   ]), 'vect__ngram_range': ((1, 1), (1, 2)), 'svc__kernel': ['linear'], 'svc__C': array([ 0.01   ,  0.08667,  0.16333,  0.24   ,  0.31667,  0.39333,\n",
       "        0.47   ,  0.54667,  0.62333,  0.7    ])},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Performing randomized search...\") \n",
    "rand_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.766\n",
      "Best parameters set:\n",
      "\t svc__C: 0.54666666666666663\n",
      "\t svc__kernel: 'linear'\n",
      "\t vect__max_df: 0.35499999999999998\n",
      "\t vect__ngram_range: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score: %0.3f\" % rand_search . best_score_) \n",
    "print(\"Best parameters set:\" )\n",
    "best_parameters_rand = rand_search.best_estimator_.get_params()\n",
    "for param_name in sorted (parameters . keys()): \n",
    "    print(\"\\t %s: %r\" % (param_name, best_parameters_rand[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pré-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Às vezes, as classes existentes no módulo de pré-processamento do sklearn podem \"ficar pequenas\". Ou seja, podemos ter que definir alguma outra transformação para o pré-processamento que não exista no módulo.\n",
    "\n",
    "Vamos ver dois exemplos muito simples de como criar a extensão da funcionalidade do módulo. Há duas formas básicas de executar essa extensão de funcionalidade.\n",
    "\n",
    "1. Estender a BaseClass\n",
    "2. Usar a função Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Estender a BaseClass no Scikit-Learn. \n",
    "\n",
    "\n",
    "Neste exemplo, criamos um transformador muito simples que retorna a entrada multiplicada por um fator X:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureMultiplier(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        \n",
    "    def transform(self, X, *_):\n",
    "        return X * self.factor\n",
    "    \n",
    "    def fit(self, *_):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0]\n",
      " [0 2 0 0]\n",
      " [0 0 3 0]\n",
      " [0 0 0 4]]\n"
     ]
    }
   ],
   "source": [
    "fm = FeatureMultiplier(2)\n",
    "test = np.diag([1,2,3,4])\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 0, 0],\n",
       "       [0, 4, 0, 0],\n",
       "       [0, 0, 6, 0],\n",
       "       [0, 0, 0, 8]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Vamos supor que queremos gerar um transformador que extraia o comprimento do corpo dos textos..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class len_body(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self = self\n",
    "    \n",
    "    def transform(self, body):\n",
    "        return [len(w) for w in body]\n",
    "    \n",
    "    def fit(self):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# largo = len_body()\n",
    "# largo.transform(body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Usando a função FunctionTransformer do módulo de pré-processamento\n",
    "\n",
    "* Vamos criar um transformador personalizado que retorne o logaritmo do input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = FunctionTransformer(np.log1p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[0,1],[2,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.69314718],\n",
       "       [ 1.09861229,  1.38629436]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* E vamos replicar o transformador que quantifica o comprimento dos textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ll(x):\n",
    "    l = [len(w) for w in x]\n",
    "    return(l)\n",
    "    \n",
    "largo2 = FunctionTransformer(ll, validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6215, 3092, 1391, 2594, 11642, 2425, 892, 1534, 869, 2973]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "largo2.transform(body)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportando binario\n",
    "\n",
    "import pickle\n",
    "def save_model(model, title='model'):\n",
    "    with open(title + '.pkl', 'wb') as fid:\n",
    "        pickle.dump(model, fid)\n",
    "        \n",
    "    print('Model save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...,\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model save\n"
     ]
    }
   ],
   "source": [
    "save_model(a,title='teste')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model save\n"
     ]
    }
   ],
   "source": [
    "save_model(pipeline, 'pipeline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openpkl(path=''):\n",
    "    path = path + '.pkl'\n",
    "    file = open(path, 'rb')\n",
    "    model = pickle.load(file)\n",
    "    file.close\n",
    "    return model\n",
    "\n",
    "teste_modelo = openpkl('pipeline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste_modelo.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       IBM Sees Holographic Calls Air Breathing Batte...\n",
       "1       The Fully Electronic Futuristic Starting Gun T...\n",
       "2       Fruits that Fight the Flu fruits that fight th...\n",
       "3                     10 Foolproof Tips for Better Sleep \n",
       "4       The 50 Coolest Jerseys You Didn t Know Existed...\n",
       "5                               Genital Herpes Treatment \n",
       "6                       fashion lane American Wild Child \n",
       "7       Racing For Recovery by Dean Johnson racing for...\n",
       "8                      Valet The Handbook 31 Days 31 days\n",
       "9             Cookies and Cream Brownies How Sweet It Is \n",
       "10      Business Financial News Breaking US Internatio...\n",
       "11      A Tip of the Cap to The Greatest Iron Man of T...\n",
       "12                         9 Foods That Trash Your Teeth \n",
       "13                                                       \n",
       "14      French Onion Steaks with Red Wine Sauce french...\n",
       "15      Izabel Goulart Swimsuit by Kikidoll 2012 Sport...\n",
       "16                    Liquid Mountaineering The Awesomer \n",
       "17                                                       \n",
       "18                          Grilled Peaches Sugarcrafter \n",
       "19      How to Make Your Home Healthier A Room by Room...\n",
       "20      Olympic Soccer Babe Alex Morgan Medal Winning ...\n",
       "21         BBC Food Recipes Blueberry and lemon traybake \n",
       "22      Quit Smoking Counter Online counter that measu...\n",
       "23            Original techniques to tie your shoe laces \n",
       "24                                                       \n",
       "25       Best College Football Fan Sign Ever Alabama Fan \n",
       "26                                    Breaking News Blog \n",
       "27                     The Alton Brown Flower Pot Smoker \n",
       "28          Supermodels show off their bikini bods Humor \n",
       "29      Genevieve Morton Swimsuit by Tyler Rose Swimwe...\n",
       "                              ...                        \n",
       "5970    CDC admits not a single person has died from c...\n",
       "5971    Honey Shortbread Fine Cooking Recipes Techniqu...\n",
       "5972            Recycle your Clothes DIYJersey Tank Vest \n",
       "5973              Brian sez its peanut butter jelly time \n",
       "5974    Honda introduces its newest robot and it cuts ...\n",
       "5975                                  Pain Tips iVillage \n",
       "5976    7 Sweet Facts About Chocolate Valentine s Day ...\n",
       "5977    Samsung Galaxy S II Over 3 million units sold ...\n",
       "5978             Pink Lemonade Cake Giving Up on Perfect \n",
       "5979                               we change beauty Blog \n",
       "5980                                        Lasagna Cups \n",
       "5981    MarkMontoya com Blog Archive More Pictures Tha...\n",
       "5982                       Afternoon tea recipes Recipes \n",
       "5983                                thefabchronicles com \n",
       "5984    Beauty Tips Eye Makeup Cosmetics Database Skin...\n",
       "5985    11 Unbelievable Inventions We Wish We Thought ...\n",
       "5986            Chicken and Black Bean Quesadilla Recipe \n",
       "5987                        Dolce Gabbana Shoes ShoeBlog \n",
       "5988    The National Aquatics Center The Official Webs...\n",
       "5989    The 10 Sins that Sabotage the Nanny Employer R...\n",
       "5990    20 Hype Street Snap Blogs for Fashion Design I...\n",
       "5991    Norway shootings mother updated by daughter s ...\n",
       "5992    Golden Gate bridge accident averted by selfles...\n",
       "5993     Roasted figs with goat cheese and truffle honey \n",
       "5994    Butternut Squash Lasagna Recipe Giada De Laure...\n",
       "5995            Life With 4 Boys 25 Meals in 4 1 2 Hours \n",
       "5996                        Red Velvet Crêpes Duhlicious \n",
       "5997    A stress reducing shopping list Health Self co...\n",
       "5998                                                     \n",
       "5999                         How to Make Flour Tortillas \n",
       "Name: title, Length: 6000, dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline2 = Pipeline([\n",
    "        ('vec', vectorizer),\n",
    "        ('model', xgboost.XGBClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vec', CountVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=1000, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "        st...\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1))])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline2.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
