{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribuições de probabilidade\n",
    "\n",
    "<br>\n",
    "<img src=\"img/distribuicoes_prob.png\">\n",
    "<br>\n",
    "\n",
    "*fonte:Wikipedia*\n",
    "\n",
    "Em teoria da probabilidade e em estatística, uma distribuição de probabilidade descreve o comportamento aleatório de um fenômeno dependente do acaso. O estudo dos fenômenos aleatórios começou com o estudo dos jogos de azar – jogos de dados, sorteios de bolas de urna e cara ou coroa eram motivações para compreender e prever os experimentos aleatórios. Essas abordagens iniciais são fenômenos discretos, o que significa que o número de resultados possíveis é finito ou contável. Entretanto, certas questões revelam distribuições de probabilidade com suporte infinito não contável. Por exemplo, quando o lançamento de uma moeda tende ao infinito, o número de coroas aproxima-se de uma distribuição normal.\n",
    "\n",
    "Flutuações e variabilidade estão presentes em quase todo valor que pode ser medido durante a observação de um fenômeno, independente de sua natureza, além disso quase todas as medidas possuem uma parte de erro intrínseco. A distribuição de probabilidade pode modelar incertezas e descrever fenômenos físicos, biológicos, econômicos, entre outros. O domínio da estatística permite o encontro das distribuições de probabilidade adaptadas aos fenômenos aleatórios.\n",
    "\n",
    "Há muitas distribuições de probabilidade diferentes. Entre as distribuições de probabilidade, a distribuição normal tem uma importância particular. De acordo com o teorema central do limite, a distribuição normal aborda o comportamento assintótico de várias distribuições de probabilidade.\n",
    "\n",
    "O conceito de distribuição de probabilidade é formalizado matematicamente pela teoria da medida – uma distribuição de probabilidade é uma medida muitas vezes vista como uma distribuição que descreve o comportamento de uma variável aleatória discreta ou contínua. Uma medida é uma distribuição de probabilidade se sua massa total for 1. O estudo de uma variável aleatória de acordo com uma distribuição de probabilidade discreta revela o cálculo de somas e de séries, enquanto que o estudo de uma variável aleatória de acordo com uma distribuição de probabilidade absolutamente contínua revela o cálculo de integrais. As funções particulares permitem caracterizar as distribuições de probabilidade como a função de distribuição e a função característica. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EVE0sbeI2vi9"
   },
   "source": [
    "# Amostras para distribuições com numpy e scipy\n",
    "\n",
    "A biblioteca  numpy oferece um conjunto de funções que geram valores aleatórios, esses valores podem vir de diferentes tipos de distribuições estatísticas e nos fornecem um conjunto de dados pertencentes aos valores do espaço de amostra dessas distribuições.\n",
    "\n",
    "Na prática, se precisássemos de um conjunto de 100 dados que sigam uma distribuição normal, teríamos que fazer uma chamada para a função normal indicando a média e o desvio padrão:\n",
    "\n",
    "```python\n",
    "    >> media = 0\n",
    "    >> desvio = 1\n",
    "    >> numpy.random.normal(media, desvio, 100)\n",
    "```\n",
    "\n",
    "Vamos trabalhar com dados de diferentes distribuições (dados por numpy.random) para visualizar o comportamento dessas variáveis. A quantidade de dados será grande para podermos apreciar corretamente sua forma gráfica.\n",
    "\n",
    "É importante reconhecer visualmente o comportamento estatístico das variáveis, já que é uma primeira aproximação à modelagem e previsão desses dados. Muitas vezes é possível ter uma ideia de como eles se comportam matematicamente apenas visualizando-os em um gráfico.\n",
    "\n",
    "Para biblioteca original [clique aqui](https://docs.scipy.org/doc/numpy-1.15.1/reference/routines.random.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "EjintSsM2vi3"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "37EluvzT2vi-"
   },
   "source": [
    "# Distribuição uniforme discreta\n",
    "\n",
    "\n",
    "Diz-se que uma variável segue uma distribuição uniforme discreta (se escreve **_X_ ~ ** unif {$x_1, x_2, ... x_n$}) se a probabilidade de aparição dos valores em cada ensaio for constante e igual: \n",
    "\n",
    "\\begin{equation*}\n",
    "P(x_i)= \\dfrac{1}{n}\n",
    "\\end{equation*}\n",
    "\n",
    "Onde **_P_** é a probabilidade, **_x_** valores dentro do espaço amostral e **_n_** a quantidade de elementos do espaço amostral.\n",
    "\n",
    "A seguir, vamos realizar uma chamada à função ```randint``` que ajusta a valores provenientes de uma distribuição uniforme discreta, com a motivação de simular o lançamento de um dado equilibrado 6000 vezes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "gAWYk-WE2vi-",
    "outputId": "a3bad4ce-2e84-4e3d-f62e-fae46c2d7b3f"
   },
   "outputs": [],
   "source": [
    "# Definimos o domínio do dado, onde somamos 1 ao valor máximo... por quê?\n",
    "valor_min = 1\n",
    "valor_max = 6 + 1\n",
    "\n",
    "# Definimos a quantidade de lançamentos do dado.\n",
    "lançamentos = 6000\n",
    "\n",
    "# Fazemos uma chamada à função randint, que retorna o resultado de cada lançamento\n",
    "samples_uniforme = np.random.randint(low = valor_min,\n",
    "                                     high = valor_max,\n",
    "                                     size = lançamentos)\n",
    "\n",
    "# Representamos graficamente os resultados\n",
    "sns.distplot(samples_uniforme, axlabel = 'número obtido', kde=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_uniforme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distribuição acumulada\n",
    "df = pd.DataFrame(samples_uniforme,columns=['face'])\n",
    "df.groupby('face').size().hist(cumulative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('face').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.face.value_counts().hist(cumulative=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribuição de Bernoulli\n",
    "\n",
    "*fonte: Wikipedia*\n",
    "\n",
    "Na área de teoria das probabilidades e estatística, a distribuição de Bernoulli, nome em homenagem ao cientista suíço Jakob Bernoulli, é a distribuição discreta de espaço amostral {0, 1}, que tem valor 1 com a probabilidade de sucesso p e valor 0 com a probabilidade de falha q = 1 − p. \n",
    "\n",
    "Um exemplo clássico de uma experiência de Bernoulli é uma jogada única de uma moeda. A moeda pode dar \"coroa\" com probabilidade p e \"cara\" com probabilidade 1 − p. A experiência é dita justa se p = 0.5, indicando a origem dessa terminologia em jogos de aposta (a aposta é justa se ambos os possíveis resultados tem a mesma probabilidade). \n",
    "\n",
    "A média dessa distribuição é sempre p e a variância p(1-p).\n",
    "\n",
    "A dsitribuição de Bernoulli é utilizada para representar diversos fenômenos em ciências médicas e sociais, em áreas como as seguintes:\n",
    "\n",
    "- Em medicina, permite por exemplo representar os factores que caracterizam um grupo de indivíduos doentes em relação a indivíduos sãos.\n",
    "- No domínio dos seguros, permite representar fracções da clientela que sejam sensíveis a determinada política securitária em relação a um dado risco particular.\n",
    "- Em instituições financeiras, pode representar os grupos de risco para a subscrição de um crédito.\n",
    "- Em econometria, permite representar uma variável discreta, como por exemplo as intenções de voto em atos eleitorais.\n",
    "\n",
    "__Na distribuição de Bernoulli, a média é a própria probabilidade.__\n",
    "\n",
    "\n",
    "### Exemplo\n",
    "\n",
    "Vamos trabalhar com uma distribuição de Bernoulli, com ```p = 0.6```, e observar a convergência dos resultados conforme o tamanho da amostra é incrementado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import bernoulli\n",
    "bern = bernoulli.rvs(p=0.7, size=1000) # Random Variates\n",
    "\n",
    "plt.title('Bernoulli: variáveis dicotômicas')\n",
    "plt.hist(bern);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bern[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bern.sum()/len(bern) # média empirica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bern.std()**2 # variância"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bern.std() * bern.std() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bern.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulação para convergência de Bernoulli com o aumento da amostra\n",
    "\n",
    "Comprovação da Lei dos Grandes Números com Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Média Verdadeira: 0.6, Variância Verdadeira: 0.24')\n",
    "for n in [3,10,100]:\n",
    "    bern = bernoulli.rvs(p=0.6, size=n)\n",
    "    print('\\namostra:',n)\n",
    "    print('média:', bern.sum()/len(bern))\n",
    "    print('var:', bern.std()**2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variância Nominal\n",
    "\n",
    "p*(1-p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bern.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bern.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizando a distribuição de Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate=0.6\n",
    "n = np.arange(0,100)\n",
    "y= bernoulli.rvs(p=0.6, size=100)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(n,y,'o')\n",
    "plt.title('Bernoulli')\n",
    "plt.xlabel('Dispersion')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculando a CDF (Cumulative Distribution Function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_bern = pd.DataFrame(bern,columns=['bernoulli'])\n",
    "df_bern['CDF'] = df_bern.bernoulli.sort_values(ascending=True).values\n",
    "df_bern.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bern.bernoulli.sum()/len(df_bern.bernoulli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df_bern['CDF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate=0.6\n",
    "n = np.arange(0,100)\n",
    "y=df_bern['CDF']\n",
    "\n",
    "plt.plot(n,y,'o-')\n",
    "plt.title('Bernoulli')\n",
    "plt.xlabel('Despersion')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FOwQ6J-K2vjG"
   },
   "source": [
    "# Distribuição Binomial\n",
    "\n",
    "*fonte: Wikipedia*\n",
    "\n",
    "Em teoria das probabilidades e estatística, a distribuição binomial é a distribuição de probabilidade discreta do número de sucessos numa sequência de n tentativas tais que:\n",
    "\n",
    "- Cada tentativa tem exclusivamente como resultado duas possibilidades, sucesso ou fracasso (binomial, a que se chama de tentativa de Bernoulli), e;\n",
    "- Cada tentativa é independente das demais, e;\n",
    "- A probabilidade de sucesso p a cada tentativa permanece constante independente das demais, e;\n",
    "- A variável de interesse, ou pretendida, é o número de sucessos  k nas  n tentativas.\n",
    "\n",
    "Mede o número de sucessos em uma sequência de _**n**_ ensaios independentes entre si, com uma probabilidade fixa **_p_** de ocorrência de sucesso entre os ensaios. Quando uma variável **_X_** segue uma distribuição binomial, escreve-se **_X ~ B (n, p)_** . Onde **_p_** é a probabilidade de sucesso (que é fixa), y _**n**_ o número de ensaios. \n",
    "\n",
    "A função da probabilidade é:\n",
    "\n",
    "\\begin{equation*}\n",
    "f(x)=  \\binom {n}{x} (p)^x (1-p)^{(n-x)}\n",
    "\\end{equation*}\n",
    "\n",
    "Onde **_x_** é a quantidade de acertos, **_p_** a probabilidade de sucesso, **_n_** a quantidade de ensaios.\n",
    "\n",
    "O ensaio de Bernoulli consiste\n",
    "\n",
    "OensaiodeBernoulliconsisteemrealizarumexperimentoaleatórioumasóvezeobservarsecertoeventoocorreounão.RepetiçõesindependentesdeumensaiodeBernoulli,comamesmaprobabilidadedeocorrênciade“sucesso”,dãoorigemaomodeloBinomial.\n",
    "\n",
    "### Exemplo\n",
    "\n",
    "Neste caso, vamos simular o lançamento de uma moeda 8 vezes por ensaio, onde a probabilidade de sucesso (obter cara) será 0,5. A seguir, a função de distribuição para o caso:\n",
    "\n",
    "\\begin{equation*}\n",
    "f(x)= \\binom {8}{x} (0,5)^x (1-0,5)^{(8-x)}\n",
    "\\end{equation*}\n",
    "\n",
    "Vamos realizar um chamado à função```binomial``` que ajusta a valores provenientes de uma distribuição binomial e vamos realizar 10.000 ensaios para montar a distribuição.\n",
    "\n",
    "Nota: A distribuição de Bernoulli é um caso especial da distribuição Binomial, com n = 1 e sua média, como esperado é np (contra p) e a variância teórica é np(1-p) (contra p(1-p))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "KoK2zcos2vjH",
    "outputId": "9c8e0f35-326c-4648-f8c7-e701719909d0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# definimos a quantidade de ensaios.\n",
    "quantidade_ensaios = 10000\n",
    "\n",
    "# definimos a quantidade de lançamentos por ensaio.\n",
    "lançamentos = 8\n",
    "\n",
    "# definimos a probabilidade de obter cara em cada lançamento.\n",
    "probabilidade_sucesso = 0.2\n",
    "\n",
    "# binomial retorna o número de sucessos de cada vez que se realizou um ensaio de 8 lançamentos.\n",
    "samples_binomial = np.random.binomial(n = lançamentos, p = probabilidade_sucesso, size = quantidade_ensaios)\n",
    "\n",
    "# construímos um gráfico.\n",
    "eixo_x = 'Número de acertos por ensaio de 8 lançamentos'\n",
    "sns.distplot(samples_binomial, axlabel = eixo_x, kde = False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_binomial[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_binomial.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partindo da Distribuição Binomial para a Densidade de Probabilidade\n",
    "\n",
    "Uma variável aleatória X que possui uma distribuição binomial representa o número de sucessos em uma sequência de n tentativas sim / não independentes, cada uma das quais produz sucesso com probabilidade p.\n",
    "\n",
    "$ E (X) = np $,  $ Var (X) = np * (1-p) $\n",
    "\n",
    "onde $E(X)$ é o valor esperado ou média da distribuição.\n",
    "\n",
    "Para saber como funciona cada função, você pode buscar na documentação oficial do Scipy.Stats.Binom [clicando aqui](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.binom.html).\n",
    "\n",
    "Exemplo de distribuição binomial: Qual é a probabilidade de obter 2 caras de 10 lançamentos de uma moeda justa?\n",
    "\n",
    "\n",
    "Neste experimento, a probabilidade de obter uma cara é de 0,3, o que significa que, em média, você pode esperar que 3 viradas de moeda sejam caras.\n",
    "\n",
    "Srá feira a simulação de uma variável aleatória binomial usando .rvs. O tamanho do parâmetro especifica quantas simulações se deseja fazer. \n",
    "\n",
    "O comando pede ao Python que retorne 10000 variáveis aleatórias binomiais com os parâmetros n e p. Será impressa a média e o desvio padrão dessas 10000 variáveis aleatórias. Então será plotado o histograma de todas as variáveis aleatórias simuladas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binom\n",
    "\n",
    "binomial_simulation = data = stats.binom.rvs(n=10,p=0.5,size=10000) # Random Variates\n",
    "print('mean: %g'% np.mean(binomial_simulation))\n",
    "print('SD: %g' % np.std(binomial_simulation))\n",
    "plt.hist(binomial_simulation, bins=10, normed=True,histtype='barstacked')\n",
    "plt.xlabel ('x')\n",
    "plt.ylabel('distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível definir todos os valores que o coin flip pode tomar com k = np.arange (0,10), pode-se observar zero caras, uma cara até dez caras. \n",
    "\n",
    "Será utilizado stats.binom.pmf para calcular a função densidade de probabilidade para cada observação. Ele retorna uma lista de 10 elementos - esses elementos representam a probabilidade associada a cada observação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=10\n",
    "p=0.5\n",
    "k=np.arange(0,10)\n",
    "binomial = stats.binom.pmf(k,n,p)  #Função Densidade de Probabilidade\n",
    "binomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(k,binomial,'o-')\n",
    "plt.title('Binomial: n=%i , p=%.2f' %(n,p),fontsize=15)\n",
    "plt.xlabel('Number of Successes',fontsize=15)\n",
    "plt.ylabel('Probability of Successes',fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d82_kn_N2vjN"
   },
   "source": [
    "# Distribuição de Poisson\n",
    "\n",
    "É uma distribuição de probabilidade de variável aleatória **discreta** que expressa a probabilidade de uma série de eventos ocorrer num certo período de tempo se estes eventos ocorrem **independentemente** de quando ocorreu o último evento. Por exemplo, o número de filhos de um casal, o número de clientes que entram em um banco durante a manhã ou o número de falhas de um carro durante um trajeto (embora exista o argumento de que esses eventos não são exatamente independentes).\n",
    "\n",
    "Esta distribuição tem como parâmetro $\\lambda$ é sempre maior que zero. **Este parâmetro indica o número médio de ocorrências de um evento por unidade contínua (como tempo ou espaço)**. Por exemplo, se o evento ocorre a uma média de 4 minutos, e estamos interessados no número de eventos que ocorrem num intervalo de 10 minutos, usariámos como modelo a distribuição de Poisson com λ = 10/4 = 2.5.\n",
    "\n",
    "Quando uma variável **_X_** segue uma distribuição de Poisson, escreve-se **_X ~ Poisson ($\\lambda$)_** e a função de probabilidade é:\n",
    "\n",
    "\\begin{equation*}\n",
    "f(x)= e^{-\\lambda} \\dfrac{\\lambda^x}{x!}\n",
    "\\end{equation*}\n",
    "\n",
    "* $e$ é base do logaritmo natural ($e$ = 2.71828...),\n",
    "* ! significa fatorial, muito usado em arranjos e permutações. Ex: Placa de carro.\n",
    "\n",
    "A distribuição de Poisson representa um modelo probabilístico adequado para o estudo de um grande número de fenômenos observáveis. Eis alguns exemplos:\n",
    "\n",
    "- Chamadas telefônicas por unidade de tempo;\n",
    "- Defeitos por unidade de área;\n",
    "- Acidentes por unidade de tempo;\n",
    "- Chegada de clientes a um supermercado por unidade de tempo;\n",
    "- Número de glóbulos sangüíneos visíveis ao microscópio por unidade de área;\n",
    "- Número de partículas emitidas por uma fonte de material radioativo por unidade de tempo.\n",
    "\n",
    "Nota: tanto a média quanto a variância em uma distribuição de Poisson é dado por $\\lambda$\n",
    "\n",
    "[Calculadora](http://www.elektro-energetika.cz/calculations/po.php)\n",
    "(Será que conseguimos construir uma calculadora em python nesse estilo?)\n",
    "\n",
    "### Exemplo\n",
    "\n",
    "Propomos o exemplo de um trem onde ocorre uma **média de 1,5 falhas por dia**, portanto $\\lambda = 1,5 $ e nossa função de probabilidades.\n",
    "\n",
    "\\begin{equation*}\n",
    "f(x)= e^{-1.5} \\dfrac{1.5^x}{x!}\n",
    "\\end{equation*}\n",
    "\n",
    "Vamos obter um conjunto de dados provenientes de uma distribuição de Poisson através da chamada à função ```poisson```, com a motivação de modelar o problema apresentado.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "QbEeFBOx2vjO",
    "outputId": "e7b085c2-ccd1-4091-d595-67a9012ac552"
   },
   "outputs": [],
   "source": [
    "# Definimos os parâmetros para a distribuição (não utilizamos a palavra lambda porque está reservada)\n",
    "parametro_lambda = 1.5\n",
    "\n",
    "# Definimos a quantidade de dias em que contamos quantas falhas houve.\n",
    "dias_contados = 365\n",
    "\n",
    "# poisson retorna a quantidade de falhas por dia.\n",
    "samples_poisson = np.random.poisson(lam = parametro_lambda, size = 365)\n",
    "\n",
    "# construímos o gráfico\n",
    "eixo_x = 'Quantidade de falhas do trem por dia'\n",
    "sns.distplot(samples_poisson, axlabel = eixo_x, kde=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_poisson[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_poisson.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partindo da Distribuição de Poisson para a Densidade de Probabilidade\n",
    "\n",
    "Uma variável aleatória X que se origina de uma distribuição de Poisson representa o número de eventos que ocorrem em um intervalo de tempo fixo com um parâmetro de taxa λ, onde λ informa a taxa na qual o número de eventos ocorre.\n",
    "\n",
    "A média e a variância serão λ.\n",
    "\n",
    "Agora será simulado 1.000 variáveis aleatórias de uma distribuição de Poisson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = stats.poisson.rvs(mu=2,loc=0,size=10000)\n",
    "print( 'Mean: %g' % np.mean(data))\n",
    "print('SD: %g' % np.std(data, ddof=1))\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(data,bins=50,normed=True)\n",
    "plt.xlim(0,10)\n",
    "plt.xlabel('Number of Accidents')\n",
    "plt.title('Simulating Poisson Random Variables')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível perceber que o número de acidentes atinge o pico em torno da média. Em média, você pode esperar um grande número de eventos. Tente valores diferentes de lambda e n, depois veja como a forma da distribuição muda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate=2\n",
    "n = np.arange(0,10)\n",
    "y=stats.poisson.pmf(n,rate) # Função Densidade de Probabilidade\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(n,y,'x--')\n",
    "plt.title('Poisson: $\\lambda$ =%i' % rate)\n",
    "plt.xlabel('Number of Accidents')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribuição Exponencial\n",
    "\n",
    "Esta é uma distribuição que se caracteriza por ter uma função de taxa de falha constante. A distribuição exponencial é a única com esta propriedade. Ela é considerada uma das mais simples em termos matemáticos. Esta distribuição tem sido usada extensivamente como um modelo para o tempo de vida de certos produtos e materiais. Ela descreve adequadamente o tempo de vida de óleos isolantes e dielétricos, entre outros.\n",
    "\n",
    "De uma forma bastante resumida imagine uma variável aleatória Poisson, onde temos a contagem do número de ocorrências em um intervalo. Suponha agora que estejamos interessados em verificar a probabilidade do tempo transcorrido entre duas ocorrências consecutivas. Essa última é considerada uma variável aleatória exponencial.\n",
    "\n",
    "Essa distribuição contínua que pode ser utilizada para descrever as probabilidades envolvidas no tempo que decorre para que um determinado evento aconteça. Existe uma conexão muito próxima entre a distribuição exponencial e a de Poisson, de forma que a função exponencial é utilizada para descrever o tempo entre as ocorrências de sucessivos eventos de uma distribuição de Poisson. As relações entre as distribuições podem ser associadas a um processo estocástico, chamado de processo de poisson.\n",
    "\n",
    "Pode ser representada pela fórmula abaixo, para valores de x >= 0.\n",
    "\n",
    "\\begin{equation*}\n",
    "f(x;\\lambda)= \\lambda e^{-\\lambda x}\n",
    "\\end{equation*}\n",
    "\n",
    "### Exemplo\n",
    "\n",
    "Da mesma forma que acontece na distribuição de Poisson, vamos adotar o parâmetro $\\lambda$ que define a frequência de ocorrência do evento igual a 1.5 e os dias contados igual a 365."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nós herdamos o parâmetro lambda e o período de tempo da distribuição anterior ...\n",
    "parametro_lambda = 1.5\n",
    "dias_contados = 3650\n",
    "\n",
    "# poisson retorna o número de falhas por dia e a exponencial o tempo para o próximo evento\n",
    "samples_exp = np.random.exponential(scale=1/parametro_lambda, size=dias_contados)\n",
    "\n",
    "# por fim, plotamos\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.distplot(samples_exp,bins=100) # Com curva KDE (Kernel Density Estimation);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_exp[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_exp.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llambda = 1.5\n",
    "tempo = 2\n",
    "func_exp = llambda * (np.e) ** (-llambda * tempo)\n",
    "func_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tempo = [1,2,3,4,5,6,7,8,9]\n",
    "func_exp = []\n",
    "for tempo in list_tempo:\n",
    "    func_exp.append(llambda * (np.e) ** (-llambda * tempo))\n",
    "func_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_func_exp = pd.DataFrame({'tempo':list_tempo,'exponencial':func_exp})\n",
    "df_func_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df_func_exp.tempo\n",
    "y=df_func_exp.exponencial\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partindo da Distribuição Exponencial para a Função Densidade de Probabilidade\n",
    "\n",
    "Pode-se simular 1000 variáveis aleatórias de uma distribuição exponencial, onde o parâmetro scale é o inverso do parâmetro lambda da distribuição de Poisson.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = stats.expon.rvs(scale=2,size=1000) # Randaom Variates\n",
    "print('Mean: %g' % np.mean(data))\n",
    "print('SD> %g' % np.std(data))\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(data,bins=20,normed=True)\n",
    "plt.xlim(0,15)\n",
    "plt.title('Simulating Exponential Random Variables')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A distribuição exponencial representa um processo no qual os eventos ocorrem de forma contínua e independente a uma taxa média constante.\n",
    "\n",
    "Seráa definido o parâmetro lambda como 0,5 e x no intervalo de 0 a 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambd=0.5\n",
    "x=np.arange(0,15,0.1)\n",
    "y=lambd * stats.expon.pdf(lambd * x)  # Probability Density Function\n",
    "plt.plot(x,y)\n",
    "plt.title('Exponential: $\\lambda$ =%.2f' % lambd)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribuição Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('<iframe width=\"640\" height=\"360\" src=\"https://www.youtube.com/embed/W5ZiwMczBNY\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ef7cLBzM2vjT"
   },
   "source": [
    "## Definição de Distribuição Normal\n",
    "\n",
    "A distribuição normal (ou Guassiana) modela uma grande quantidade de variáveis observadas na natureza, como a estatura ou peso de uma população.\n",
    "\n",
    "Também sob certas condições, algumas distribuições se comportam como normais, isto é conhecido como o **teorema do limite central**.\n",
    "\n",
    "É possível ajustar uma distribuição de Poisson a uma normal quando $\\lambda$ é um valor de grande magnitude (rodar posteriormente a distribuição Poisson alterando o lambda para algo em torno de 15e dias_contados para em torno de 3000 onde a forma da distribuição ficará parecida com a normal).\n",
    "\n",
    "Também é possível ajustar uma binomial a uma distribuição normal fazendo-se uma normalização dos dados. Para isso, propõe-se como exemplo agregar o argumento ```fit=stats.norm``` à construção do gráfico.\n",
    "\n",
    "Dizemos que uma variável aleatória _**X**_ segue uma distribuição normal **_X ~ N ( $\\mu$, $\\sigma$)_** se sua distribuição de probabilidades estiver dada por:\n",
    "\n",
    "\\begin{equation*}\n",
    "p(x)= \\dfrac{1}{\\sqrt{2 \\pi \\sigma^²}} e^ \\dfrac{-(x-\\mu)^2}{2 \\sigma^2}\n",
    "\\end{equation*}\n",
    "\n",
    "### Exemplo (1)\n",
    "\n",
    "Para a definição de uma distribuição normal, é necessário estabelecer uma média e um desvio padrão, como as características de uma certa amostra. \n",
    "\n",
    "Imaginemos um exemplo em que temos uma população de pessoas cuja altura segue uma distribuição normal, com $\\mu = 1.67 $ m e $\\sigma = 0.15 $ m\n",
    "\n",
    "A seguir, vamos usar um conjunto de amostras que vêm de uma distribuição normal, chamando à função ```normal``` do numpy com os parâmetros propostos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.random.normal(1.67, 0.15, 10000)).plot.hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemplo (2)\n",
    "\n",
    "Da mesma forma, imaginemos um exemplo em que temos uma população de ursos cujo peso segue uma distribuição normal, com $\\mu = 342,73 $ kg e $\\sigma = 45,78 $ kg\n",
    "\n",
    "Também vamos usar um conjunto de amostras que vêm de uma distribuição normal, chamando à função ```normal``` do numpy com os parâmetros propostos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q5Ok2Nra2vjU",
    "outputId": "37713d5a-fe7f-4129-c2f6-2fcc6f8a063e"
   },
   "outputs": [],
   "source": [
    "# definimos a média\n",
    "media = 342.73\n",
    "\n",
    "# definimos o desvio padrão\n",
    "desvio_padrão = 45.78\n",
    "\n",
    "# quantidade de amostras na população\n",
    "n_amostras = 3000\n",
    "\n",
    "# chamamos à função normal\n",
    "samples_normal = np.random.normal(loc = media, \n",
    "                                  scale = desvio_padrão, \n",
    "                                  size = n_amostras)\n",
    "\n",
    "# construímos o gráfico\n",
    "eixo_x = 'Peso'\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.distplot(samples_normal, axlabel = eixo_x)\n",
    "plt.show()\n",
    "\n",
    "# plt.figure(figsize=(10,8))\n",
    "# sns.distplot(samples_normal,\n",
    "#              hist_kws=dict(cumulative=True),\n",
    "#              kde_kws=dict(cumulative=True))\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E na realidade como isso faz diferença na nossa vida?\n",
    "Vamos pegar um ônibus.\n",
    "<br>\n",
    "É isso que imaginamos...\n",
    "<br>\n",
    "<img src=\"https://image.shutterstock.com/image-photo/woman-on-passenger-seat-bus-260nw-743692555.jpg\">\n",
    "<br>\n",
    "Mas, nunca estamos sozinhos...\n",
    "<br>\n",
    "<img src=\"https://image.shutterstock.com/image-photo/group-tourists-preparing-get-on-260nw-743695567.jpg\">\n",
    "<br>\n",
    "E tudo bem, desque a variância das pessoas que estiverem conosco estejam dentro da curva normal utilizada para projetar os acentos do ônibus...\n",
    "<br>\n",
    "<img src=\"https://image.shutterstock.com/image-photo/guy-girl-on-bus-has-260nw-743693851.jpg\">\n",
    "<br>\n",
    "Se não...\n",
    "<br>\n",
    "<img src=\"https://static1.squarespace.com/static/583e5fa2e6f2e18631f2da34/t/59fb6148d6839abd5f9d84bc/1509646681673/andre.jpg\">\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribuição normal converge com o aumento do tamanho da amostra\n",
    "\n",
    "Utilizando os mesmos valoes para a média (342.73) e o desvio padrão (45.78), vamos variar o tamanho da amostra em 10, 100, 1000, 10000 e 100000 observações, para observar o comportamento da distribuição sendo normalizado, seguido do gráfico da função densidade acumulada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for n, c in [[10,'b'],[100,'r'],[1000,'y'],[10000,'g'],[100000,'m']]:\n",
    "    print('n:',n)\n",
    "    \n",
    "    fig, ax = plt.subplots(2,1,figsize=(7, 11))\n",
    "\n",
    "    samples_normal = np.random.normal(loc = media,\n",
    "                                      scale = desvio_padrão,\n",
    "                                      size = n)\n",
    "    sns.distplot(samples_normal,\n",
    "                 axlabel = eixo_x,\n",
    "                 ax=ax[0],\n",
    "                 color=c, \n",
    "                 bins=30)\n",
    "    \n",
    "    sns.distplot(samples_normal,\n",
    "                 hist_kws=dict(cumulative=True),\n",
    "                 kde_kws=dict(cumulative=True),\n",
    "                 ax=ax[1], color=c)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribuição normal padrão\n",
    "\n",
    "Existe uma infinidade de possibilidade para uma variável X seguir uma distribuição Normal com média $\\mu$ e desvio $\\sigma$ quaisquer:\n",
    "\n",
    "$X \\sim \\mathcal{N}(\\mu,\\,\\sigma^{2})\\,$\n",
    "\n",
    "Uma forma mais fácil de trabalhar com uma distribuição que segue uma normal é tornando-a uma **normal padrão**, e fazemos isso com uma operação bastante simples, basicamente dividindo todos os valores pela média da amostra e dividindo esse resultado pelo desvio padrão da amostra.\n",
    "\n",
    "Isso faz com que a média seja centrada no zero e o desvio padrão seja o valor 1, e isso vai simplificar muito as contas de agora em diante.\n",
    "\n",
    "A escala horizontal do gráfico da distribuição normal padrão corresponde ao **Z-Score**, que é uma medida de posição que indica o número de desvios padrão em que um valor se encontra a partir da média. Podemos transformar um valor x em **Z-Score** subtraindo o valor meedio µ e em seguida dividindo-se pelo desvio padrão $\\sigma$.\n",
    "\n",
    "$Z \\sim \\dfrac{x - \\mu} {\\sigma^{2}\\,} $\n",
    "\n",
    "\n",
    "**Propriedades da distribuição normal padrão**\n",
    "- A área acumulada é próxima de 0 para z-scores próximos a z=-3,49.\n",
    "- A área acumulada aumenta conforme os z-scores aumentam.\n",
    "- A área acumulada para z=0 é 0,5000.\n",
    "- A área acumulada é próxima a 1 para z-scores próximos a z=3,49."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vamos trabalhar com a mesma média e o mesmo desvio padrão (samples_normal.std = 45.71075907280459)\n",
    "media = 342.73\n",
    "\n",
    "new_samples_normal = []\n",
    "\n",
    "samples_normal_std = samples_normal.std()\n",
    "for row in samples_normal:\n",
    "    new_value = (row-media)/samples_normal_std\n",
    "    new_samples_normal.append(new_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construímos o gráfico\n",
    "eixo_x = 'Peso'\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.distplot(new_samples_normal, axlabel = 'desvio-padrão')\n",
    "sns.distplot(new_samples_normal,\n",
    "             hist_kws=dict(cumulative=True),\n",
    "             kde_kws=dict(cumulative=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Z-score\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\\begin{equation*}\n",
    "Z \\sim \\dfrac{x - \\mu} {\\sigma^{2}\\,}\n",
    "\\end{equation*}\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "![z-score e suas probabilidades](http://www.portalaction.com.br/sites/default/files/EstatisticaBasica/figuras/distribuicaoNormal/normal3.PNG)\n",
    "\n",
    "Na estatística, o escore padrão **z-score** é o número fracionário assinado de desvios padrão pelo qual o valor de uma observação ou ponto de dados está acima do valor médio do que está sendo observado ou medido. Valores observados acima da média têm escores padrões positivos, enquanto valores abaixo da média têm escores padrão negativos.\n",
    "\n",
    "É calculado subtraindo a média populacional de uma pontuação bruta individual e dividindo a diferença pelo desvio padrão da população. É uma quantidade adimensional. Esse processo de conversão é chamado de padronização ou normalização (no entanto, \"normalização\" pode se referir a muitos tipos de proporções; consulte a normalização para saber mais).\n",
    "\n",
    "Os escores padrão também são chamados de valores z, escores z, escores normais e variáveis padronizadas. Eles são usados com mais frequência para comparar uma observação a um desvio teórico, como um desvio normal padrão.\n",
    "\n",
    "A computação de um escore z requer o conhecimento da média e do desvio padrão da população completa à qual um ponto de dados pertence; se alguém tiver apenas uma amostra de observações da população, então o cálculo análogo com média da amostra e desvio padrão da amostra produz a estatística-t."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avançado\n",
    "\n",
    "## Cálculo das probabilidades para os desvios-padrão da distribuição normal com Scipy.Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicanco Scipy.Stats para uma normal com média 0 e desvio-padrão 1\n",
    "\n",
    "media = 0\n",
    "desvio_padrao = 1\n",
    "\n",
    "import scipy.stats\n",
    "scipy.stats.norm(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilidade do intervalo de -1 desvio-padrão até 1 desvio-padrão\n",
    "\n",
    "2 * (scipy.stats.norm(media, desvio_padrao).cdf(1) - scipy.stats.norm(media, desvio_padrao).cdf(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilidade do intervalo de -2 desvios-padrão até 2 desvios-padrão\n",
    "\n",
    "2 * (scipy.stats.norm(media, desvio_padrao).cdf(2) - scipy.stats.norm(media, desvio_padrao).cdf(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilidade do intervalo de -3 desvios-padrão até 3 desvios-padrão\n",
    "\n",
    "2 * (scipy.stats.norm(media, desvio_padrao).cdf(3) - scipy.stats.norm(media, desvio_padrao).cdf(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilidade do intervalo de -4 desvios-padrão até 4 desvios-padrão\n",
    "\n",
    "2 * (scipy.stats.norm(media, desvio_padrao).cdf(4) - scipy.stats.norm(media, desvio_padrao).cdf(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RFBq4LpH2vjk"
   },
   "source": [
    "## Teste de Normalidade\n",
    "\n",
    "O test shapiro-wilks é um indicador de quão bem os nossos dados se ajustam à distribuição normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "h0rV4jm12vjl",
    "outputId": "d4e76aa2-0449-4789-d013-4e7c810ff748"
   },
   "outputs": [],
   "source": [
    "resultado_poisson = stats.shapiro(samples_uniforme)\n",
    "resultado_uniforme = stats.shapiro(samples_uniforme)\n",
    "resultado_binomial = stats.shapiro(samples_binomial)\n",
    "resultado_normal = stats.shapiro(samples_normal)\n",
    "\n",
    "print('poisson: ', resultado_poisson)\n",
    "print('uniforme:', resultado_uniforme)\n",
    "print('binomial:', resultado_binomial)\n",
    "print('normal: ', resultado_normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "MD8ZZ-vC2vjr"
   },
   "source": [
    "## Teste de Kolmogorow-Smirnov\n",
    "\n",
    "Em estatística, o teste Kolmogorov–Smirnov (também conhecido como teste KS ou teste K–S) é um teste não paramétrico sobre a igualdade de distribuições de probabilidade contínuas e unidimensionais que pode ser usado para comparar uma amostra com uma distribuição de probabilidade de referência (teste K–S uniamostral) ou duas amostras uma com a outra (teste K–S biamostral).[1] Recebe este nome em homenagem aos matemáticos russos Andrei Kolmogorov e Nikolai Smirnov.\n",
    "\n",
    "A estatística de Kolmogorov–Smirnov quantifica a distância entre a função distribuição empírica da amostra e a função distribuição acumulada da distribuição de referência ou entre as funções distribuição empírica de duas amostras. A distribuição nula desta estatística é calculada sob a hipótese nula de que a amostra é retirada da distribuição de referência (no caso uniamostral) ou de que as amostras são retiradas da mesma distribuição (no caso biamostral). Em cada caso, as distribuições consideradas sob a hipótese nula são distribuições contínuas, mas não restritas.\n",
    "\n",
    "O teste K–S biamostral é um dos métodos não paramétricos mais úteis e difundidos para a comparação de duas amostras, já que é sensível a diferenças tanto no local, como na forma das funções distribuição acumulada empírica das duas amostras.[2]\n",
    "\n",
    "O teste de Kolmogorov–Smirnov pode ser modificado para servir como um teste da qualidade do ajuste. No caso especial do teste da normalidade da distribuição, as amostras são padronizadas e comparadas com uma distribuição normal padrão. Isto equivale a tornar a média e a variância da distribuição de referência iguais aos estimados da amostras, sabendo que usar isto para definir a distribuição de referência específica muda a distribuição nula da estatística. Vários estudos encontraram que, mesmo nesta forma corrigida, o teste é menos potente em avaliar a normalidade do que o teste de Shapiro–Wilk e o teste de Anderson–Darling.[3] Entretanto, estes outros testes também têm suas desvantagens. O teste de Shapiro–Wilk, por exemplo, é conhecido por não funcionar bem em amostras com muitos valores idênticos. \n",
    "\n",
    "<br>\n",
    "<img src=\"img/teste_ks.png\">\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kstest, ks_2samp\n",
    "\n",
    "kstest(np.random.choice(samples_normal, 500, replace=False), 'norm')\n",
    "stats.kstest(samples_normal,'norm', alternative = 'greater', mode='asymp')\n",
    "stats.kstest(samples_normal,'norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_2samp(np.random.choice(samples_normal, 50, replace=False), np.random.choice(samples_normal, 50, replace=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapa com a origem e relação entre os tipos de distribuição de probabilidade\n",
    "\n",
    "<br> <br>\n",
    "![mapa_distribuicoes](http://blog.cloudera.com/wp-content/uploads/2015/12/distribution.png)\n",
    "<br> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "PRACTICA_GUIADA_Probabilidad_pt_br.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
