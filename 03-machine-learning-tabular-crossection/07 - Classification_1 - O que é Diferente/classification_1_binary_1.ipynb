{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 3.8.1 - Classification Basics - Metrics - Model Test Pipeline\n",
    "\n",
    "Fala galera! Na aula de hoje, entraremos num capítulo que trata de um dos problemas mais comuns para Machine Learning: classificação! Em problemas de classifcação, temos um dataset com elementos de diversas classes e temos que ser capazes de discerní-los. Podemos dividir esse problema em 3 tipos:\n",
    " - **Classificação Binária**: atribuir um datapoint como pertencente a 1 de 2 classes.\n",
    " - **Classificação Multiclasse**: atribuir um datapoint como pertencente a 1 de n classes, n > 2.\n",
    " - **Classificação Multilabel**: atribuir um datapoint como pertence a n de m classes, m > n. <br>\n",
    "Nessas 2 primeiras aulas, nosso foco será em classificação binária. Porém, antes de atacarmos um problema em específico, vamos esclarecer um conceito importantíssimo para classificação:\n",
    "\n",
    "# Sobre matrizes de confusão e suas métricas\n",
    "\n",
    "Numa classificação binária, temos 4 possíveis *outputs*: True Positive, False Positive, False Negative e True Negative. Podemos visualizar esses outputs numa matriz de confusão como essa: \n",
    "\n",
    "<img src=\"imgs/confusion_matrix.png\" align=\"left\" width=\"100%\">\n",
    "\n",
    "<br>\n",
    "\n",
    "Como podemos observar acima, trabalhamos com 4 métricas sobre essa matriz de confusão. Elas são:\n",
    " - **Accuracy**: de tudo o que você classificou, qual parte você acertou. É a primeira métrica que olhamos, mas algumas vezes ela pode não responder nossas perguntas de modo satisfatório e ocultar o que está acontecendo com os erros.\n",
    " - **Precision**: fração dos dados categorizados positivamente que são, de fato, casos positivos. É útil para sabermos quão confiável é nossa previsão para positivo.\n",
    " - **Recall / Sensivity**: fração de dados positivos categorizados de fato como positivos. Mostra como nosso modelo enxerga os dados positivos\n",
    " - **Specificity**: fração de dados negativos categorizados de fato como negativos. Mostra como nosso modelo enxerga os dados negativos.\n",
    "\n",
    "<br>\n",
    "Para cada problema de classificação binária, é interessante utilizar uma ou mais dessas métricas. A ideia é que sempre tenhamos controle não só da nossa acurácia, mas como estamos acertando e errando com nosso modelo, de modo a entender como melhorá-lo e quais as consequências dele nas previsões. Além das 4 métricas acima, também utilizamos o F1 Score, que é um balanço entre Precision e Recall, calculado por F1 = 2*((precision * recall) / (precision + recall)). <br>\n",
    "Com essas métricas em mãos, nos levamos à uma questão mais primordial: como escolher uma métrica para meu problema? Embora não exista uma resposta pronta para essa pergunta, é sempre interessante observarmos acurácia, precision e recall, juntas, para termos um entendimento do que está acontecendo :) <br>\n",
    "Separei alguns links para vocês irem mais a fundo nesse assunto de interpretar e escolher métricas:\n",
    "\n",
    " - __[Classification Accuracy is Not Enough: More Performance Measures You Can Use](https://machinelearningmastery.com/classification-accuracy-is-not-enough-more-performance-measures-you-can-use/)__\n",
    " - __[Data Science Performance Metrics for Everyone](https://machinelearningmastery.com/classification-accuracy-is-not-enough-more-performance-measures-you-can-use/)__\n",
    " - __[Measuring Model Goodness — Part 1](https://towardsdatascience.com/measuring-model-goodness-part-1-a24ed4d62f71)__\n",
    " - __[The 3 Pillars of Binary Classification: Accuracy, Precision & Recall](https://medium.com/@yashwant140393/the-3-pillars-of-binary-classification-accuracy-precision-recall-d2da3d09f664)__\n",
    "\n",
    "# Let's save some lifes\n",
    "\n",
    "Na aula de hoje, vamos trabalhar com o Breast Cancer Dataset. Ao invés de fazer o download, vamos aproveitar o módulo datasets do scikit! Esse dataset contém 13 atributos e 2 possíveis outcomes: M (Malign) ou B (Benign). Nossa tarefa será, a partir dos features, conseguir prever o tipo de tumor de cada paciente. Vamos primeiro fazer o loading do dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "# Import scikit-learn dataset library\n",
    "from sklearn import datasets\n",
    "\n",
    "# Load dataset\n",
    "cancer = datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "       'smoothness error', 'compactness error', 'concavity error',\n",
       "       'concave points error', 'symmetry error',\n",
       "       'fractal dimension error', 'worst radius', 'worst texture',\n",
       "       'worst perimeter', 'worst area', 'worst smoothness',\n",
       "       'worst compactness', 'worst concavity', 'worst concave points',\n",
       "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['malignant', 'benign'], dtype='<U9')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cancer.data, columns = cancer.feature_names).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, agora precisamos realizar o `train_test_split` dos nossos dados, uma vez que voltamos a realizar aprendizado supervisionado. Vamos fazer um split 80-20. Recomendo utilizar as aulas anteriores para isso! Na célula abaixo, realize o train-test-split criando 4 variáveis: X_train, X_test, y_train, y_test. Para reproducibilidade, vamos no tradicional random_state de 42, já que é a resposta para tudo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/solution_00.py\n",
    "\n",
    "# Import train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, test_size=0.2, random_state=42) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com nosso dados de treino e test, estamos prontos para aplicar nossos métodos de classificação! Vamos implementar uma logística e observar os resultados segundo as métricas que discutimos mais acima:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marcos.silva\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# %load solutions/solution_01.py\n",
    "#Import Logictic Regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Create a logistic regression Classifier\n",
    "clf = LogisticRegression()\n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x271c999b668>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(clf.predict_proba(X_test), columns=['zero', 'um'])['um'].plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Legal, montamos nosso modelo de regressão logística. Vamos montar a matriz de confusão dados os outputs do modelo e nossos targets. Para tal, importe o módulo `metrics` do scikit e crie uma variável cnf_matrix que recebe metrics.confusion_matrix(). Essa __[classe](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)__ recebe 2 argumentos: y_test e y_pred. Por fim, faça o `print()` da matriz!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[39,  4],\n",
       "       [ 1, 70]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %load solutions/solution_02.py\n",
    "\n",
    "from sklearn import metrics\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece então que temos 39 TP, 4 FP, 1 FN e 70 TN. Vamos puxar as métricas accuracy, precision e recall chamando os respectivos métodos de `metrics`. Eles são `.accuracy_score()`, `.precision_score()` e `.recall_score()`. Todos eles recebem 2 argumentos: y_test e y_pred. Faça o print das 3 métricas: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.956140350877193\n",
      "Precision: 0.9459459459459459\n",
      "Recall: 0.9859154929577465\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9655172413793103"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %load solutions/solution_03.py\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))\n",
    "\n",
    "metrics.f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cross_val_score(clf, cancer.data, cancer.target, cv = 10, scoring='recall' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9718253968253968, 0.018074514727661813)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.mean(), results.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['explained_variance', 'r2', 'neg_median_absolute_error', 'neg_mean_absolute_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'accuracy', 'roc_auc', 'balanced_accuracy', 'average_precision', 'neg_log_loss', 'brier_score_loss', 'adjusted_rand_score', 'homogeneity_score', 'completeness_score', 'v_measure_score', 'mutual_info_score', 'adjusted_mutual_info_score', 'normalized_mutual_info_score', 'fowlkes_mallows_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.SCORERS.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Olha só! Parece que fizemos um modelo muito bom para prever o perfil do câncer de mama dos datapoints observados! Nossas 3 métricas estão top-notch, todas acima de 90%. Essa é a maneira artesanal de fazer um classificador. Vamos para algo mais emocionante.\n",
    "\n",
    "## Let's save some lifes again\n",
    "\n",
    "Para esse exercício, usaremos o __[dataset](https://www.kaggle.com/uciml/pima-indians-diabetes-database)__ de diabetes da população indiana. Vamos explorar um pouco dele! Entre no link do Kaggle e faça o download do dataset na pasta data dessa aula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      "pregnant    768 non-null int64\n",
      "glucose     768 non-null int64\n",
      "bp          768 non-null int64\n",
      "skin        768 non-null int64\n",
      "insulin     768 non-null int64\n",
      "bmi         768 non-null float64\n",
      "pedigree    768 non-null float64\n",
      "age         768 non-null int64\n",
      "label       768 non-null int64\n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "col_names = ['pregnant', 'glucose', 'bp', 'skin', 'insulin', 'bmi', 'pedigree', 'age', 'label']\n",
    "\n",
    "pima = pd.read_csv(\"diabetes.csv\", header=0, names=col_names)\n",
    "\n",
    "pima.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnant</th>\n",
       "      <th>glucose</th>\n",
       "      <th>bp</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnant  glucose  bp  skin  insulin   bmi  pedigree  age  label\n",
       "0         6      148  72    35        0  33.6     0.627   50      1\n",
       "1         1       85  66    29        0  26.6     0.351   31      0\n",
       "2         8      183  64     0        0  23.3     0.672   32      1\n",
       "3         1       89  66    23       94  28.1     0.167   21      0\n",
       "4         0      137  40    35      168  43.1     2.288   33      1"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pima.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que temos 1 para casos positivos de diabetes e 0 para casos negativos. Num problema de classificação, é **muito importante que, sempre que possível, façamos o balanceamento de classes, senão o modelo aprenderá de modo enviesado**. Na célula abaixo, vamos realizar um `.groupby()` em label seguido de um `.count()` para checar se nosso dataset está balanceado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    500\n",
       "1    268\n",
       "Name: glucose, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pima.groupby('label').glucose.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, ele não está balanceado 50-50, mas pelo menos ele não está ordens de grandeza desbalanceado. Vamos seguir como ele está, observar os resultados e então decidir se vale a pena balancea-lo ou aplicar outras transformações. Abaixo, realize o train-test-split da mesma forma que o exercício anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset in features and target variable\n",
    "feature_cols = ['pregnant', 'insulin', 'bmi', 'age','glucose','bp','pedigree']\n",
    "X = pima[feature_cols] # Features\n",
    "y = pima.label # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/solution_04.py\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos aplicar a Regressão logística da mesma maneira. Ao final da construção das predictions, já chame as 3 métricas básicas de classificação binária!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7662337662337663\n",
      "Precision: 0.6938775510204082\n",
      "Recall: 0.6181818181818182\n"
     ]
    }
   ],
   "source": [
    "# %load solutions/solution_05.py\n",
    "\n",
    "# Create a svm Classifier\n",
    "clf = LogisticRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Print the 3 main binary classification metrics\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, dessa vez nossos resultados não deram tão certo...será que a regressão logística está realizando seu trabalho? Podemos observar isso pelo plot da curva ROC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2b1bdae7dd8>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_proba = clf.predict_proba(X_test)[::,1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\n",
    "auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
    "plt.legend(loc=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma coisa que podemos fazer é resolver esse problema na força bruta: puxar um monte de modelos, testar no nosso dataset e ver o que se sai melhor. Isso parece meio burro, mas realmente fazemos isso no nosso dia-a-dia: por que testar um modelo se podemos testar vários ao mesmo tempo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "KNeighborsClassifier\n",
      "****Results****\n",
      "Accuracy: 0.7142857142857143\n",
      "Precision: 0.5901639344262295\n",
      "Recall: 0.6545454545454545\n",
      "==============================\n",
      "GaussianNB\n",
      "****Results****\n",
      "Accuracy: 0.7662337662337663\n",
      "Precision: 0.6610169491525424\n",
      "Recall: 0.7090909090909091\n",
      "==============================\n",
      "LogisticRegression\n",
      "****Results****\n",
      "Accuracy: 0.7662337662337663\n",
      "Precision: 0.6938775510204082\n",
      "Recall: 0.6181818181818182\n",
      "==============================\n",
      "SVC\n",
      "****Results****\n",
      "Accuracy: 0.6428571428571429\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "==============================\n",
      "DecisionTreeClassifier\n",
      "****Results****\n",
      "Accuracy: 0.7532467532467533\n",
      "Precision: 0.6231884057971014\n",
      "Recall: 0.7818181818181819\n",
      "==============================\n",
      "RandomForestClassifier\n",
      "****Results****\n",
      "Accuracy: 0.7597402597402597\n",
      "Precision: 0.6607142857142857\n",
      "Recall: 0.6727272727272727\n",
      "==============================\n",
      "GradientBoostingClassifier\n",
      "****Results****\n",
      "Accuracy: 0.7532467532467533\n",
      "Precision: 0.6349206349206349\n",
      "Recall: 0.7272727272727273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abelardo/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/abelardo/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/abelardo/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/abelardo/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    GaussianNB(),\n",
    "    LogisticRegression(),\n",
    "    SVC(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    GradientBoostingClassifier()]\n",
    "\n",
    "\n",
    "for clf in classifiers:\n",
    "    clf.fit(X_train, y_train)\n",
    "    name = clf.__class__.__name__\n",
    "    \n",
    "    print(\"=\"*30)\n",
    "    print(name)\n",
    "    \n",
    "    print('****Results****')\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "    print(\"Precision:\", metrics.precision_score(y_test, y_pred))\n",
    "    print(\"Recall:\", metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É desse jeito que testamos vários modelos ao mesmo tempo, para então analisar seus outputs. Dados os resultados acima, qual classificador você escolheria? Existe mais de uma resposta certa para essa pergunta. Pessoalmente, eu pegaria o Naive-Bayes ou a Decision Tree. <br>\n",
    "Podemos observar também que os algoritmos apresentam performances semelhantes. Será que não vale a pena voltar ao dataset e tomar decisões sobre ele? Por exemplo, realizar um balanceamento e scaling devidos? Fica então o desafio para vocês melhorarem a performance não utilizando métodos mais complexos, mas usando o feijão com arroz que aprendemos até agora que é ter carinho e atenção com os dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnant</th>\n",
       "      <th>glucose</th>\n",
       "      <th>bp</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnant  glucose  bp  skin  insulin   bmi  pedigree  age  label\n",
       "0         6      148  72    35        0  33.6     0.627   50      1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pima.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pima_0 = pima[pima.label==0]\n",
    "pima_1 = pima[pima.label==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pima_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "268"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pima_0 = pima_0.sample(n=268, replace=True)\n",
    "len(pima_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pima = pd.concat([pima_0, pima_1], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    268\n",
       "1    268\n",
       "Name: pregnant, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pima.groupby('label').pregnant.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "KNeighborsClassifier\n",
      "****Results****\n",
      "Accuracy: 0.7962962962962963\n",
      "Precision: 0.7755102040816326\n",
      "Recall: 0.7755102040816326\n",
      "==============================\n",
      "GaussianNB\n",
      "****Results****\n",
      "Accuracy: 0.7407407407407407\n",
      "Precision: 0.7142857142857143\n",
      "Recall: 0.7142857142857143\n",
      "==============================\n",
      "LogisticRegression\n",
      "****Results****\n",
      "Accuracy: 0.7777777777777778\n",
      "Precision: 0.7358490566037735\n",
      "Recall: 0.7959183673469388\n",
      "==============================\n",
      "SVC\n",
      "****Results****\n",
      "Accuracy: 0.6666666666666666\n",
      "Precision: 0.5764705882352941\n",
      "Recall: 1.0\n",
      "==============================\n",
      "DecisionTreeClassifier\n",
      "****Results****\n",
      "Accuracy: 0.7685185185185185\n",
      "Precision: 0.7222222222222222\n",
      "Recall: 0.7959183673469388\n",
      "==============================\n",
      "RandomForestClassifier\n",
      "****Results****\n",
      "Accuracy: 0.8055555555555556\n",
      "Precision: 0.75\n",
      "Recall: 0.8571428571428571\n",
      "==============================\n",
      "GradientBoostingClassifier\n",
      "****Results****\n",
      "Accuracy: 0.7870370370370371\n",
      "Precision: 0.7407407407407407\n",
      "Recall: 0.8163265306122449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abelardo/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/abelardo/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/abelardo/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#split dataset in features and target variable\n",
    "feature_cols = ['pregnant', 'insulin', 'bmi', 'age','glucose','bp','pedigree']\n",
    "X = pima[feature_cols] # Features\n",
    "y = pima.label # Target variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    GaussianNB(),\n",
    "    LogisticRegression(),\n",
    "    SVC(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    GradientBoostingClassifier()]\n",
    "\n",
    "\n",
    "for clf in classifiers:\n",
    "    clf.fit(X_train, y_train)\n",
    "    name = clf.__class__.__name__\n",
    "    \n",
    "    print(\"=\"*30)\n",
    "    print(name)\n",
    "    \n",
    "    print('****Results****')\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "    print(\"Precision:\", metrics.precision_score(y_test, y_pred))\n",
    "    print(\"Recall:\", metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
