{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines para Automatizar Fluxos de Trabalho de Aprendizado de Máquina\n",
    "\n",
    "Há fluxos de trabalho padrão no aprendizado de máquina aplicado. Padrão porque eles superam problemas comuns, como vazamento de dados em seu equipamento de teste.\n",
    "\n",
    "Python scikit-learn fornece um utilitário Pipeline para ajudar a automatizar fluxos de trabalho de aprendizado de máquina.\n",
    "\n",
    "Os pipelines funcionam permitindo que uma sequência linear de transformações de dados seja encadeada, culminando em um processo de modelagem que pode ser avaliado.\n",
    "\n",
    "O objetivo é garantir que todas as etapas do pipeline sejam restritas aos dados disponíveis para a avaliação, como o conjunto de dados de treinamento ou cada dobra do procedimento de validação cruzada.\n",
    "\n",
    "Você pode aprender mais sobre Pipelines no scikit-learn lendo a seção Pipeline do guia do usuário . Você também pode revisar a documentação da API para as  classes Pipeline e  FeatureUnion no módulo de pipeline ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline 1: preparação e modelagem de dados\n",
    "Uma armadilha fácil de cair no aprendizado de máquina aplicado é o vazamento de dados do conjunto de dados de treinamento para o conjunto de dados de teste.\n",
    "\n",
    "Para evitar essa armadilha, você precisa de um equipamento de teste robusto com forte separação de treinamento e testes. Isso inclui preparação de dados.\n",
    "\n",
    "A preparação de dados é uma maneira fácil de vazar o conhecimento de todo o conjunto de dados de treinamento para o algoritmo. Por exemplo, preparar seus dados usando normalização ou padronização em todo o conjunto de dados de treinamento antes do aprendizado não seria um teste válido porque o conjunto de dados de treinamento teria sido influenciado pela escala dos dados no conjunto de testes.\n",
    "\n",
    "Os pipelines ajudam a evitar o vazamento de dados em seu equipamento de teste, garantindo que a preparação de dados, como a padronização, seja restrita a cada dobra do procedimento de validação cruzada.\n",
    "\n",
    "O exemplo abaixo demonstra esse importante fluxo de trabalho de preparação de dados e avaliação de modelos. O pipeline é definido com duas etapas:\n",
    "\n",
    "Padronize os dados.\n",
    "Aprenda um modelo de Análise Linear Discriminante.\n",
    "O pipeline é então avaliado usando validação cruzada de 10 vezes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.773462064251538\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline that standardizes the data then creates a model\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "# load data\n",
    "\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(url, names=names)\n",
    "array = dataframe.values\n",
    "\n",
    "\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "# create pipeline\n",
    "\n",
    "\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('lda', LinearDiscriminantAnalysis()))\n",
    "model = Pipeline(estimators)\n",
    "\n",
    "\n",
    "\n",
    "# evaluate pipeline\n",
    "seed = 7\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline 2: Extração e Modelagem de Recursos\n",
    "Extração de recurso é outro procedimento que é suscetível a vazamento de dados.\n",
    "\n",
    "Como a preparação de dados, os procedimentos de extração de recursos devem ser restritos aos dados em seu conjunto de dados de treinamento.\n",
    "\n",
    "O pipeline fornece uma ferramenta útil chamada FeatureUnion, que permite que os resultados de vários procedimentos de seleção e extração de recursos sejam combinados em um conjunto de dados maior no qual um modelo pode ser treinado. É importante ressaltar que toda a extração de recursos e a união de recursos ocorrem dentro de cada dobra do procedimento de validação cruzada.\n",
    "\n",
    "O exemplo abaixo demonstra o pipeline definido com quatro etapas:\n",
    "\n",
    "Extração de recursos com análise de componentes principais (3 recursos)\n",
    "Extração de recursos com seleção estatística (6 recursos)\n",
    "União de recursos\n",
    "Aprenda um modelo de regressão logística\n",
    "O pipeline é então avaliado usando validação cruzada de 10 vezes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7760423786739576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marco\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\marco\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\marco\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\marco\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\marco\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\marco\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\marco\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\marco\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\marco\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\marco\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline that extracts features from the data then creates a model\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "\n",
    "# load data\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(url, names=names)\n",
    "array = dataframe.values\n",
    "\n",
    "\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "\n",
    "\n",
    "# create feature union\n",
    "features = []\n",
    "features.append(('pca', PCA(n_components=3, random_state=42)))\n",
    "features.append(('select_best', SelectKBest(k=6, )))\n",
    "feature_union = FeatureUnion(features)\n",
    "\n",
    "\n",
    "# create pipeline\n",
    "estimators = []\n",
    "estimators.append(('feature_union', feature_union))\n",
    "estimators.append(('logistic', sklearn.ensambles.RandomForest()))\n",
    "model = Pipeline(estimators)\n",
    "\n",
    "\n",
    "# evaluate pipeline\n",
    "seed = 7\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resumo\n",
    "Neste post você descobriu as dificuldades do vazamento de dados no aprendizado de máquina aplicado.\n",
    "\n",
    "Você descobriu os utilitários de pipeline no Python-learn de Python e como eles podem ser usados ​​para automatizar fluxos de trabalho de aprendizado de máquina aplicados padrão.\n",
    "\n",
    "Você aprendeu a usar o Pipelines em dois casos de uso importantes:\n",
    "\n",
    "Preparação e modelagem de dados restrita a cada dobra do procedimento de validação cruzada.\n",
    "Extração de recurso e união de recurso restrita a cada dobra do procedimento de validação cruzada.\n",
    "Você tem alguma dúvida sobre vazamento de dados, pipelines ou este post? Faça suas perguntas nos comentários e eu farei o meu melhor para responder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
