{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercicios\n",
    "\n",
    "Utilize o dataset train.csv para os exercicios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estamos em 2015 e você trabalha em uma empresa que compra filmes para passar no cinema. Bons filmes custam caro, assim como filmes ruins barato, mas Bons filmes atraem mais público. Seu chefe sabe que você está aprendendo Machine Learning e te propõe a seguinte tarefa:  - Precisamos achar uma boa oportunidade que nos faça aumentar o lucro da empresa!\n",
    "\n",
    "Você conseguirá aumentar o lucro da empresa quando comprar um filme que é subvalorizado mas que as features dele indicam que será um bom filme.\n",
    "\n",
    "Se pudessemos descobrir quais filmes que as pessoas acham que seriam ruins mas na verdade são bons, poderiamos investir apenas nestes e ganhar a diferença já que foi mal precificado.\n",
    "\n",
    "\n",
    "Vamos partir dos seguintes pressupostos:\n",
    "- Um filme bom ou ruim do ponto de vista de quem está precificando será o tamanho do seu orçamento (budget).\n",
    "\n",
    "- Um filme Bom/Ruim do ponto de vista do público serão filmes com altas notas (imdb_score).\n",
    "\n",
    "Então vamos procurar os filmes que tenham uma boa relação entre budget e score.\n",
    "(é como se quisessemos comprar scores pois isso que o público quer ver mas os donos dos filmes vendem baseado no budget do filme).\n",
    "\n",
    "O primeiro passo é entendermos bem o problema e os dados disponíveis.\n",
    "\n",
    "Por exemplo, se vamos comprar um filme, algumas features não estarão disponiveis antes da compra (elas são criadas apenas após a compra) para predizer o rating como as vendas de ingresso, faturamento, etc.\n",
    "\n",
    "Depois separamos nos nossos dados quais serão nossas variáveis explicativas (Os X) e qual é nossa variável target (nosso Y).\n",
    "\n",
    "Caso algumas das nossas variáveis explicativas sejam categórias, precisamos transforma-las em numéricas para que o modelo consiga entende-la.\n",
    "\n",
    "Podemos utilizar uma função do pandas dessa forma:\n",
    "\n",
    "``` df = pd.get_dummies(df) ```\n",
    "\n",
    "O último passo antes de rodar um modelo é dividir nossos dados em duas partes, uma para treinar o modelo e outra para testa-lo, podemos fazer uma amostra aleatória ou usar a função do sklearn que nos ajuda com isso:\n",
    "\n",
    "```\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    " X_train, X_test, y_train, y_test = train_test_split(df[X], df[y], test_size=0.33, random_state=42)\n",
    "```\n",
    "Para isso Treine um Modelo de Machine Learning supervisionado que aprenda a predizer as notas dos filmes.\n",
    "\n",
    "Utilize os 4 passos visto na primeira aula de machine learning:\n",
    "```from sklearn.linear_model import LinearRegression```\n",
    "\n",
    "Após treinar o modelo vamos ver como estão as [métricas](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics) de assertividade.\n",
    "\n",
    "Analisar o R2, RMSE, MSE. Qual é o melhor nesse caso?\n",
    "\n",
    "Exemplo do MSE\n",
    "```\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mean_squared_error(y_true, y_pred)\n",
    "```\n",
    "\n",
    "Como poderiamos melhorar esse modelo? Será que existe algum método para colocar todas as variáveis ao quadrado, cubo, etc para que possamos capturar efeitos não lineares? Óbviamente existe e já foi implementado no sklearn, podemos usar a função:\n",
    "\n",
    "```\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(degree=3)\n",
    "\n",
    "df = poly.fit_transform(df)\n",
    "```\n",
    "\n",
    "Aparentemente sempre que aumentamos o grau do polinomio nosso modelo fica melhor, porque não podemos botar um número alto como 10?\n",
    "\n",
    "Rode o algoritmo com um grau = 10 e compare as métricas de treino contra as métricas de teste. O que está acontecendo?\n",
    "\n",
    "Parece que estamos chegando perto de um modelo bom para nosso objetivo de identificar oportunidade nos filmes. Será que poderiamos utilizar outro método de regressão mais robusto? Vamos tentar utilizar um dos melhores métodos que utiliza arvores aleatórias (usado geralmente em classificação e as estudaremos mais profundamente no módulo 4) como modelo:\n",
    "\n",
    "Treine agora o mesmo modelo utilizando um modelo não-linear (não exige que as correlações sejam lineares) e compare as métricas.\n",
    "\n",
    "```from sklearn.ensemble import RandomForestRegressor```\n",
    "\n",
    "\n",
    "\n",
    "Agora estamos em 2016. Use seu modelo treinado com todos os filmes até 2015 para responder a pergunta do seu chefe com os filmes que apareceram em 2016: Quais são os filmes que são realmente oportunidades de ganhar dinheiro (altos ratings, baixo custo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passo 1 - Entender o problema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O problema está descrito no tutorial acima. O que não está escrito é qual abordagem deveriamos ter para resolve-lo.\n",
    "\n",
    "Vamos pensar em uma possibilidade de solução aqui e escreveremos todo o restante do código pensando em como alcançar esse resultado.\n",
    "\n",
    "Não existe um só caminho para resolver esse problema, mas a solução que eu pensei em aplicar é a seguinte:\n",
    "\n",
    "    1) de um lado os donos dos filmes precificam seus produtos com base em quanto gastaram.\n",
    "\n",
    "    2) Seguindo o pressuposto do problema, o sucesso de bilheteria do filme depende apenas das notas que as pessoas vão dar a ele.\n",
    "\n",
    "Com isso chegamos a conclusão que o melhor filme para apostarmos são aqueles que a relação entre o preço (1-custo) e o (2-receita) é a mais vantajoso para nós.\n",
    "\n",
    "Uma forma de pensar é que temos que \"comprar\" scores então procuraremos os scores mais baratos que será dado por (1)/(2) -> custo do filme / beneficio do filme.\n",
    "\n",
    "Então precisamos treinar um modelo de machine learning que quando chegar um filme novo, prediga com o máximo de acurácia a nota média que as pessoas darão para ele ( o quociente na nossa equação) já que o númerador (o custo do filme) já saberemos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agora vamos fazer uma cópia do nosso dataframe.\n",
    "# Note que usamos a função deep=True pois só assim garantimos que o \n",
    "# dado está duplicado e não é apenas um \"atalho\" para o dataset original\n",
    "df = df_raw.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passo 2 - Escolher as variáveis.\n",
    "\n",
    "\n",
    "Definido claramente o que vamos fazer, vamos olhar as variáveis disponiveis e ver o que faz ou não sentido incluir.\n",
    "\n",
    "Diferentemente de modelagem estatistica, em machine learning não estamos preocupados com as variáveis serem correlacionadas, então não há um bom motivo (por hora) para retirarmos variáveis do modelo, portanto, meu primeiro modelo de 'benchmark' terá o máximo de variáveis/features possível.\n",
    "\n",
    "Algumas são facilmente excluidas, pois mesmo que sejam boas preditoras como o tamanho da bilheteria, ela só estará disponível após o filme ser lançado. Parte bastante importante da definição de um modelo de machine learning é pensar nesses pontos, de quais variáveis estarão disponiveis em um modelo de produção e isso, muitas vezes, pode ser bastante complicado por conta do carater temporal das variáveis tornando-se um \"leakage\" ou seja, um vazamento de dados.\n",
    "\n",
    "\n",
    "Variáveis como gross sabemos que não estará disponivel antes do lançamento então não vamos usa-la para treinar nosso modelo.\n",
    "\n",
    "Outra variável que não faz sentido para um modelo de machine é aquela que identifica o filme como um id, index ou o nome do filme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unnamed: 0',\n",
       " 'color',\n",
       " 'director_name',\n",
       " 'num_critic_for_reviews',\n",
       " 'duration',\n",
       " 'director_facebook_likes',\n",
       " 'actor_3_facebook_likes',\n",
       " 'actor_2_name',\n",
       " 'actor_1_facebook_likes',\n",
       " 'gross',\n",
       " 'genres',\n",
       " 'actor_1_name',\n",
       " 'movie_title',\n",
       " 'num_voted_users',\n",
       " 'cast_total_facebook_likes',\n",
       " 'actor_3_name',\n",
       " 'facenumber_in_poster',\n",
       " 'plot_keywords',\n",
       " 'movie_imdb_link',\n",
       " 'num_user_for_reviews',\n",
       " 'language',\n",
       " 'country',\n",
       " 'content_rating',\n",
       " 'budget',\n",
       " 'title_year',\n",
       " 'actor_2_facebook_likes',\n",
       " 'imdb_score',\n",
       " 'aspect_ratio',\n",
       " 'movie_facebook_likes']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['Unnamed: 0', 'gross', 'movie_title', 'plot_keywords']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw.drop(columns_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['color',\n",
       " 'director_name',\n",
       " 'num_critic_for_reviews',\n",
       " 'duration',\n",
       " 'director_facebook_likes',\n",
       " 'actor_3_facebook_likes',\n",
       " 'actor_2_name',\n",
       " 'actor_1_facebook_likes',\n",
       " 'genres',\n",
       " 'actor_1_name',\n",
       " 'num_voted_users',\n",
       " 'cast_total_facebook_likes',\n",
       " 'actor_3_name',\n",
       " 'facenumber_in_poster',\n",
       " 'movie_imdb_link',\n",
       " 'num_user_for_reviews',\n",
       " 'language',\n",
       " 'country',\n",
       " 'content_rating',\n",
       " 'budget',\n",
       " 'title_year',\n",
       " 'actor_2_facebook_likes',\n",
       " 'imdb_score',\n",
       " 'aspect_ratio',\n",
       " 'movie_facebook_likes']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passo 3 - Tratando as variáveis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Essa é a etapa mais longa, mais importante e mais dificil de um problema de machine learning.** (falaremos mais sobre essas técnicas nas próximas aulas)\n",
    "\n",
    "Essa etapa podemos usar todos os tratamentos de variáveis que aprendemos na modelagem estatistica quando estavamos rodando regressões simples. Não vou repetir os tratamentos mas todos podem ser utilizados.\n",
    "\n",
    "\n",
    "#### Campos nulos.\n",
    "\n",
    "Quando rodamos um dff.describe() percebemos muitos campos nulos e há diversas formas de trata-los.\n",
    "\n",
    "Alternativas para tratar nulos.\n",
    "\n",
    "1) Deleter todos os nulos.\n",
    "\n",
    "```\n",
    "df = df.dropna()\n",
    "```\n",
    "\n",
    "2) Substituir os nans pelas médias (nas numéricas) ou modas (nas categóricas).\n",
    "\n",
    "df['numericas'] = df['numericas'].fillna(df.mean())\n",
    "\n",
    "\n",
    "3) rodar um \"pré-ML\" que prevê os valores faltantes.\n",
    "\n",
    "\n",
    "\n",
    "4) Usar um algoritmo robusto para campos nulos.\n",
    "\n",
    "ex:\n",
    "\n",
    "```\n",
    "import xgboost as xgb\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos usar uma abordagem mista. Nas variáveis numéricas vamos substituir pela média e nas variáveis categóricas vamos excluir as linhas com campos nulos para aprender as duas metodologias. \n",
    "\n",
    "(conforme vimos em estatistica, excluir linhas que não são aleatórias enviesam nosso modelo e não deve ser feito a menos que você tenha certeza que aqueles nulos são por alguma falha aleatória o que é bastante raro. Não sendo aleatório devemos tratar com uma das outras metodologias, principalmente a número 4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "color                         object\n",
       "director_name                 object\n",
       "num_critic_for_reviews       float64\n",
       "duration                     float64\n",
       "director_facebook_likes      float64\n",
       "actor_3_facebook_likes       float64\n",
       "actor_2_name                  object\n",
       "actor_1_facebook_likes       float64\n",
       "genres                        object\n",
       "actor_1_name                  object\n",
       "num_voted_users                int64\n",
       "cast_total_facebook_likes      int64\n",
       "actor_3_name                  object\n",
       "facenumber_in_poster         float64\n",
       "movie_imdb_link               object\n",
       "num_user_for_reviews         float64\n",
       "language                      object\n",
       "country                       object\n",
       "content_rating                object\n",
       "budget                       float64\n",
       "title_year                   float64\n",
       "actor_2_facebook_likes       float64\n",
       "imdb_score                   float64\n",
       "aspect_ratio                 float64\n",
       "movie_facebook_likes         float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric = df.select_dtypes(include=[np.number]) # dataset apenas com colunas numéricas.\n",
    "numericas = list(df_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nessa função selecionamos todas as colunas númericas e substituimos seus \n",
    "# valores pelas médias das colunas. A função fillna retorna todos os campos \n",
    "# nulos e a função df.mean retorna as médias de cada coluna.\n",
    "df[numericas] = df[numericas].fillna(df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4937, 25)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# já nas variáveis categóricas (que contém texto ao invés de números)\n",
    "# vamos substituir os campos nulos por uma nova string que representa que aquele campo é faltante.\n",
    "df = df.fillna('na') # substitui os dados faltantes por 'na'\n",
    "df = df.dropna() # se sobrar alguma linha (nao deveria), dropamos essas linhas.\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4937, 25)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nossa segunda etapa de tratamento das variáveis consiste em transformar as variáveis em funções lineares (se estivermos rodando modelos lineares) através da aplicação de log nas variáveis \"explosivas\" tornando-a linear. Não faremos essa etapa pois nosso objetivo é rodar um algoritmo não linear em seguida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A terceira etapa de preparação dos dados é criar variáveis dummies para nossas features categóricas.\n",
    "\n",
    "Basicamente os algoritmos de machine learning não conseguem interpretar textos como o genêro de um filme ou os atores que participaram então precisamos transformar essas colunas categóricas em colunas numéricas para que o algoritmo possa capturar seus efeitos e predizer nosso target.\n",
    "\n",
    "Substituir as categorias por números dessa forma: COluna genêro de filme com valores [Terror=1, Comédia=2, Ação=3] embora faça o algoritmo rodar, não funcionará bem como variável explicativa pois elas não representam uma sequencia numérica. A forma mais simples de fazermos isso virar uma variável explicativa é pegar cada uma das categorias possíveis e transformar em uma coluna forma única que recebe apenas dois valores, 0 e 1. 0 se o valor não estiver presente e 1 caso esteja presente. Dessa forma nossa  representação ficará da seguinte forma. \n",
    "\n",
    "- Coluna 1 = genero_terror\n",
    "- Coluna 2 = genero_comédia\n",
    "- Coluna 3 = genero_ação\n",
    "\n",
    "Assumindo 1 ou 0 dependendo do filme.\n",
    "\n",
    "Uma observação sobre essa técnica é que não é necessário colocar todas as possibilidades, uma delas se torna redundante e ao modelar esse caso podemos excluir uma delas.\n",
    "\n",
    "Essa técninca chamamos de one_hot (sklearn) e no pandas temos a função get_dummies que faz o mesmo processo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4937, 16728)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aumentamos das 26 colunas originais para mais de 15mil colunas!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passo 4 - Treinando o modelo de Machine Learning\n",
    "\n",
    "Essa é a etapa mais simples mas que exige mais experiência.\n",
    "\n",
    "1) qual algoritmos escolher?\n",
    "\n",
    "Sabemos que nosso problema se trata de prever uma variável continua (uma nota) e como temos diversas notas para treina-lo podemos usar uma abordagem supervisionado.\n",
    "\n",
    "(obs: poderiamos tentar transformar cada intervalo de notas em uma categoria, ex: [0,1] -> 1, [1,2] -> 2 .... [9,10] -> 10 e prever usando um algoritmo de classificação, mas como as notas fazem sentido como uma variável numérica, ou seja, a nota seguinte é a nota anterior + 1, um algoritmo de classificação dificilmente superaria um de regressão já que as probabilidades de cada classe prevista em uma classificação é independente, é como se uma nota não tivesse nenhuma relação com a outra e isso não é verdade no nosso caso).\n",
    "\n",
    "Então:\n",
    "\n",
    "    Supervisionado -> Regressão\n",
    "    \n",
    "    \n",
    "Mas há dezenas de algoritmos de regressão (ver todos os disponiveis no sklearn nesse link: http://scikit-learn.org/stable/supervised_learning.html )\n",
    "\n",
    "Alguns deles:\n",
    "- MQO (o mais simples que estudamos em estatistica e abrimos o código na aula2 de machine learning).\n",
    "- Ridge -> Método de Shrinkage. Conrola sobreajuste com L1\n",
    "\n",
    "    $L = ∑( Ŷi– Yi)^2 + λ∑ β^2$\n",
    "\n",
    "\n",
    "- lasso -> Também método de Shrinkage. controle sobreajuste com L2\n",
    "\n",
    "   $ L = ∑( Ŷi– Yi)^2 + λ∑ |β|$\n",
    "\n",
    "\n",
    "- elasticnet -> combinação de Lasso + Ridge\n",
    "- Regressão Bayesiana -> Retorna distribuições de probabilidade ao invés de simples valores.\n",
    "\n",
    "    Ex: https://towardsdatascience.com/introduction-to-bayesian-linear-regression-e66e60791ea7?gi=392eaf9ea3b \n",
    "    \n",
    "- Arvores aleatórias -> insere não lineariedades\n",
    "- Redes neurais -> também insere não lineariedades.\n",
    "- Ensambles -> Combinação de diferentes modelos.\n",
    "- Etc\n",
    "\n",
    "\n",
    "Qual usar ?\n",
    "\n",
    "No nosso exemplo vamos usar o mais simples MQO para usar de comparativo e um extremamente poderoso que são as arvores aleatórias (que ainda não vimos seu funcionamento).\n",
    "\n",
    "Na prática, quando colocamos um modelo em produção, podemos rodar diferentes algoritmos (que tem suas próprias vantagens e desvantagens) e pegar uma combinação desses diferentes algoritmos como o resultado final. A essa combinação de modelos damos o nome de **ensamble**.\n",
    "\n",
    "Para rodar qualquer modelo de machine learning desses, vamos passar pelos mesmos passos:\n",
    "\n",
    "    1) Importar o modelo desejado.\n",
    "    2) Instanciar em uma variável com os parâmetros desejados (ainda não vimos os parâmetros).\n",
    "    3) Separar nossos dados em variáveis explicativas (X) e explicadas/target (Y)\n",
    "    4) Separar nossos dados em Treino e Teste\n",
    "    5) Treinar o Modelo com o .fit()\n",
    "    6) Analisar as métricas, se não estiver boas, voltamos aos passos anteriores de trabalhar com as variáveis.\n",
    "    7) Estando tudo ok, rodamos previsões"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) Importar modelos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Instanciar os modelos em variáveis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_MQO = LinearRegression()\n",
    "modelo_RF = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) Separar os dados em X e Y**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['imdb_score'], axis = 1)\n",
    "Y = df['imdb_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4) Separar os dados em Treino e Teste ** \n",
    "\n",
    "Esse ponto é crucial em machine learning e falaremos mais vezes sobre diferentes técnicas em \"splitar\" os dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3949, 16727)\n",
      "(988, 16727)\n",
      "(3949,)\n",
      "(988,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "900 / (900 + 3600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5) Treinar o Modelo para que o algoritmo descrubra os melhores betas (que produzem os menores erros)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo_MQO.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6) Após treinar o modelo podemos analisar suas métricas e aqui é uma parte sensivel, vamos entender algumas métricas.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Dados de Treino-----\n",
      "MSE - treino 3.4614227492080305e-10\n",
      "MAE - treino 1.160846905179369e-05\n",
      "R2 - treino 0.9999999997291479\n",
      "\n",
      "-----Dados de Teste-----\n",
      "MSE - test 0.6794077192742255\n",
      "MAE - test 0.47469819667708535\n",
      "R2 - test 0.4369571865956374\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, median_absolute_error\n",
    "\n",
    "yhat_train = modelo_MQO.predict(X_train) # previsao dos dados de treino para calcular as métricas\n",
    "yhat_test = modelo_MQO.predict(X_test) # previsao dos dados de teste para calcular métricas\n",
    "\n",
    "print('-----Dados de Treino-----')\n",
    "print('MSE - treino', mean_squared_error(y_train, yhat_train))\n",
    "print('MAE - treino', median_absolute_error(y_train, yhat_train))\n",
    "print('R2 - treino', r2_score(y_train, yhat_train))\n",
    "\n",
    "print('\\n-----Dados de Teste-----')\n",
    "print('MSE - test', mean_squared_error(y_test, yhat_test))\n",
    "print('MAE - test', median_absolute_error(y_test, yhat_test))\n",
    "print('R2 - test', r2_score(y_test, yhat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos entender primeiro as métricas e em seguida entender a diferença entre os números de treino e de teste.\n",
    "\n",
    "**O que é o MSE e o MAE**\n",
    "MSE: Erros médios quadraticos.\n",
    "MAE: Erros médios absolutos.\n",
    "\n",
    "Qual a diferença entre eles?\n",
    "\n",
    "Pensemos no caso de um dataset com muitos outlinears, qual das duas métricas será mais prejudica (ou seja, qual métrica é mais sensivel a dados muito fora do padrão?). Nosso métrica ao quadrado é mais sensivel pois pegamos a diferença entre o valor predito e o realizado e elevamos ao quadrado tornando a diferença ainda maior. Já o MAE não é tão sensivel aos valores extremos pois consideramos apenas a distância absoluta que da o mesmo peso a distâncias grandes e pequenas.\n",
    "Ex: Valor predito = 8, Valor Real = 5.\n",
    "MAE= 8-5 = 3\n",
    "MSE= (8-5)^2 = 9 -> Penaliza erros maiores.\n",
    "\n",
    "\n",
    "Já o R2 é a mesma intepretação que demos em modelagem estatistica (% da variação de Y explicada por todas as variáveis explicativas X). Só que agora nosso objetivo é aumentar ao máximo nosso R2.\n",
    "\n",
    "\n",
    "\n",
    "** Métricas de Treino e Métricas de Teste **\n",
    "\n",
    "O grande objetivo de um modelo de aprendizado de maquina (ML) é termos um modelo que é preditivo para novos dados, ou seja, precisamos de um modelo que seja bastante genérico, que depois de treinado pode pegar dados que não estavam na amostra e consiga prever seu target com uma boa precisão.\n",
    "\n",
    "Então ter boas métricas nos dados de treino não significam necessariamente que o modelo é um bom preditor. Para isso ele precisa ter boas métricas nos dados de teste! (aquela parte dos dados que separamos e não participaram do treino). Se nosso algoritmo é capaz de prever de maneira satisfatória nossos dados de teste (que são dados novos para ele já que não participaram do treino) esse é um bom modelo.\n",
    "\n",
    "Quando as métricas dos dados de treino estão muito superiores aos dados de teste (como no nosso exemplo) significa que estamos fazendo um superajuste/sobreajuste ou como gostamos de chamar o modelo está com overfiting. Significa basicamente que nosso modelo se tornou especialista em prever nossos dados de treino mas não necessariamente é um bom modelo para prever dados fora do treinamento. Há muitas formas de contornar isso que veremos nas próximas aulas, mas a mais importante que faremos aqui é tentar equilibrar a complexidade do modelo, basicamente colocamos mais variáveis do que seria necessario.\n",
    "\n",
    "É aqui que voltamos ao passo de escolher e tratar variaveis e rodamos tudo novamente.\n",
    "Vamos fazer todos os processos na próxima linha e colocar um modelo um pouco mais simples:\n",
    "\n",
    "\n",
    "<img src=\"img\\overfit.png\" style=\"height:250px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos remover algumas colunas que podem estar causando um superajuste/overfiting no nosso modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unnamed: 0',\n",
       " 'color',\n",
       " 'director_name',\n",
       " 'num_critic_for_reviews',\n",
       " 'duration',\n",
       " 'director_facebook_likes',\n",
       " 'actor_3_facebook_likes',\n",
       " 'actor_2_name',\n",
       " 'actor_1_facebook_likes',\n",
       " 'gross',\n",
       " 'genres',\n",
       " 'actor_1_name',\n",
       " 'movie_title',\n",
       " 'num_voted_users',\n",
       " 'cast_total_facebook_likes',\n",
       " 'actor_3_name',\n",
       " 'facenumber_in_poster',\n",
       " 'plot_keywords',\n",
       " 'movie_imdb_link',\n",
       " 'num_user_for_reviews',\n",
       " 'language',\n",
       " 'country',\n",
       " 'content_rating',\n",
       " 'budget',\n",
       " 'title_year',\n",
       " 'actor_2_facebook_likes',\n",
       " 'imdb_score',\n",
       " 'aspect_ratio',\n",
       " 'movie_facebook_likes']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0\n",
      "director_name\n",
      "actor_2_name\n",
      "actor_1_name\n",
      "actor_3_name\n",
      "plot_keywords\n",
      "movie_imdb_link\n"
     ]
    }
   ],
   "source": [
    "for column in list(df_raw):\n",
    "    if 'likes' in column:\n",
    "        pass\n",
    "    elif 'name' in column or 'link' in column or 'Unnamed: 0' in column or 'plot_keywords' in column:\n",
    "        print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overfiting_columns = []\n",
    "\n",
    "for column in list(df):\n",
    "    if 'likes' in column:\n",
    "        pass\n",
    "    elif 'name' in column or 'link' in column or 'Unnamed: 0' in column:\n",
    "        overfiting_columns.append(column)\n",
    "        \n",
    "print(f'#columns_to_drop: {len(overfiting_columns)}')\n",
    "df = df.drop(overfiting_columns, axis=1)\n",
    "df = pd.get_dummies(df)\n",
    "\n",
    "print(f'new_shape: {df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mqo(df, model):\n",
    "    X = df.drop(['imdb_score'], axis = 1)\n",
    "    Y = df['imdb_score']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25)    \n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "    yhat_train = model.predict(X_train) # previsao dos dados de treino para calcular as métricas\n",
    "    yhat_test = model.predict(X_test[list(X_train)]) # previsao dos dados de teste para calcular métricas\n",
    "\n",
    "    print('-----Dados de Treino-----')\n",
    "    print('MSE - treino', mean_squared_error(y_train, yhat_train))\n",
    "    print('MAE - treino', median_absolute_error(y_train, yhat_train))\n",
    "    print('R2 - treino', r2_score(y_train, yhat_train))\n",
    "\n",
    "    print('\\n-----Dados de Teste-----')\n",
    "    print('MSE - test', mean_squared_error(y_test, yhat_test))\n",
    "    print('MAE - test', median_absolute_error(y_test, yhat_test))\n",
    "    print('R2 - test', r2_score(y_test, yhat_test))\n",
    "    \n",
    "run_mqo(df, LinearRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos passar agora agora um segundo modelo que consegue capturar, entre outras coisas, não lineariedades:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Dados de Treino-----\n",
      "MSE - treino 0.12606231766612644\n",
      "MAE - treino 0.16000000000000014\n",
      "R2 - treino 0.8985825079310189\n",
      "\n",
      "-----Dados de Teste-----\n",
      "MSE - test 0.7349672874493928\n",
      "MAE - test 0.4399999999999995\n",
      "R2 - test 0.4454201027866417\n"
     ]
    }
   ],
   "source": [
    "run_mqo(df, RandomForestRegressor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece bem melhor agora, tanto o R2 aumentou como ficou mais parecido entre treino e teste sugerindo que não estou dando overfiting no modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ainda criar modelos um pouco mais complexos inserindo formas quadraticas, cubicas, etc para tentar capturar algum efeito não linear nos dados.\n",
    "\n",
    "Idealmente plotariamos as variáveis e escolheriamos as que fazem mais sentido colocar variaveis quadraticas, etc. Mas na prática rodamos um algoritmo para passar um polinomio em todas as nossas variáveis como no código abaixo:\n",
    "\n",
    "Obs: Colocamos todos os passos da regressão em uma função para não termos que ficar repetindo mais códigos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(y_train, yhat_train,y_test, yhat_test):\n",
    "    print('\\n-----Dados de Treino-----')\n",
    "    print('MSE - treino', mean_squared_error(y_train, yhat_train))\n",
    "    print('MAE - treino', median_absolute_error(y_train, yhat_train))\n",
    "    print('R2 - treino', r2_score(y_train, yhat_train))\n",
    "\n",
    "    print('\\n-----Dados de Teste-----')\n",
    "    print('MSE - test', mean_squared_error(y_test, yhat_test))\n",
    "    print('MAE - test', median_absolute_error(y_test, yhat_test))\n",
    "    print('R2 - test', r2_score(y_test, yhat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "numeric_columns = ['num_critic_for_reviews',\n",
    "                     'duration',\n",
    "                     'director_facebook_likes',\n",
    "                     'actor_3_facebook_likes',\n",
    "                     'actor_1_facebook_likes',\n",
    "                     'num_voted_users',\n",
    "                     'cast_total_facebook_likes',\n",
    "                     'facenumber_in_poster',\n",
    "                     'num_user_for_reviews',\n",
    "                     'budget',\n",
    "                     'title_year',\n",
    "                     'actor_2_facebook_likes',\n",
    "                     'aspect_ratio',\n",
    "                     'movie_facebook_likes']\n",
    "\n",
    "dummies = []\n",
    "\n",
    "for column in list(df):\n",
    "    if 'imdb_score' in column:\n",
    "        pass\n",
    "    elif column not in numeric_columns:\n",
    "        dummies.append(column)\n",
    "            \n",
    "def run_model_with_poly(dataframe, poly_n, modelo):\n",
    "        \n",
    "    poly = PolynomialFeatures(degree=poly_n)\n",
    "\n",
    "    newX = dataframe[dummies+numeric_columns]\n",
    "    print('newX shape', newX.shape)\n",
    "    \n",
    "    newY = dataframe['imdb_score']\n",
    "    \n",
    "    df_temp = pd.DataFrame(poly.fit_transform(newX[numeric_columns]))\n",
    "    print('\\ndf_temp shape', df_temp.shape)\n",
    "    \n",
    "    df_temp = pd.concat([df_temp,dataframe[dummies].reset_index()], axis=1)\n",
    "    print('df_temp shape', df_temp.shape)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_temp,newY,test_size=0.2)\n",
    "\n",
    "    print('\\ntrain shape', X_train.shape)\n",
    "    print('teste shape', X_test.shape)\n",
    "    \n",
    "    modelo.fit(X_train, y_train)\n",
    "\n",
    "    yhat = modelo.predict(X_train)\n",
    "    yhat_test = modelo.predict(X_test[list(X_train)])\n",
    "\n",
    "    print_metrics(y_train, yhat, y_test, yhat_test)\n",
    "    return modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparando nossos dois modelos (MQO vs Arvores Aleatórias) parece que as segunda consegue superar as métricas no treino e no teste então vamos usar esse modelo em produção (ou seja, para realizar nosso trabalho)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newX shape (4937, 1046)\n",
      "\n",
      "df_temp shape (4937, 15)\n",
      "df_temp shape (4937, 1048)\n",
      "\n",
      "train shape (3949, 1048)\n",
      "teste shape (988, 1048)\n",
      "\n",
      "-----Dados de Treino-----\n",
      "MSE - treino 0.464623308253822\n",
      "MAE - treino 0.3288167293337212\n",
      "R2 - treino 0.6382568795489624\n",
      "\n",
      "-----Dados de Teste-----\n",
      "MSE - test 0.6392919158029365\n",
      "MAE - test 0.49085686864009404\n",
      "R2 - test 0.4585404877019176\n"
     ]
    }
   ],
   "source": [
    "model1 = run_model_with_poly(df, 1, LinearRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newX shape (4937, 1046)\n",
      "\n",
      "df_temp shape (4937, 120)\n",
      "df_temp shape (4937, 1153)\n",
      "\n",
      "train shape (3949, 1153)\n",
      "teste shape (988, 1153)\n",
      "\n",
      "-----Dados de Treino-----\n",
      "MSE - treino 0.8402968139718888\n",
      "MAE - treino 0.5330488904305888\n",
      "R2 - treino 0.35109550966948877\n",
      "\n",
      "-----Dados de Teste-----\n",
      "MSE - test 1.0394061919562865\n",
      "MAE - test 0.5225989807184295\n",
      "R2 - test 0.08637961565854357\n"
     ]
    }
   ],
   "source": [
    "model2 = run_model_with_poly(df, 2, LinearRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newX shape (4937, 1046)\n",
      "\n",
      "df_temp shape (4937, 15)\n",
      "df_temp shape (4937, 1048)\n",
      "\n",
      "train shape (3949, 1048)\n",
      "teste shape (988, 1048)\n",
      "\n",
      "-----Dados de Treino-----\n",
      "MSE - treino 0.11800278551532034\n",
      "MAE - treino 0.15999999999999925\n",
      "R2 - treino 0.9067922373630145\n",
      "\n",
      "-----Dados de Teste-----\n",
      "MSE - test 0.6664698380566801\n",
      "MAE - test 0.46000000000000085\n",
      "R2 - test 0.4685376381152988\n"
     ]
    }
   ],
   "source": [
    "model3 = run_model_with_poly(df, 1, RandomForestRegressor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newX shape (4937, 1046)\n",
      "\n",
      "df_temp shape (4937, 120)\n",
      "df_temp shape (4937, 1153)\n",
      "\n",
      "train shape (3949, 1153)\n",
      "teste shape (988, 1153)\n",
      "\n",
      "-----Dados de Treino-----\n",
      "MSE - treino 0.12479903773107116\n",
      "MAE - treino 0.16999999999999904\n",
      "R2 - treino 0.9002756187657337\n",
      "\n",
      "-----Dados de Teste-----\n",
      "MSE - test 0.6817317813765181\n",
      "MAE - test 0.42500000000000027\n",
      "R2 - test 0.4806721147829238\n"
     ]
    }
   ],
   "source": [
    "model4 = run_model_with_poly(df, 2, RandomForestRegressor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Após estarmos convictos que o modelo treinado tem uma boa relação entre o viés e variância (parametrizado pela complexidade do nosso modelo. Novamente, quanto mais complexo mais ele consegue capturar efeitos não previsto pelo modelo como comportamentos não lineares e interação das variáveis, mas tornando o modelo menos genérico, ou seja, diminuindo os scores dos dados de teste) vamos treinar o modelo final com os parâmetros que conseguiram os melhores resultados nos dados de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dos nossos testes parece que a melhor combinação foi um RandomForestRegressor com polinomios = 1\n",
    "# Então vamos fazer o treinamento do modelo final com TODOS os dados \n",
    "# (agora não podemos mais confiar nas métrica pois não teremos dados de teste)\n",
    "\n",
    "Y = df['imdb_score']\n",
    "X = df.drop(['imdb_score'], axis=1)\n",
    "\n",
    "final_model = RandomForestRegressor().fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1046"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passo 5 - Fazer Predições."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>color</th>\n",
       "      <th>director_name</th>\n",
       "      <th>num_critic_for_reviews</th>\n",
       "      <th>duration</th>\n",
       "      <th>director_facebook_likes</th>\n",
       "      <th>actor_3_facebook_likes</th>\n",
       "      <th>actor_2_name</th>\n",
       "      <th>actor_1_facebook_likes</th>\n",
       "      <th>gross</th>\n",
       "      <th>...</th>\n",
       "      <th>num_user_for_reviews</th>\n",
       "      <th>language</th>\n",
       "      <th>country</th>\n",
       "      <th>content_rating</th>\n",
       "      <th>budget</th>\n",
       "      <th>title_year</th>\n",
       "      <th>actor_2_facebook_likes</th>\n",
       "      <th>imdb_score</th>\n",
       "      <th>aspect_ratio</th>\n",
       "      <th>movie_facebook_likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>Color</td>\n",
       "      <td>Zack Snyder</td>\n",
       "      <td>673.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>Lauren Cohan</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>330249062.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3018.0</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>250000000.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2.35</td>\n",
       "      <td>197000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>Color</td>\n",
       "      <td>Anthony Russo</td>\n",
       "      <td>516.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>Scarlett Johansson</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>407197282.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>250000000.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>19000.0</td>\n",
       "      <td>8.2</td>\n",
       "      <td>2.35</td>\n",
       "      <td>72000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57</td>\n",
       "      <td>Color</td>\n",
       "      <td>Justin Lin</td>\n",
       "      <td>322.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>681.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>Melissa Roxburgh</td>\n",
       "      <td>998.0</td>\n",
       "      <td>130468626.0</td>\n",
       "      <td>...</td>\n",
       "      <td>432.0</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>185000000.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2.35</td>\n",
       "      <td>30000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63</td>\n",
       "      <td>Color</td>\n",
       "      <td>David Yates</td>\n",
       "      <td>248.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>Alexander Skarsgård</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>124051759.0</td>\n",
       "      <td>...</td>\n",
       "      <td>239.0</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>180000000.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2.35</td>\n",
       "      <td>29000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65</td>\n",
       "      <td>Color</td>\n",
       "      <td>Bryan Singer</td>\n",
       "      <td>396.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>Michael Fassbender</td>\n",
       "      <td>34000.0</td>\n",
       "      <td>154985087.0</td>\n",
       "      <td>...</td>\n",
       "      <td>622.0</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>178000000.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>13000.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>2.35</td>\n",
       "      <td>54000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  color  director_name  num_critic_for_reviews  duration  \\\n",
       "0          10  Color    Zack Snyder                   673.0     183.0   \n",
       "1          27  Color  Anthony Russo                   516.0     147.0   \n",
       "2          57  Color     Justin Lin                   322.0     122.0   \n",
       "3          63  Color    David Yates                   248.0     110.0   \n",
       "4          65  Color   Bryan Singer                   396.0     144.0   \n",
       "\n",
       "   director_facebook_likes  actor_3_facebook_likes         actor_2_name  \\\n",
       "0                      0.0                  2000.0         Lauren Cohan   \n",
       "1                     94.0                 11000.0   Scarlett Johansson   \n",
       "2                    681.0                   105.0     Melissa Roxburgh   \n",
       "3                    282.0                   103.0  Alexander Skarsgård   \n",
       "4                      0.0                  1000.0   Michael Fassbender   \n",
       "\n",
       "   actor_1_facebook_likes        gross          ...           \\\n",
       "0                 15000.0  330249062.0          ...            \n",
       "1                 21000.0  407197282.0          ...            \n",
       "2                   998.0  130468626.0          ...            \n",
       "3                 11000.0  124051759.0          ...            \n",
       "4                 34000.0  154985087.0          ...            \n",
       "\n",
       "  num_user_for_reviews language country  content_rating       budget  \\\n",
       "0               3018.0  English     USA           PG-13  250000000.0   \n",
       "1               1022.0  English     USA           PG-13  250000000.0   \n",
       "2                432.0  English     USA           PG-13  185000000.0   \n",
       "3                239.0  English     USA           PG-13  180000000.0   \n",
       "4                622.0  English     USA           PG-13  178000000.0   \n",
       "\n",
       "  title_year  actor_2_facebook_likes imdb_score aspect_ratio  \\\n",
       "0     2016.0                  4000.0        6.9         2.35   \n",
       "1     2016.0                 19000.0        8.2         2.35   \n",
       "2     2016.0                   119.0        7.5         2.35   \n",
       "3     2016.0                 10000.0        6.6         2.35   \n",
       "4     2016.0                 13000.0        7.3         2.35   \n",
       "\n",
       "   movie_facebook_likes  \n",
       "0              197000.0  \n",
       "1               72000.0  \n",
       "2               30000.0  \n",
       "3               29000.0  \n",
       "4               54000.0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Depois que temos o melhor modelo treinado vamos pegar os dados do mundo real e fazer previsão.\n",
    "\n",
    "df2016_raw = pd.read_csv('test.csv')\n",
    "df2016 = df2016_raw.copy(deep=True)\n",
    "df2016.head()\n",
    "\n",
    "# nesse nosso caso, temos o target nos dados \"reais\", geralmente não o teriamos, \n",
    "# aqui poderemos saber a perfomance do nosso algoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todos os tratamentos de dados que fizemos no dataset original precisamos refazer aqui:\n",
    "\n",
    "df2016 = df2016.drop(columns_to_drop, axis=1)\n",
    "\n",
    "df2016[list(df_numeric)] = df2016[list(df_numeric)].fillna(df2016.mean())\n",
    "\n",
    "df2016 = df2016.fillna('na')\n",
    "\n",
    "df2016 = pd.get_dummies(df2016)\n",
    "\n",
    "Y2016 = df2016['imdb_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1046"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "587"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(df2016))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df2016' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-a7d1f355f42a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdummy\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mdummy\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf2016\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m         \u001b[0mdf2016\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdummy\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'dummies adicionadas:{i}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df2016' is not defined"
     ]
    }
   ],
   "source": [
    "for i, dummy in enumerate(list(X)):\n",
    "    if dummy not in list(df2016):\n",
    "        df2016[dummy] = 0\n",
    "\n",
    "print(f'dummies adicionadas:{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2016 = df2016[list(X)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = final_model.predict(X2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.93, 7.41, 5.8 , 5.73, 6.03, 6.1 , 5.99, 4.16, 5.47, 5.94, 6.18,\n",
       "       5.73, 3.1 , 6.54, 5.82, 6.17, 5.47, 5.85, 5.89, 5.71, 5.68, 5.01,\n",
       "       5.9 , 5.31, 5.6 , 6.02, 6.79, 6.39, 7.76, 5.91, 5.92, 5.82, 5.93,\n",
       "       6.12, 7.15, 5.43, 6.65, 5.93, 5.97, 6.37, 3.1 , 6.05, 4.93, 6.03,\n",
       "       4.41, 5.99, 5.54, 6.71, 6.09, 6.71, 5.89, 6.44, 6.66, 5.65, 6.02,\n",
       "       5.27, 6.29, 5.87, 5.48, 5.56, 5.88, 6.46, 4.92, 5.64, 5.64, 5.65,\n",
       "       4.82, 5.39, 6.59, 6.03, 5.63, 6.42, 6.23, 6.37, 5.66, 5.45, 5.79,\n",
       "       6.13, 4.45, 6.15, 5.29, 7.2 , 5.71, 6.77, 4.85, 5.84, 4.85, 5.39,\n",
       "       5.21, 7.22, 5.56, 4.82, 5.88, 4.98, 6.2 , 5.91, 5.28, 5.21, 6.09,\n",
       "       6.21, 6.05, 5.57, 5.08, 5.95, 5.97, 5.76])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perfeito! Temos um array com os valores previstos\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>color</th>\n",
       "      <th>director_name</th>\n",
       "      <th>num_critic_for_reviews</th>\n",
       "      <th>duration</th>\n",
       "      <th>director_facebook_likes</th>\n",
       "      <th>actor_3_facebook_likes</th>\n",
       "      <th>actor_2_name</th>\n",
       "      <th>actor_1_facebook_likes</th>\n",
       "      <th>gross</th>\n",
       "      <th>...</th>\n",
       "      <th>language</th>\n",
       "      <th>country</th>\n",
       "      <th>content_rating</th>\n",
       "      <th>budget</th>\n",
       "      <th>title_year</th>\n",
       "      <th>actor_2_facebook_likes</th>\n",
       "      <th>imdb_score</th>\n",
       "      <th>aspect_ratio</th>\n",
       "      <th>movie_facebook_likes</th>\n",
       "      <th>score_previsto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>Color</td>\n",
       "      <td>Zack Snyder</td>\n",
       "      <td>673.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>Lauren Cohan</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>330249062.0</td>\n",
       "      <td>...</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>250000000.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2.35</td>\n",
       "      <td>197000.0</td>\n",
       "      <td>6.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>Color</td>\n",
       "      <td>Anthony Russo</td>\n",
       "      <td>516.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>Scarlett Johansson</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>407197282.0</td>\n",
       "      <td>...</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>250000000.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>19000.0</td>\n",
       "      <td>8.2</td>\n",
       "      <td>2.35</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>7.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57</td>\n",
       "      <td>Color</td>\n",
       "      <td>Justin Lin</td>\n",
       "      <td>322.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>681.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>Melissa Roxburgh</td>\n",
       "      <td>998.0</td>\n",
       "      <td>130468626.0</td>\n",
       "      <td>...</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>185000000.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2.35</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>5.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63</td>\n",
       "      <td>Color</td>\n",
       "      <td>David Yates</td>\n",
       "      <td>248.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>Alexander Skarsgård</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>124051759.0</td>\n",
       "      <td>...</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>180000000.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2.35</td>\n",
       "      <td>29000.0</td>\n",
       "      <td>5.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65</td>\n",
       "      <td>Color</td>\n",
       "      <td>Bryan Singer</td>\n",
       "      <td>396.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>Michael Fassbender</td>\n",
       "      <td>34000.0</td>\n",
       "      <td>154985087.0</td>\n",
       "      <td>...</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>178000000.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>13000.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>2.35</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>6.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  color  director_name  num_critic_for_reviews  duration  \\\n",
       "0          10  Color    Zack Snyder                   673.0     183.0   \n",
       "1          27  Color  Anthony Russo                   516.0     147.0   \n",
       "2          57  Color     Justin Lin                   322.0     122.0   \n",
       "3          63  Color    David Yates                   248.0     110.0   \n",
       "4          65  Color   Bryan Singer                   396.0     144.0   \n",
       "\n",
       "   director_facebook_likes  actor_3_facebook_likes         actor_2_name  \\\n",
       "0                      0.0                  2000.0         Lauren Cohan   \n",
       "1                     94.0                 11000.0   Scarlett Johansson   \n",
       "2                    681.0                   105.0     Melissa Roxburgh   \n",
       "3                    282.0                   103.0  Alexander Skarsgård   \n",
       "4                      0.0                  1000.0   Michael Fassbender   \n",
       "\n",
       "   actor_1_facebook_likes        gross       ...       language country  \\\n",
       "0                 15000.0  330249062.0       ...        English     USA   \n",
       "1                 21000.0  407197282.0       ...        English     USA   \n",
       "2                   998.0  130468626.0       ...        English     USA   \n",
       "3                 11000.0  124051759.0       ...        English     USA   \n",
       "4                 34000.0  154985087.0       ...        English     USA   \n",
       "\n",
       "  content_rating       budget  title_year actor_2_facebook_likes  imdb_score  \\\n",
       "0          PG-13  250000000.0      2016.0                 4000.0         6.9   \n",
       "1          PG-13  250000000.0      2016.0                19000.0         8.2   \n",
       "2          PG-13  185000000.0      2016.0                  119.0         7.5   \n",
       "3          PG-13  180000000.0      2016.0                10000.0         6.6   \n",
       "4          PG-13  178000000.0      2016.0                13000.0         7.3   \n",
       "\n",
       "  aspect_ratio movie_facebook_likes  score_previsto  \n",
       "0         2.35             197000.0            6.93  \n",
       "1         2.35              72000.0            7.41  \n",
       "2         2.35              30000.0            5.80  \n",
       "3         2.35              29000.0            5.73  \n",
       "4         2.35              54000.0            6.03  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# como podemos saber de qual filme se trata cada um dos score previstos?\n",
    "# o algoritmo não diz qual é o nome do filme, mas a ordem em que passamos os dados se mantém ..\n",
    "# então podemos adicionar uma coluna no nosso dataframe original com as predições!\n",
    "\n",
    "df2016_raw['score_previsto'] = yhat\n",
    "df2016_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Respondendo a pergunta do nosso Desafio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marcos\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "result = df2016_raw[['movie_title','budget','score_previsto']]\n",
    "result['ratio'] = (result['budget']/1000000)/(result['score_previsto'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_title</th>\n",
       "      <th>budget</th>\n",
       "      <th>score_previsto</th>\n",
       "      <th>ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Ghostbusters</td>\n",
       "      <td>144000000.0</td>\n",
       "      <td>3.10</td>\n",
       "      <td>46.451613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Ghostbusters</td>\n",
       "      <td>144000000.0</td>\n",
       "      <td>3.10</td>\n",
       "      <td>46.451613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Independence Day: Resurgence</td>\n",
       "      <td>165000000.0</td>\n",
       "      <td>4.16</td>\n",
       "      <td>39.663462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Batman v Superman: Dawn of Justice</td>\n",
       "      <td>250000000.0</td>\n",
       "      <td>6.93</td>\n",
       "      <td>36.075036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Captain America: Civil War</td>\n",
       "      <td>250000000.0</td>\n",
       "      <td>7.41</td>\n",
       "      <td>33.738192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Star Trek Beyond</td>\n",
       "      <td>185000000.0</td>\n",
       "      <td>5.80</td>\n",
       "      <td>31.896552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The Legend of Tarzan</td>\n",
       "      <td>180000000.0</td>\n",
       "      <td>5.73</td>\n",
       "      <td>31.413613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Legend of Tarzan</td>\n",
       "      <td>180000000.0</td>\n",
       "      <td>5.73</td>\n",
       "      <td>31.413613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X-Men: Apocalypse</td>\n",
       "      <td>178000000.0</td>\n",
       "      <td>6.03</td>\n",
       "      <td>29.519071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Jungle Book</td>\n",
       "      <td>175000000.0</td>\n",
       "      <td>5.99</td>\n",
       "      <td>29.215359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            movie_title       budget  score_previsto  \\\n",
       "40                        Ghostbusters   144000000.0            3.10   \n",
       "12                        Ghostbusters   144000000.0            3.10   \n",
       "7         Independence Day: Resurgence   165000000.0            4.16   \n",
       "0   Batman v Superman: Dawn of Justice   250000000.0            6.93   \n",
       "1           Captain America: Civil War   250000000.0            7.41   \n",
       "2                     Star Trek Beyond   185000000.0            5.80   \n",
       "11                The Legend of Tarzan   180000000.0            5.73   \n",
       "3                 The Legend of Tarzan   180000000.0            5.73   \n",
       "4                    X-Men: Apocalypse   178000000.0            6.03   \n",
       "6                      The Jungle Book   175000000.0            5.99   \n",
       "\n",
       "        ratio  \n",
       "40  46.451613  \n",
       "12  46.451613  \n",
       "7   39.663462  \n",
       "0   36.075036  \n",
       "1   33.738192  \n",
       "2   31.896552  \n",
       "11  31.413613  \n",
       "3   31.413613  \n",
       "4   29.519071  \n",
       "6   29.215359  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"piores\" 10 filmes nas regras desse desafio, são os filmes que os scores custam mais caro.\n",
    "result.sort_values(by=['ratio'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-323261827f4a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# \"melhores\" 10 filmes nas regras desse desafio.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ratio'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "# \"melhores\" 10 filmes nas regras desse desafio.\n",
    "result.sort_values(by=['ratio'], ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Próximo passo, colocar o modelo em produção ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
